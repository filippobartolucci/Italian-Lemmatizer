{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  95\n",
      "Max sentence length:  107\n",
      "Number of sentences in dev set:  703\n",
      "Number of sentences in test set:  5596\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, LSTM, Dense, Embedding, Concatenate, Bidirectional, TimeDistributed, RepeatVector, Activation, Dot, Lambda, GRU\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import gensim\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# set all random seeds\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "dataset_path = \"./dev.csv\"\n",
    "df_dev = pd.read_csv(dataset_path, sep=\"\\t\", header=None,\n",
    "                     names=[\"word\", \"tag\", \"lemm\"])\n",
    "\n",
    "dataset_path = \"./test.csv\"\n",
    "df_test = pd.read_csv(dataset_path, sep=\"\\t\", header=None,\n",
    "                      names=[\"word\", \"tag\", \"lemm\"])\n",
    "\n",
    "df_dev[\"word\"] = df_dev[\"word\"].astype(str)\n",
    "df_dev[\"tag\"] = df_dev[\"tag\"].astype(str)\n",
    "df_dev[\"lemm\"] = df_dev[\"lemm\"].astype(str)\n",
    "\n",
    "df_test[\"word\"] = df_test[\"word\"].astype(str)\n",
    "df_test[\"tag\"] = df_test[\"tag\"].astype(str)\n",
    "df_test[\"lemm\"] = df_test[\"lemm\"].astype(str)\n",
    "\n",
    "# remove head\n",
    "df_dev = df_dev.iloc[1:]\n",
    "df_test = df_test.iloc[1:]\n",
    "\n",
    "# removing rows where tag is nan\n",
    "df_dev = df_dev.dropna(subset=[\"tag\"])\n",
    "df_dev = df_dev[df_dev[\"tag\"] != \"nan\"]\n",
    "df_test = df_test.dropna(subset=[\"tag\"])\n",
    "df_test = df_test[df_test[\"tag\"] != \"nan\"]\n",
    "\n",
    "# lower case all words\n",
    "df_test[\"word\"] = df_test[\"word\"].str.lower()\n",
    "df_dev[\"word\"] = df_dev[\"word\"].str.lower()\n",
    "\n",
    "def get_sentences(df):\n",
    "    words = []\n",
    "    tags = []\n",
    "    lemmas = []\n",
    "    sentence = []\n",
    "    max_s = 0\n",
    "    for index, row in df.iterrows():\n",
    "        word = row[\"word\"]\n",
    "        tag = row[\"tag\"]\n",
    "        lemm = row[\"lemm\"]\n",
    "        sentence.append([word, tag, lemm])\n",
    "\n",
    "        if row[\"word\"] in [\".\", \"?\", \"!\", \";\"]:\n",
    "            words.append([word for word, tag, lemm in sentence])\n",
    "            tags.append([tag for word, tag, lemm in sentence])\n",
    "            lemmas.append([lemm for word, tag, lemm in sentence])\n",
    "            max_s = max(max_s, len(sentence))\n",
    "            sentence = []\n",
    "\n",
    "    print(\"Max sentence length: \", max_s)\n",
    "    return words, tags, lemmas\n",
    "\n",
    "# _s is for string\n",
    "dev_words_s, dev_tags_s, dev_lemmas_s = get_sentences(df_dev)\n",
    "test_words_s, test_tags_s, test_lemmas_s = get_sentences(df_test)\n",
    "print(\"Number of sentences in dev set: \", len(dev_words_s))\n",
    "print(\"Number of sentences in test set: \", len(test_words_s))\n",
    "\n",
    "for i in range(len(dev_words_s)):\n",
    "    if len(dev_words_s[i]) != len(dev_tags_s[i]) or len(dev_words_s[i]) != len(dev_lemmas_s[i]):\n",
    "        print(\"Dimension mismatch in sentence: \", i)\n",
    "        print(\"Words: \", dev_words_s[i])\n",
    "        print(\"Tags: \", dev_tags_s[i])\n",
    "        print(\"Lemmas: \", dev_lemmas_s[i])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean sentence length:  24.610241820768138\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# max sentence length, mean, median \n",
    "mean_s = 0\n",
    "for i in range(len(dev_words_s)):\n",
    "    mean_s += len(dev_words_s[i])\n",
    "mean_s /= len(dev_words_s)\n",
    "print(\"Mean sentence length: \", mean_s)\n",
    "\n",
    "# plot length distribution\n",
    "lengths = [len(s) for s in dev_words_s]\n",
    "sns.displot(lengths, kde=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word:  ['mi', 'riferisco', 'al', 'lavoro', 'dove', 'non', \"c'\", '&egrave;', ',', 'innanzitutto', 'nel', 'mezzogiorno', ',', 'e', 'al', 'lavoro', 'che', 'cambia', '.']\n",
      "Tag:  ['pron_per', 'v_gvrb', 'prep_a', 'nn', 'conj_s', 'adv', 'adv', 'v_essere', 'p_oth', 'adv', 'prep_a', 'nn_p', 'p_oth', 'conj_c', 'prep_a', 'nn', 'pron_rel', 'v_gvrb', 'p_eos']\n",
      "Lemma:  ['mi', 'riferire', 'al', 'lavoro', 'dove', 'non', 'ci', 'essere', ',', 'innanzitutto', 'nel', 'mezzogiorno', ',', 'e', 'al', 'lavoro', 'che', 'cambiare', '.']\n",
      "Encoded word:  [153, 8977, 31, 162, 99, 13, 75, 11, 1, 4242, 35, 1277, 1, 4, 31, 162, 5, 3359, 2]\n",
      "Encoded tag:  [14, 5, 7, 1, 16, 8, 8, 13, 4, 8, 7, 9, 4, 11, 7, 1, 15, 5, 10]\n",
      "Encoded lemma:  [167, 2613, 32, 147, 104, 14, 41, 4, 1, 3755, 39, 1380, 1, 5, 32, 147, 6, 642, 2]\n",
      "\n",
      "Number of unique words:  19729\n",
      "Number of unique tags:  31\n",
      "Number of unique lemmas:  12857\n"
     ]
    }
   ],
   "source": [
    "# encode words\n",
    "word_tokenizer = Tokenizer(filters=\"\")\n",
    "word_tokenizer.fit_on_texts(dev_words_s + test_words_s)\n",
    "dev_words_e = word_tokenizer.texts_to_sequences(dev_words_s)\n",
    "test_words_e = word_tokenizer.texts_to_sequences(test_words_s)\n",
    "\n",
    "# encode tags\n",
    "tag_tokenizer = Tokenizer(filters=\"\")\n",
    "tag_tokenizer.fit_on_texts(dev_tags_s + test_tags_s)\n",
    "dev_tags_e = tag_tokenizer.texts_to_sequences(dev_tags_s)\n",
    "test_tags_e = tag_tokenizer.texts_to_sequences(test_tags_s)\n",
    "\n",
    "# encode lemmas\n",
    "lemma_tokenizer = Tokenizer(filters=\"\")\n",
    "lemma_tokenizer.fit_on_texts(dev_lemmas_s + test_lemmas_s)\n",
    "dev_lemmas_e = lemma_tokenizer.texts_to_sequences(dev_lemmas_s)\n",
    "test_lemmas_e = lemma_tokenizer.texts_to_sequences(test_lemmas_s)\n",
    "\n",
    "# look at first encoded data point\n",
    "print(\"Word: \", dev_words_s[0])\n",
    "print(\"Tag: \", dev_tags_s[0])\n",
    "print(\"Lemma: \", dev_lemmas_s[0])\n",
    "print(\"Encoded word: \", dev_words_e[0])\n",
    "print(\"Encoded tag: \", dev_tags_e[0])\n",
    "print(\"Encoded lemma: \", dev_lemmas_e[0])\n",
    "\n",
    "print(\"\\nNumber of unique words: \", len(word_tokenizer.word_index))\n",
    "print(\"Number of unique tags: \", len(tag_tokenizer.word_index))\n",
    "print(\"Number of unique lemmas: \", len(lemma_tokenizer.word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded words:  [ 153 8977   31  162   99   13   75   11    1 4242   35 1277    1    4\n",
      "   31  162    5 3359    2    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0]\n",
      "Encoded tags:  [14  5  7  1 16  8  8 13  4  8  7  9  4 11  7  1 15  5 10  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0]\n",
      "Encoded lemmas:  [ 167 2613   32  147  104   14   41    4    1 3755   39 1380    1    5\n",
      "   32  147    6  642    2    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "MAX_SENTENCE_LENGTH = 50\n",
    "PADDING_TYPE = \"post\"\n",
    "TRUNCATING_TYPE = \"post\"\n",
    "\n",
    "# pad encoded data\n",
    "dev_words_e = tf.keras.preprocessing.sequence.pad_sequences(dev_words_e, maxlen=MAX_SENTENCE_LENGTH, padding=PADDING_TYPE, truncating=TRUNCATING_TYPE)\n",
    "test_words_e = tf.keras.preprocessing.sequence.pad_sequences(test_words_e, maxlen=MAX_SENTENCE_LENGTH, padding=PADDING_TYPE, truncating=TRUNCATING_TYPE)\n",
    "dev_tags_e = tf.keras.preprocessing.sequence.pad_sequences(dev_tags_e, maxlen=MAX_SENTENCE_LENGTH, padding=PADDING_TYPE, truncating=TRUNCATING_TYPE)\n",
    "test_tags_e = tf.keras.preprocessing.sequence.pad_sequences(test_tags_e, maxlen=MAX_SENTENCE_LENGTH, padding=PADDING_TYPE, truncating=TRUNCATING_TYPE)\n",
    "dev_lemmas_e = tf.keras.preprocessing.sequence.pad_sequences(dev_lemmas_e, maxlen=MAX_SENTENCE_LENGTH, padding=PADDING_TYPE, truncating=TRUNCATING_TYPE)\n",
    "test_lemmas_e = tf.keras.preprocessing.sequence.pad_sequences(test_lemmas_e, maxlen=MAX_SENTENCE_LENGTH, padding=PADDING_TYPE, truncating=TRUNCATING_TYPE)\n",
    "\n",
    "# print first encoded data point\n",
    "print(\"Encoded words: \", dev_words_e[0])\n",
    "print(\"Encoded tags: \", dev_tags_e[0])\n",
    "print(\"Encoded lemmas: \", dev_lemmas_e[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 256\n",
    "VOCABULARY_SIZE = len(word_tokenizer.word_index) + 1\n",
    "\n",
    "# train word2vec model\n",
    "word2vec = gensim.models.Word2Vec(dev_words_s + test_words_s, vector_size=EMBEDDING_SIZE, window=7, min_count=1, workers=4)\n",
    "\n",
    "# create an empty embedding matix\n",
    "embedding_weights = np.zeros((VOCABULARY_SIZE, EMBEDDING_SIZE))\n",
    "\n",
    "# create a word to index dictionary mapping\n",
    "word2id = word_tokenizer.word_index\n",
    "\n",
    "# copy vectors from word2vec model to the words present in corpus\n",
    "for word, index in word2id.items():\n",
    "    try:\n",
    "        embedding_weights[index, :] = word2vec.wv[word]\n",
    "    except KeyError:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dev words:  (703, 50)\n",
      "Shape of dev tags:  (703, 50)\n",
      "Shape of dev lemmas:  (703, 50)\n",
      "Shape of test words:  (5596, 50)\n",
      "Shape of test tags:  (5596, 50)\n",
      "Shape of test lemmas:  (5596, 50)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of dev words: \", dev_words_e.shape)\n",
    "print(\"Shape of dev tags: \", dev_tags_e.shape)\n",
    "print(\"Shape of dev lemmas: \", dev_lemmas_e.shape)\n",
    "print(\"Shape of test words: \", test_words_e.shape)\n",
    "print(\"Shape of test tags: \", test_tags_e.shape)\n",
    "print(\"Shape of test lemmas: \", test_lemmas_e.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " words (InputLayer)             [(None, 50)]         0           []                               \n",
      "                                                                                                  \n",
      " tags (InputLayer)              [(None, 50)]         0           []                               \n",
      "                                                                                                  \n",
      " word_embedding (Embedding)     (None, 50, 256)      5050880     ['words[0][0]']                  \n",
      "                                                                                                  \n",
      " tag_embedding (Embedding)      (None, 50, 256)      8192        ['tags[0][0]']                   \n",
      "                                                                                                  \n",
      " time1 (TimeDistributed)        (None, 50, 256)      65792       ['word_embedding[0][0]']         \n",
      "                                                                                                  \n",
      " time2 (TimeDistributed)        (None, 50, 256)      65792       ['tag_embedding[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 50, 512)      0           ['time1[0][0]',                  \n",
      "                                                                  'time2[0][0]']                  \n",
      "                                                                                                  \n",
      " lstm1 (Bidirectional)          (None, 50, 2048)     12591104    ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 50, 2048)     0           ['lstm1[0][0]']                  \n",
      "                                                                                                  \n",
      " lstm2 (Bidirectional)          (None, 50, 2048)     25174016    ['dropout_12[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 50, 2048)     0           ['lstm2[0][0]']                  \n",
      "                                                                                                  \n",
      " dense1 (Dense)                 (None, 50, 1024)     2098176     ['dropout_13[0][0]']             \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 50, 12858)    13179450    ['dense1[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 58,233,402\n",
      "Trainable params: 58,233,402\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Bidirectional LSTM for lemmatization\n",
    "# inputs:\n",
    "#   - words: encoded words\n",
    "#   - tags: encoded tags\n",
    "# outputs:\n",
    "#   - lemmas: encoded lemmas\n",
    "\n",
    "def get_model():\n",
    "    words = tf.keras.Input(shape=(MAX_SENTENCE_LENGTH,), name=\"words\")\n",
    "    tags = tf.keras.Input(shape=(MAX_SENTENCE_LENGTH,), name=\"tags\")\n",
    "\n",
    "    word_embedding = tf.keras.layers.Embedding(input_dim=VOCABULARY_SIZE, output_dim=EMBEDDING_SIZE, weights=[embedding_weights], trainable=True, name=\"word_embedding\")(words)\n",
    "    word_embedding = TimeDistributed(tf.keras.layers.Dense(EMBEDDING_SIZE, activation=\"swish\"), name=\"time1\")(word_embedding)\n",
    "    tag_embedding = tf.keras.layers.Embedding(input_dim=len(tag_tokenizer.word_index) + 1, output_dim=EMBEDDING_SIZE, trainable = True, name=\"tag_embedding\")(tags)\n",
    "    tag_embedding = TimeDistributed(tf.keras.layers.Dense(EMBEDDING_SIZE, activation=\"swish\"), name=\"time2\")(tag_embedding)\n",
    "\n",
    "    # concatenate word and tag embeddings\n",
    "    Concatenate = tf.keras.layers.Concatenate()([word_embedding, tag_embedding])\n",
    "\n",
    "    # bidirectional LSTM\n",
    "    lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(1024, return_sequences=True), name=\"lstm1\")(Concatenate)\n",
    "    lstm = tf.keras.layers.Dropout(0.5)(lstm)\n",
    "    lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(1024, return_sequences=True), name=\"lstm2\")(lstm)\n",
    "\n",
    "    dropout = tf.keras.layers.Dropout(0.5)(lstm)\n",
    "    dense = tf.keras.layers.Dense(1024, activation=\"swish\", name=\"dense1\")(dropout)\n",
    "\n",
    "    output = tf.keras.layers.Dense(len(lemma_tokenizer.word_index) + 1, activation=\"softmax\", name=\"output\")(dense)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[words, tags], outputs=output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "    \n",
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\"])\n",
    "history = model.fit(x={\"words\": dev_words_e, \"tags\": dev_tags_e}, y=dev_lemmas_e, batch_size=32, epochs=70, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 14s 81ms/step - loss: 5.3124 - sparse_categorical_accuracy: 0.7896\n",
      "Test loss:  5.31242561340332\n",
      "Test accuracy:  0.7896175980567932\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(x={\"words\": test_words_e, \"tags\": test_tags_e}, y=test_lemmas_e)\n",
    "print(\"Test loss: \", result[0])\n",
    "print(\"Test accuracy: \", result[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:25:29) [Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08eac26dc1f80337b7d87e94e7159a5bad95c2e85f47efef91c61359b3afbfe9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
