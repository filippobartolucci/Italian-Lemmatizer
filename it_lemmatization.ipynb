{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### DF shape: (19789, 3)\n",
      "\n",
      "### NaN values:\n",
      "word    0\n",
      "tag     0\n",
      "lemm    0\n",
      "dtype: int64\n",
      "\n",
      "### DF shape after removing rows where tag is nan: (19726, 3)\n",
      "\n",
      "### Unique values:\n",
      "word    19726\n",
      "tag        31\n",
      "lemm    12643\n",
      "dtype: int64\n",
      "\n",
      "### Number of word that are equals to lemm:\n",
      "9967\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "      <th>lemm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mi</td>\n",
       "      <td>pron_per</td>\n",
       "      <td>mi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>riferisco</td>\n",
       "      <td>v_gvrb</td>\n",
       "      <td>riferire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>al</td>\n",
       "      <td>prep_a</td>\n",
       "      <td>al</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lavoro</td>\n",
       "      <td>nn</td>\n",
       "      <td>lavoro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dove</td>\n",
       "      <td>conj_s</td>\n",
       "      <td>dove</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word       tag      lemm\n",
       "1         mi  pron_per        mi\n",
       "2  riferisco    v_gvrb  riferire\n",
       "3         al    prep_a        al\n",
       "4     lavoro        nn    lavoro\n",
       "5       dove    conj_s      dove"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Embedding, Concatenate, Bidirectional, TimeDistributed, RepeatVector, Activation, Dot, Lambda\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# set all random seeds\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "dataset_path = \"./dev.csv\"\n",
    "df = pd.read_csv(dataset_path, sep=\"\\t\", header=None, names=[\"word\", \"tag\", \"lemm\"])\n",
    "\n",
    "dataset_path = \"./test.csv\"\n",
    "df = pd.concat([df,pd.read_csv(dataset_path, sep=\"\\t\", header=None, names=[\"word\", \"tag\", \"lemm\"])])\n",
    "\n",
    "df[\"word\"] = df[\"word\"].astype(str) \n",
    "df[\"tag\"] = df[\"tag\"].astype(str)\n",
    "df[\"lemm\"] = df[\"lemm\"].astype(str)\n",
    "\n",
    "# remove duplicates in word columns\n",
    "df = df.drop_duplicates(subset=[\"word\"])\n",
    "\n",
    "# remove head\n",
    "df = df.iloc[1:]\n",
    "\n",
    "# df = df[df[\"tag\"] != \"p_oth\"]\n",
    "# df = df[df[\"tag\"] != \"c_num\"]\n",
    "\n",
    "print(\"### DF shape:\" ,df.shape)\n",
    "print(\"\\n### NaN values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# removing rows where tag is nan\n",
    "df = df.dropna(subset=[\"tag\"])\n",
    "df = df[df[\"tag\"] != \"nan\"]\n",
    "\n",
    "print(\"\\n### DF shape after removing rows where tag is nan:\" ,df.shape)\n",
    "\n",
    "# print number of unique values for each column\n",
    "print(\"\\n### Unique values:\")\n",
    "print(df.nunique())\n",
    "\n",
    "# lower case all words\n",
    "df[\"word\"] = df[\"word\"].str.lower()\n",
    "\n",
    "# count number of row where word is equal to lemm\n",
    "print(\"\\n### Number of word that are equals to lemm:\")\n",
    "print(df[df[\"word\"] == df[\"lemm\"]].shape[0])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Number of unique characters: 60\n",
      "\n",
      "### Max word length: 25\n"
     ]
    }
   ],
   "source": [
    "# get all unique letter in words\n",
    "characters = set()\n",
    "\n",
    "for word in df[\"word\"]:\n",
    "    for letter in word:\n",
    "        characters.add(letter)\n",
    "\n",
    "for lemma in df[\"lemm\"]:\n",
    "    for letter in lemma:\n",
    "        characters.add(letter)\n",
    "\n",
    "# add padding and unknown to characters\n",
    "characters.add(\" \")\n",
    "\n",
    "# the length of the vocab for one-hot encoded char\n",
    "vocab_size = len(characters)\n",
    "\n",
    "print(\"\\n### Number of unique characters:\", vocab_size)\n",
    "\n",
    "# Input in a LSTM must have all the same length\n",
    "# so we pad the words with spaces to have the same length\n",
    "def pad_word(word, max_word_length):\n",
    "    return word + \" \" * (max_word_length - len(word))\n",
    "\n",
    "max_word_length = max(df[\"word\"].str.len().max(), df[\"lemm\"].str.len().max())\n",
    "print(\"\\n### Max word length:\", max_word_length)\n",
    "max_word_length +=1\n",
    "max_word_length = int(max_word_length)\n",
    "\n",
    "df[\"word\"] = df[\"word\"].apply(lambda x: pad_word(x, max_word_length))\n",
    "df[\"lemm\"] = df[\"lemm\"].apply(lambda x: pad_word(x, max_word_length))\n",
    "\n",
    "# order characters\n",
    "characters = sorted(list(characters))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each word is encoded as a list of one-hot encoded characters\n",
    "char_enc = OneHotEncoder(sparse_output=False)\n",
    "char_enc.fit([[char] for char in characters])\n",
    "\n",
    "def encode_word(word):\n",
    "    return char_enc.transform([[char] for char in word])\n",
    "\n",
    "def decode_word(word):\n",
    "    decoded_word = \"\"\n",
    "    for c in word:\n",
    "        decoded_word += char_enc.inverse_transform([c])[0]\n",
    "    return decoded_word\n",
    "\n",
    "# Applying the encoding to the words in the dataframe        \n",
    "df[\"word_e\"] = df[\"word\"].apply(encode_word)\n",
    "df[\"lemm_e\"] = df[\"lemm\"].apply(encode_word)\n",
    "\n",
    "mask_value = char_enc.transform([[\" \"]])[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Number of POS tags: 31\n"
     ]
    }
   ],
   "source": [
    "tag_enc = OneHotEncoder(sparse_output=False)\n",
    "tag_enc.fit(df[[\"tag\"]])\n",
    "df[\"tag_e\"] = tag_enc.transform(df[[\"tag\"]]).tolist()\n",
    "\n",
    "# the length of the vocab for one-hot encoded pos\n",
    "pos_size = len(tag_enc.categories_[0])\n",
    "print(\"### Number of POS tags:\", pos_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Word train shape: (17397, 26, 60)\n",
      "### Tag train shape: (17397, 31)\n",
      "### Y train shape: (17397, 26, 60)\n",
      "\n",
      "### Word val shape: (356, 26, 60)\n",
      "### Tag val shape: (356, 31)\n",
      "### Y val shape: (356, 26, 60)\n",
      "\n",
      "### Word test shape: (1973, 26, 60)\n",
      "### Tag test shape: (1973, 31)\n",
      "### Y test shape: (1973, 26, 60)\n",
      "\n",
      "### Vocab size: 60\n",
      "### POS tag size: 31\n"
     ]
    }
   ],
   "source": [
    "x_word  = np.array(df[\"word_e\"].tolist())\n",
    "x_tag   = np.array(df[\"tag_e\"].tolist())\n",
    "y = np.array(df[\"lemm_e\"].tolist())\n",
    "tag_list = df[\"tag\"].tolist()\n",
    "\n",
    "word_train, word_test, tag_train, tag_test, y_train, y_test, _, tag_list = train_test_split(x_word, x_tag, y, tag_list , test_size=0.1, random_state=42)\n",
    "word_train, word_val, tag_train, tag_val, y_train, y_val = train_test_split(word_train, tag_train, y_train, test_size=0.02, random_state=42)\n",
    "\n",
    "print(\"### Word train shape:\", word_train.shape)\n",
    "print(\"### Tag train shape:\", tag_train.shape)\n",
    "print(\"### Y train shape:\", y_train.shape)\n",
    "\n",
    "print(\"\\n### Word val shape:\", word_val.shape)\n",
    "print(\"### Tag val shape:\", tag_val.shape)\n",
    "print(\"### Y val shape:\", y_val.shape)\n",
    "\n",
    "print(\"\\n### Word test shape:\", word_test.shape)\n",
    "print(\"### Tag test shape:\", tag_test.shape)\n",
    "print(\"### Y test shape:\", y_test.shape)\n",
    "\n",
    "print(\"\\n### Vocab size:\", vocab_size)\n",
    "print(\"### POS tag size:\", pos_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " tag_input (InputLayer)         [(None, 31)]         0           []                               \n",
      "                                                                                                  \n",
      " tag_dense (Dense)              (None, 64)           2048        ['tag_input[0][0]']              \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 26, 60)]     0           []                               \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 64)           0           ['tag_dense[1][0]']              \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 26, 512)      649216      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " tag_dense2 (Dense)             (None, 64)           4160        ['dropout[1][0]']                \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, 26, 512)     1574912     ['bidirectional[1][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " repeat_vector (RepeatVector)   (None, 26, 64)       0           ['tag_dense2[1][0]']             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 26, 576)      0           ['bidirectional_1[1][0]',        \n",
      "                                                                  'repeat_vector[1][0]']          \n",
      "                                                                                                  \n",
      " lstm2dense (Dense)             (None, 26, 64)       36928       ['concatenate[1][0]']            \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 26, 64)       0           ['lstm2dense[1][0]']             \n",
      "                                                                                                  \n",
      " dense2dense (Dense)            (None, 26, 64)       4160        ['dropout_1[1][0]']              \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 26, 60)       3900        ['dense2dense[1][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,275,324\n",
      "Trainable params: 2,275,324\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    # Inputs\n",
    "    word_input = tf.keras.layers.Input(name=\"word_input\", shape=(max_word_length, vocab_size))\n",
    "    tag_input = tf.keras.layers.Input(name=\"tag_input\", shape=(pos_size))\n",
    "\n",
    "    word_input = tf.keras.layers.Masking(mask_value= mask_value)(word_input)\n",
    "\n",
    "    # Bidirectional LSTM layer\n",
    "    lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True))(word_input)\n",
    "    lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True))(lstm)\n",
    "\n",
    "    # Fully connected layer for tag_input\n",
    "    tag_fc = tf.keras.layers.Dense(64, name=\"tag_dense\", activation='swish')(tag_input)\n",
    "    tag_fc = tf.keras.layers.Dropout(0.2)(tag_fc)\n",
    "    tag_fc = tf.keras.layers.Dense(64, name=\"tag_dense2\", activation='swish')(tag_fc)\n",
    "    tag_fc = tf.keras.layers.RepeatVector(max_word_length)(tag_fc)\n",
    "\n",
    "    # Concatenate the two inputs\n",
    "    concat = tf.keras.layers.Concatenate()([lstm, tag_fc])\n",
    "\n",
    "    # Fully connected layer\n",
    "    fc = tf.keras.layers.Dense(64, name=\"lstm2dense\", activation='swish')(concat)\n",
    "    fc = tf.keras.layers.Dropout(0.2)(fc)\n",
    "    fc = tf.keras.layers.Dense(64, name=\"dense2dense\", activation='swish')(fc)\n",
    "    \n",
    "    # Output layer\n",
    "    output = tf.keras.layers.Dense(vocab_size, name=\"output\", activation='softmax')(fc)\n",
    "\n",
    "    # Create model\n",
    "    return tf.keras.models.Model(inputs=[word_input, tag_input], outputs=output)\n",
    "\n",
    "# Create model\n",
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Accuracy\n",
    "\n",
    "Each lemma is correct only if all the characters generated by the model are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.argmax(y_true, axis=-1)\n",
    "    y_pred = tf.argmax(y_pred, axis=-1)\n",
    "    correct_predictions = tf.reduce_all(tf.equal(y_true, y_pred), axis=-1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
    "    return accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 11s 190ms/step - loss: 1.7009 - accuracy: 0.0000e+00 - val_loss: 1.0293 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 5s 134ms/step - loss: 0.9688 - accuracy: 0.0000e+00 - val_loss: 0.9095 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 5s 133ms/step - loss: 0.9101 - accuracy: 1.1489e-04 - val_loss: 0.8761 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 5s 133ms/step - loss: 0.8679 - accuracy: 5.7445e-05 - val_loss: 0.8181 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 5s 133ms/step - loss: 0.7762 - accuracy: 2.2978e-04 - val_loss: 0.6517 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 5s 132ms/step - loss: 0.5116 - accuracy: 0.0291 - val_loss: 0.2702 - val_accuracy: 0.2725\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 5s 132ms/step - loss: 0.2474 - accuracy: 0.2732 - val_loss: 0.1348 - val_accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 5s 133ms/step - loss: 0.1551 - accuracy: 0.4821 - val_loss: 0.0984 - val_accuracy: 0.6292\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 5s 133ms/step - loss: 0.1195 - accuracy: 0.5804 - val_loss: 0.0794 - val_accuracy: 0.7135\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 5s 132ms/step - loss: 0.0993 - accuracy: 0.6374 - val_loss: 0.0676 - val_accuracy: 0.7444\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 5s 132ms/step - loss: 0.0861 - accuracy: 0.6801 - val_loss: 0.0590 - val_accuracy: 0.7697\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 5s 133ms/step - loss: 0.0770 - accuracy: 0.7124 - val_loss: 0.0552 - val_accuracy: 0.7978\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 5s 133ms/step - loss: 0.0691 - accuracy: 0.7449 - val_loss: 0.0503 - val_accuracy: 0.8090\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 5s 133ms/step - loss: 0.0630 - accuracy: 0.7589 - val_loss: 0.0448 - val_accuracy: 0.8371\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 5s 132ms/step - loss: 0.0604 - accuracy: 0.7733 - val_loss: 0.0483 - val_accuracy: 0.8230\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 5s 135ms/step - loss: 0.0570 - accuracy: 0.7851 - val_loss: 0.0407 - val_accuracy: 0.8455\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 5s 132ms/step - loss: 0.0515 - accuracy: 0.7988 - val_loss: 0.0384 - val_accuracy: 0.8483\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.0476 - accuracy: 0.8125 - val_loss: 0.0366 - val_accuracy: 0.8399\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 4s 132ms/step - loss: 0.0455 - accuracy: 0.8166 - val_loss: 0.0365 - val_accuracy: 0.8427\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.0431 - accuracy: 0.8258 - val_loss: 0.0315 - val_accuracy: 0.8624\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 5s 132ms/step - loss: 0.0392 - accuracy: 0.8316 - val_loss: 0.0332 - val_accuracy: 0.8455\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 5s 132ms/step - loss: 0.0375 - accuracy: 0.8406 - val_loss: 0.0300 - val_accuracy: 0.8652\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 4s 132ms/step - loss: 0.0364 - accuracy: 0.8431 - val_loss: 0.0303 - val_accuracy: 0.8455\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 5s 132ms/step - loss: 0.0333 - accuracy: 0.8502 - val_loss: 0.0272 - val_accuracy: 0.8680\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 5s 132ms/step - loss: 0.0313 - accuracy: 0.8532 - val_loss: 0.0271 - val_accuracy: 0.8708\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 4s 132ms/step - loss: 0.0300 - accuracy: 0.8576 - val_loss: 0.0251 - val_accuracy: 0.8736\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 5s 133ms/step - loss: 0.0277 - accuracy: 0.8636 - val_loss: 0.0241 - val_accuracy: 0.8708\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 5s 132ms/step - loss: 0.0258 - accuracy: 0.8706 - val_loss: 0.0242 - val_accuracy: 0.8961\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 5s 133ms/step - loss: 0.0247 - accuracy: 0.8757 - val_loss: 0.0260 - val_accuracy: 0.8820\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 5s 132ms/step - loss: 0.0241 - accuracy: 0.8768 - val_loss: 0.0216 - val_accuracy: 0.8736\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.0218 - accuracy: 0.8869 - val_loss: 0.0201 - val_accuracy: 0.8876\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.0205 - accuracy: 0.8904 - val_loss: 0.0213 - val_accuracy: 0.8961\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.0195 - accuracy: 0.8934 - val_loss: 0.0198 - val_accuracy: 0.8792\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.0189 - accuracy: 0.8952 - val_loss: 0.0208 - val_accuracy: 0.9017\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 4s 132ms/step - loss: 0.0176 - accuracy: 0.8995 - val_loss: 0.0180 - val_accuracy: 0.9045\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.0169 - accuracy: 0.9015 - val_loss: 0.0203 - val_accuracy: 0.8848\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 4s 132ms/step - loss: 0.0156 - accuracy: 0.9101 - val_loss: 0.0194 - val_accuracy: 0.9073\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 5s 132ms/step - loss: 0.0153 - accuracy: 0.9088 - val_loss: 0.0193 - val_accuracy: 0.8933\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 5s 132ms/step - loss: 0.0139 - accuracy: 0.9170 - val_loss: 0.0199 - val_accuracy: 0.8904\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 4s 132ms/step - loss: 0.0134 - accuracy: 0.9178 - val_loss: 0.0200 - val_accuracy: 0.8989\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 4s 132ms/step - loss: 0.0127 - accuracy: 0.9231 - val_loss: 0.0183 - val_accuracy: 0.9073\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 5s 133ms/step - loss: 0.0121 - accuracy: 0.9254 - val_loss: 0.0209 - val_accuracy: 0.9129\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 5s 133ms/step - loss: 0.0122 - accuracy: 0.9254 - val_loss: 0.0233 - val_accuracy: 0.8989\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.0113 - accuracy: 0.9263 - val_loss: 0.0194 - val_accuracy: 0.8933\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 5s 132ms/step - loss: 0.0106 - accuracy: 0.9337 - val_loss: 0.0186 - val_accuracy: 0.8989\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 5s 132ms/step - loss: 0.0096 - accuracy: 0.9405 - val_loss: 0.0227 - val_accuracy: 0.8933\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 5s 132ms/step - loss: 0.0093 - accuracy: 0.9397 - val_loss: 0.0217 - val_accuracy: 0.8876\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.0092 - accuracy: 0.9394 - val_loss: 0.0204 - val_accuracy: 0.9017\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 4s 132ms/step - loss: 0.0085 - accuracy: 0.9445 - val_loss: 0.0211 - val_accuracy: 0.9045\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 5s 133ms/step - loss: 0.0077 - accuracy: 0.9511 - val_loss: 0.0221 - val_accuracy: 0.9101\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 5s 132ms/step - loss: 0.0071 - accuracy: 0.9525 - val_loss: 0.0230 - val_accuracy: 0.9045\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 5s 132ms/step - loss: 0.0067 - accuracy: 0.9552 - val_loss: 0.0247 - val_accuracy: 0.9073\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 5s 134ms/step - loss: 0.0061 - accuracy: 0.9605 - val_loss: 0.0226 - val_accuracy: 0.9129\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 5s 133ms/step - loss: 0.0061 - accuracy: 0.9593 - val_loss: 0.0260 - val_accuracy: 0.9185\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.0065 - accuracy: 0.9566 - val_loss: 0.0218 - val_accuracy: 0.9045\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 5s 132ms/step - loss: 0.0056 - accuracy: 0.9630 - val_loss: 0.0224 - val_accuracy: 0.9017\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 5s 132ms/step - loss: 0.0049 - accuracy: 0.9680 - val_loss: 0.0208 - val_accuracy: 0.9017\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 5s 132ms/step - loss: 0.0052 - accuracy: 0.9642 - val_loss: 0.0242 - val_accuracy: 0.9017\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 5s 132ms/step - loss: 0.0046 - accuracy: 0.9684 - val_loss: 0.0242 - val_accuracy: 0.9129\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 5s 131ms/step - loss: 0.0041 - accuracy: 0.9718 - val_loss: 0.0246 - val_accuracy: 0.9017\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.0040 - accuracy: 0.9736 - val_loss: 0.0266 - val_accuracy: 0.9101\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 5s 132ms/step - loss: 0.0038 - accuracy: 0.9742 - val_loss: 0.0264 - val_accuracy: 0.8989\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 4s 132ms/step - loss: 0.0035 - accuracy: 0.9765 - val_loss: 0.0230 - val_accuracy: 0.9242\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.0033 - accuracy: 0.9772 - val_loss: 0.0264 - val_accuracy: 0.9298\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.0031 - accuracy: 0.9791 - val_loss: 0.0253 - val_accuracy: 0.9157\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.0031 - accuracy: 0.9784 - val_loss: 0.0253 - val_accuracy: 0.9270\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 5s 136ms/step - loss: 0.0029 - accuracy: 0.9806 - val_loss: 0.0290 - val_accuracy: 0.9101\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.0031 - accuracy: 0.9785 - val_loss: 0.0320 - val_accuracy: 0.9129\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 4s 132ms/step - loss: 0.0034 - accuracy: 0.9759 - val_loss: 0.0237 - val_accuracy: 0.9242\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 4s 132ms/step - loss: 0.0033 - accuracy: 0.9771 - val_loss: 0.0314 - val_accuracy: 0.9101\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.0040 - accuracy: 0.9718 - val_loss: 0.0267 - val_accuracy: 0.8989\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.0039 - accuracy: 0.9725 - val_loss: 0.0234 - val_accuracy: 0.9213\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.0026 - accuracy: 0.9818 - val_loss: 0.0236 - val_accuracy: 0.9157\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.0022 - accuracy: 0.9867 - val_loss: 0.0231 - val_accuracy: 0.9270\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.0019 - accuracy: 0.9874 - val_loss: 0.0272 - val_accuracy: 0.8961\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.0046 - accuracy: 0.9713 - val_loss: 0.0312 - val_accuracy: 0.9157\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 4s 132ms/step - loss: 0.0040 - accuracy: 0.9730 - val_loss: 0.0243 - val_accuracy: 0.9270\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.0026 - accuracy: 0.9824 - val_loss: 0.0265 - val_accuracy: 0.9157\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.0022 - accuracy: 0.9855 - val_loss: 0.0251 - val_accuracy: 0.9213\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.0018 - accuracy: 0.9883 - val_loss: 0.0287 - val_accuracy: 0.9298\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.0016 - accuracy: 0.9902 - val_loss: 0.0257 - val_accuracy: 0.9326\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 5s 132ms/step - loss: 0.0014 - accuracy: 0.9907 - val_loss: 0.0273 - val_accuracy: 0.9185\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 4s 132ms/step - loss: 0.0014 - accuracy: 0.9914 - val_loss: 0.0309 - val_accuracy: 0.9298\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.0012 - accuracy: 0.9923 - val_loss: 0.0298 - val_accuracy: 0.9298\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.0012 - accuracy: 0.9924 - val_loss: 0.0299 - val_accuracy: 0.9326\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.0011 - accuracy: 0.9937 - val_loss: 0.0296 - val_accuracy: 0.9242\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 4s 132ms/step - loss: 0.0011 - accuracy: 0.9935 - val_loss: 0.0284 - val_accuracy: 0.9270\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 9.3621e-04 - accuracy: 0.9947 - val_loss: 0.0297 - val_accuracy: 0.9270\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 4s 132ms/step - loss: 9.2585e-04 - accuracy: 0.9932 - val_loss: 0.0294 - val_accuracy: 0.9242\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 4s 132ms/step - loss: 9.9279e-04 - accuracy: 0.9926 - val_loss: 0.0307 - val_accuracy: 0.9242\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 5s 132ms/step - loss: 9.2415e-04 - accuracy: 0.9943 - val_loss: 0.0315 - val_accuracy: 0.9298\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 8.6083e-04 - accuracy: 0.9943 - val_loss: 0.0296 - val_accuracy: 0.9298\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.0010 - accuracy: 0.9937 - val_loss: 0.0276 - val_accuracy: 0.9270\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 4s 130ms/step - loss: 9.6463e-04 - accuracy: 0.9942 - val_loss: 0.0293 - val_accuracy: 0.9298\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.0015 - accuracy: 0.9896 - val_loss: 0.0267 - val_accuracy: 0.9073\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.0018 - accuracy: 0.9868 - val_loss: 0.0281 - val_accuracy: 0.9326\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.0013 - accuracy: 0.9915 - val_loss: 0.0328 - val_accuracy: 0.9157\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.0011 - accuracy: 0.9934 - val_loss: 0.0310 - val_accuracy: 0.9242\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.0017 - accuracy: 0.9879 - val_loss: 0.0325 - val_accuracy: 0.9129\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 4s 131ms/step - loss: 0.0026 - accuracy: 0.9821 - val_loss: 0.0313 - val_accuracy: 0.9213\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "epochs = 100\n",
    "batch_size = 512\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H.%M.%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[accuracy])\n",
    "history = model.fit([word_train, tag_train], y_train, epochs=epochs, batch_size=batch_size, validation_data=([word_val, tag_val], y_val), callbacks=[tensorboard_callback])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Test Accuracy: 91.150630\n",
      "### Test Loss: 0.043829\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loss, acc = model.evaluate([word_test, tag_test], y_test, verbose=0)\n",
    "print('### Test Accuracy: %f' % (acc*100))\n",
    "print('### Test Loss: %f' % (loss))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization Accuracy\n",
    "\n",
    "Lemmatisation accuracy is defined as the number of correct lemma assignment divided by the total number of tokens in the test set belonging to the considered lexical classes (ADJ_, ADV,NN, V_). \n",
    "\n",
    "(Evalita2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABlUAAANXCAYAAACsYNmPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABnr0lEQVR4nOzde5SVdd3//9cMCAPiGRkEUQ6eIhUQkrDErEkMw7QyT7fQlCgqeaAsVATFA1ZKGGGUCZpHSoVf31QMp8hM1AQxvQ3NFFEUkExJlIPM/P64l3M3N2DXGDADPB5r7bWaz/5c+3rv7Sxw9fTaV0lNTU1NAAAAAAAA+EClDT0AAAAAAADA5kBUAQAAAAAAKEBUAQAAAAAAKEBUAQAAAAAAKEBUAQAAAAAAKEBUAQAAAAAAKEBUAQAAAAAAKEBUAQAAAAAAKEBUAQAAAAAAKEBUAQAAAAAAKEBUAQCArcSNN96YkpKS2kdZWVn22WefDB06NIsXL95o550/f36d837QY/78+Rttjv/rL3/5S+3n8Oabb26y8wIAAJuvpg09AAAAsGmNHj06nTp1yooVK/LQQw/lxz/+ce699948/fTTadmy5QY/36677pqbb765zto111yTV155JT/4wQ/W2rup3HLLLWnbtm3+8Y9/5M4778ypp566yc4NAABsnkpqampqGnoIAABg47vxxhtTWVmZP/3pT+nVq1ft+je/+c2MHTs2t912W0488cT/6BzvvPNOoTDz+c9/Pk8//fQmvTLlX9XU1KRz58754he/mBdffDH/+Mc/8rvf/a5BZvl3li9fnm233bahxwAAAOLrvwAAYKv36U9/Okny4osv1q7dcsst6dmzZ1q0aJGdd945J5xwQl5++eU6x33qU5/K/vvvn9mzZ6dv375p2bJlLrzwwg89x9VXX51DDjkku+yyS1q0aJGePXvmzjvvXGvfu+++m7PPPjutW7fOdtttl6OPPjoLFy5MSUlJLrnkkkLn+uMf/5j58+fnhBNOyAknnJAHH3wwr7zyylr7qqurc+211+aAAw5IWVlZdt111xx55JF5/PHH6+y75ZZbcvDBB6dly5bZaaed0rdv3/zmN7+pfX59s3Xs2DFf/epXa39+/yvafv/73+fMM89MmzZtsvvuuydJXnrppZx55pnZd99906JFi+yyyy457rjj1hmm3nzzzZx33nnp2LFjmjdvnt133z0DBw7M0qVL8/bbb2fbbbfNOeecs9Zxr7zySpo0aZIxY8YU+hwBAGBrI6oAAMBW7m9/+1uSZJdddkmSXHHFFRk4cGD23nvvjB07Nueee26qqqrSt2/fte498ve//z2f+9zn0r1794wbNy6HH374h57j2muvTY8ePTJ69OhceeWVadq0aY477rjcc889dfZ99atfzfjx49O/f/9897vfTYsWLXLUUUfV61y33nprunTpko997GMZMGBAWrZsmdtvv32tfV//+tdz7rnnpkOHDvnud7+b4cOHp6ysLI888kjtnksvvTSnnHJKttlmm4wePTqXXnppOnTokN/+9rcf7oNIcuaZZ+aZZ57JyJEjM3z48CTJn/70pzz88MM54YQT8sMf/jBDhgxJVVVVPvWpT+Wdd96pPfbtt9/OoYcemvHjx+eII47ItddemyFDhmTevHl55ZVX0qpVqxx77LGZMmVK1qxZU+e8t99+e2pqanLyySd/6NkBAGBL5p4qAACwlXnrrbeydOnSrFixIn/84x8zevTotGjRIp///Ofz0ksvZdSoUbn88svrXHXyxS9+MT169Mh1111XZ33RokWZOHFiTj/99P94rueeey4tWrSo/Xno0KE56KCDMnbs2NpoMmfOnPziF7/IueeeW3s/ljPPPDOVlZV58sknC51n9erV+eUvf5khQ4YkSVq0aJGjjz46t956a84///zafb/73e9y44035uyzz861115bu/7Nb34z73+L8vPPP5/Ro0fn2GOPzZ133pnS0v/979b+k29a3nnnnVNVVZUmTZrUrh111FH58pe/XGffgAED0qdPn9x111055ZRTkiTf//738/TTT+fuu+/OscceW7t3xIgRtTMNHDgwt956a2bMmJEjjzyyds8tt9ySvn37Zo899vjQswMAwJbMlSoAALCVqaioyK677poOHTrkhBNOSKtWrTJ16tS0b98+d999d6qrq/OVr3wlS5curX20bds2e++991r3HWnevHkqKys3yFz/GlT+8Y9/5K233sqhhx6aOXPm1K5Pnz49yf+ElH/1jW98o/B57rvvvvz973+vc/+YE088MU8++WT++7//u3btrrvuSklJSUaNGrXWa5SUlCRJpk2blurq6owcObJOUPnXPR/G4MGD6wSVpO7ns3r16vz973/PXnvtlR133LHOZ3TXXXelW7dudYLK/52poqIi7dq1y6233lr73NNPP50///nP+a//+q8PPTcAAGzpXKkCAABbmQkTJmSfffZJ06ZNU15enn333bc2CPz1r39NTU1N9t5773Ueu80229T5uX379mnWrNkGmevXv/51Lr/88sydOzcrV66sXf/XOPHSSy+ltLQ0nTp1qnPsXnvtVfg8t9xySzp16pTmzZvn+eefT5J06dIlLVu2zK233porr7wyyf98LVq7du2y8847r/e1/va3v6W0tDRdu3YtfP4i/u/7S/7nXjJjxozJ5MmTs3DhwjpXwrz11lt1ZvrSl770ga9fWlqak08+OT/+8Y/zzjvv1L73srKyHHfccRvujQAAwBZGVAEAgK3MwQcfnF69eq3zuerq6pSUlOS+++5b60qJJGnVqlWdn//16on/xB/+8IccffTR6du3b6677rrstttu2WabbTJ58uTcdtttG+QcSbJs2bL8v//3/7JixYp1hqPbbrstV1xxxX90lUl9/N97mrxvXZ/rN77xjUyePDnnnntu+vTpkx122CElJSU54YQTUl1dXe9zDxw4MN///vczbdq0nHjiibntttvy+c9/PjvssEO9XwsAALYWogoAAFCrS5cuqampSadOnbLPPvtssvPeddddKSsry/3335/mzZvXrk+ePLnOvj333DPV1dV58cUX60SR9684+XfuvvvurFixIj/+8Y/TunXrOs89++yzGTFiRP74xz/mk5/8ZLp06ZL7778/b7zxxnqvVunSpUuqq6vzzDPPpHv37us970477ZQ333yzztqqVavy2muvFZo7Se68884MGjQo11xzTe3aihUr1nrdLl265Omnn/63r7f//vunR48eufXWW7P77rtnwYIFGT9+fOF5AABga+SeKgAAQK0vfvGLadKkSS699NK1brReU1OTv//97xvlvE2aNElJSUmdKzfmz5+fadOm1dnXr1+/JMl1111XZ71oDLjlllvSuXPnDBkyJF/+8pfrPL71rW+lVatWtfcZ+dKXvpSamppceumla73O+5/NMccck9LS0owePXqtq0X+9fPr0qVLHnzwwTrP//SnP13vlSrr0qRJk7X+mYwfP36t1/jSl76UJ598MlOnTl3v3O875ZRT8pvf/Cbjxo3LLrvsks997nOF5wEAgK2RK1UAAIBaXbp0yeWXX54LLrgg8+fPzzHHHJPtttsuL774YqZOnZrTTjst3/rWtzb4eY866qiMHTs2Rx55ZE466aQsWbIkEyZMyF577ZU///nPtft69uyZL33pSxk3blz+/ve/5+Mf/3h+//vf57nnnkvywTeHf/XVV/O73/0uZ5999jqfb968efr165df/vKX+eEPf5jDDz88p5xySn74wx/mr3/9a4488shUV1fnD3/4Qw4//PAMHTo0e+21Vy666KJcdtllOfTQQ/PFL34xzZs3z5/+9Ke0a9cuY8aMSZKceuqpGTJkSL70pS/ls5/9bJ588sncf//9a10t80E+//nP5+abb84OO+yQrl27ZtasWXnggQeyyy671Nl3/vnn584778xxxx2Xr33ta+nZs2feeOON/OpXv8rEiRPTrVu32r0nnXRSvv3tb2fq1Kk544wz1rpnDgAAUJeoAgAA1DF8+PDss88++cEPflB7lUaHDh1yxBFH5Oijj94o5/z0pz+dG264IVdddVXOPffcdOrUKd/97nczf/78OlElSX7+85+nbdu2uf322zN16tRUVFRkypQp2XfffVNWVrbec9xxxx2prq7OgAED1rtnwIABueuuu3Lffffl6KOPzuTJk3PggQfmhhtuyPnnn58ddtghvXr1yiGHHFJ7zOjRo9OpU6eMHz8+F110UVq2bJkDDzwwp5xySu2ewYMH58UXX8wNN9yQ6dOn59BDD82MGTPymc98pvBndO2116ZJkya59dZbs2LFinziE5/IAw88UHv1zvtatWqVP/zhDxk1alSmTp2am266KW3atMlnPvOZ7L777nX2lpeX54gjjsi9995bZ14AAGDdSmr+7/XfAAAAm5m5c+emR48eueWWW3LyySc39DiblWOPPTZPPfVU4fvSAADA1sw9VQAAgM3Ku+++u9bauHHjUlpamr59+zbARJuv1157Lffcc4+rVAAAoCBf/wUAAGxWvve972X27Nk5/PDD07Rp09x333257777ctppp6VDhw4NPd5m4cUXX8wf//jH/OxnP8s222yT008/vaFHAgCAzYKoAgAAbFYOOeSQzJgxI5dddlnefvvt7LHHHrnkkkty0UUXNfRom43f//73qayszB577JGbbropbdu2beiRAABgs+CeKgAAAAAAAAW4pwoAAAAAAEABogoAAAAAAEABW909Vaqrq/Pqq69mu+22S0lJSUOPAwAAAAAANKCampr885//TLt27VJa+sHXomx1UeXVV19Nhw4dGnoMAAAAAACgEXn55Zez++67f+CerS6qbLfddkn+58PZfvvtG3gaAAAAAACgIS1btiwdOnSo7QcfZKuLKu9/5df2228vqgAAAAAAAElS6JYhblQPAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCbDIPPvhgBgwYkHbt2qWkpCTTpk37t8fMnDkzBx10UJo3b5699torN95440afk82f3zU2Fb9rAPDh+DsU2NL4cw22HqIKsMksX7483bp1y4QJEwrtf/HFF3PUUUfl8MMPz9y5c3Puuefm1FNPzf3337+RJ2Vz53eNTcXvGgB8OP4OBbY0/lyDrUdJTU1NTUMPsSktW7YsO+ywQ956661sv/32DT0ObLVKSkoyderUHHPMMevd853vfCf33HNPnn766dq1E044IW+++WamT5++CaZkS+B3jU3F7xoAfDj+DgW2NP5cg81PfbqBK1WARmvWrFmpqKios9avX7/MmjWrgSZiS+V3jU3F7xoAfDj+DgW2NP5cg82XqAI0WosWLUp5eXmdtfLy8ixbtizvvvtuA03FlsjvGpuK3zUA+HD8HQpsafy5BpsvUQUAAAAAAKAAUQVotNq2bZvFixfXWVu8eHG23377tGjRooGmYkvkd41Nxe8aAHw4/g4FtjT+XIPNl6gCNFp9+vRJVVVVnbUZM2akT58+DTQRWyq/a2wqftcA4MPxdyiwpfHnGmy+GjSqPPjggxkwYEDatWuXkpKSTJs27d8eM3PmzBx00EFp3rx59tprr9x4440bfU5gw3j77bczd+7czJ07N0ny4osvZu7cuVmwYEGS5IILLsjAgQNr9w8ZMiQvvPBCvv3tb2fevHm57rrr8otf/CLnnXdeQ4zPZsTvGpuK3zUA+HD8HQpsafy5BluPBo0qy5cvT7du3TJhwoRC+1988cUcddRROfzwwzN37tyce+65OfXUU3P//fdv5EmBDeHxxx9Pjx490qNHjyTJsGHD0qNHj4wcOTJJ8tprr9X+y0aSdOrUKffcc09mzJiRbt265ZprrsnPfvaz9OvXr0HmZ/Phd41Nxe8aAHw4/g4FtjT+XIOtR0lNTU1NQw+RJCUlJZk6dWqOOeaY9e75zne+k3vuuSdPP/107doJJ5yQN998M9OnTy90nmXLlmWHHXbIW2+9le233/4/HRsAAAAAANiM1acbbFb3VJk1a1YqKirqrPXr1y+zZs1a7zErV67MsmXL6jwAAAAAAADqq2lDD1AfixYtSnl5eZ218vLyLFu2LO+++25atGix1jFjxozJpZdeuqlGhA1qwegDGnoENqE9Rj7VYOf+xPhPNNi52fT++I0/Nti5f9/3sAY7N5veYQ/+vqFHANhi/OWK3zb0CGxCH7no0w09Amx0v/jlwQ09ApvQV457rKFHgA1ms7pS5cO44IIL8tZbb9U+Xn755YYeCQAAAAAA2AxtVleqtG3bNosXL66ztnjx4my//fbrvEolSZo3b57mzZtvivEAAAAAAIAt2GZ1pUqfPn1SVVVVZ23GjBnp06dPA00EAAAAAABsLRo0qrz99tuZO3du5s6dmyR58cUXM3fu3CxYsCDJ/3x118CBA2v3DxkyJC+88EK+/e1vZ968ebnuuuvyi1/8Iuedd15DjA8AAAAAAGxFGjSqPP744+nRo0d69OiRJBk2bFh69OiRkSNHJklee+212sCSJJ06dco999yTGTNmpFu3brnmmmvys5/9LP369WuQ+QEAAAAAgK1Hg95T5VOf+lRqamrW+/yNN964zmOeeOKJjTgVAAAAAADA2jare6oAAAAAAAA0FFEFAAAAAAAaiQkTJqRjx44pKytL796989hjj6137+rVqzN69Oh06dIlZWVl6datW6ZPn15nT8eOHVNSUrLW46yzzqrdc/rpp6dLly5p0aJFdt1113zhC1/IvHnzNtp73JyJKgAAAAAA0AhMmTIlw4YNy6hRozJnzpx069Yt/fr1y5IlS9a5f8SIEfnJT36S8ePH55lnnsmQIUNy7LHH1rmFxp/+9Ke89tprtY8ZM2YkSY477rjaPT179szkyZPzl7/8Jffff39qampyxBFHZM2aNRv3DW+GRBUAAAAAAGgExo4dm8GDB6eysjJdu3bNxIkT07Jly0yaNGmd+2+++eZceOGF6d+/fzp37pwzzjgj/fv3zzXXXFO7Z9ddd03btm1rH7/+9a/TpUuXHHbYYbV7TjvttPTt2zcdO3bMQQcdlMsvvzwvv/xy5s+fv7Hf8mZHVAEAAAAAgAa2atWqzJ49OxUVFbVrpaWlqaioyKxZs9Z5zMqVK1NWVlZnrUWLFnnooYfWe45bbrklX/va11JSUrLOPcuXL8/kyZPTqVOndOjQ4UO+my2XqAIAAAAAAA1s6dKlWbNmTcrLy+usl5eXZ9GiRes8pl+/fhk7dmz++te/prq6OjNmzMjdd9+d1157bZ37p02bljfffDNf/epX13ruuuuuS6tWrdKqVavcd999mTFjRpo1a/Yfv68tjagCAAAAAACboWuvvTZ777139ttvvzRr1ixDhw5NZWVlSkvX/X/933DDDfnc5z6Xdu3arfXcySefnCeeeCK///3vs88+++QrX/lKVqxYsbHfwmZHVAEAAAAAgAbWunXrNGnSJIsXL66zvnjx4rRt23adx+y6666ZNm1ali9fnpdeeinz5s1Lq1at0rlz57X2vvTSS3nggQdy6qmnrvO1dthhh+y9997p27dv7rzzzsybNy9Tp079z9/YFkZUAQAAAACABtasWbP07NkzVVVVtWvV1dWpqqpKnz59PvDYsrKytG/fPu+9917uuuuufOELX1hrz+TJk9OmTZscddRR/3aWmpqa1NTUZOXKlfV/I1u4pg09AAAAAAAAkAwbNiyDBg1Kr169cvDBB2fcuHFZvnx5KisrkyQDBw5M+/btM2bMmCTJo48+moULF6Z79+5ZuHBhLrnkklRXV+fb3/52ndetrq7O5MmTM2jQoDRtWjcLvPDCC5kyZUqOOOKI7LrrrnnllVdy1VVXpUWLFunfv/+meeObEVEFAAAAAAAageOPPz6vv/56Ro4cmUWLFqV79+6ZPn167c3rFyxYUOd+KStWrMiIESPywgsvpFWrVunfv39uvvnm7LjjjnVe94EHHsiCBQvyta99ba1zlpWV5Q9/+EPGjRuXf/zjHykvL0/fvn3z8MMPp02bNhv1/W6ORBUAAAAAAGgkhg4dmqFDh67zuZkzZ9b5+bDDDsszzzzzb1/ziCOOSE1NzTqfa9euXe699956z7m1ck8VAAAAAACAAlypAgAAAADAFqnbnfc39AhsQk9+ud9GP4crVQAAAAAAAAoQVQAAAAAAAAoQVQAAAAAAAAoQVQAAAAAAAAoQVQAAAAAAAAoQVbZAEyZMSMeOHVNWVpbevXvnscceW+/e1atXZ/To0enSpUvKysrSrVu3TJ8+fb37r7rqqpSUlOTcc8+ts75o0aKccsopadu2bbbddtscdNBBueuuu+rsOfroo7PHHnukrKwsu+22W0455ZS8+uqr/9F7BQAAAACATUVU2cJMmTIlw4YNy6hRozJnzpx069Yt/fr1y5IlS9a5f8SIEfnJT36S8ePH55lnnsmQIUNy7LHH5oknnlhr75/+9Kf85Cc/yYEHHrjWcwMHDsyzzz6bX/3qV3nqqafyxS9+MV/5ylfqvM7hhx+eX/ziF3n22Wdz11135W9/+1u+/OUvb7g3DwAAAAAAG5GosoUZO3ZsBg8enMrKynTt2jUTJ05My5YtM2nSpHXuv/nmm3PhhRemf//+6dy5c84444z0798/11xzTZ19b7/9dk4++eRcf/312WmnndZ6nYcffjjf+MY3cvDBB6dz584ZMWJEdtxxx8yePbt2z3nnnZePf/zj2XPPPXPIIYdk+PDheeSRR7J69eoN+yEAAAAAAMBGIKpsQVatWpXZs2enoqKidq20tDQVFRWZNWvWOo9ZuXJlysrK6qy1aNEiDz30UJ21s846K0cddVSd1/5XhxxySKZMmZI33ngj1dXVueOOO7JixYp86lOfWuf+N954I7feemsOOeSQbLPNNvV4lwAAAAAA0DBElS3I0qVLs2bNmpSXl9dZLy8vz6JFi9Z5TL9+/TJ27Nj89a9/TXV1dWbMmJG77747r732Wu2eO+64I3PmzMmYMWPWe+5f/OIXWb16dXbZZZc0b948p59+eqZOnZq99tqrzr7vfOc72XbbbbPLLrtkwYIF+f/+v//vP3jHAAAAAACw6YgqW7lrr702e++9d/bbb780a9YsQ4cOTWVlZUpL/+dX4+WXX84555yTW2+9da0rWv7VxRdfnDfffDMPPPBAHn/88QwbNixf+cpX8tRTT9XZd/755+eJJ57Ib37zmzRp0iQDBw5MTU3NRn2PAAAAAACwITRt6AHYcFq3bp0mTZpk8eLFddYXL16ctm3brvOYXXfdNdOmTcuKFSvy97//Pe3atcvw4cPTuXPnJMns2bOzZMmSHHTQQbXHrFmzJg8++GB+9KMfZeXKlZk/f35+9KMf5emnn85HP/rRJEm3bt3yhz/8IRMmTMjEiRPrzNi6devss88++chHPpIOHTrkkUceSZ8+fTb0xwEAAAAAABuUK1W2IM2aNUvPnj1TVVVVu1ZdXZ2qqqp/Gy3KysrSvn37vPfee7nrrrvyhS98IUnymc98Jk899VTmzp1b++jVq1dOPvnkzJ07N02aNMk777yTJLVXt7yvSZMmqa6uXu85339u5cqVH+r9AgAAAADApuRKlS3MsGHDMmjQoPTq1SsHH3xwxo0bl+XLl6eysjJJMnDgwLRv3772/iiPPvpoFi5cmO7du2fhwoW55JJLUl1dnW9/+9tJku222y77779/nXO8f0+U99f322+/7LXXXjn99NNz9dVXZ5dddsm0adMyY8aM/PrXv649z5/+9Kd88pOfzE477ZS//e1vufjii9OlSxdXqQAAAAAAsFkQVbYwxx9/fF5//fWMHDkyixYtSvfu3TN9+vTam9cvWLCgzhUlK1asyIgRI/LCCy+kVatW6d+/f26++ebsuOOOhc+5zTbb5N57783w4cMzYMCAvP3229lrr71y0003pX///kmSli1b5u67786oUaOyfPny7LbbbjnyyCMzYsSING/efIN+BgAAAAAAsDGIKlugoUOHZujQoet8bubMmXV+Puyww/LMM8/U6/X/72skyd5775277rprvccccMAB+e1vf1uv8wAAAAAAQGPinioAAAAAAAAFuFLlQ+h5/s8begQ2odnfH9jQIwAAAAAA0Ai4UgUAAAAAAKAAUQUAAAAAAKAAUQUAAAAAAKAAUQUAAAAAAKAAUQUAAAAAAKAAUQUAAAAAAKAAUQUAAAAAAKAAUQUAAAAAAKAAUQUAAAAAAKAAUQUAAAAAAKAAUQUAAAAAAKAAUQUAAAAAAKAAUQUAAACAzcKECRPSsWPHlJWVpXfv3nnsscfWu3f16tUZPXp0unTpkrKysnTr1i3Tp0+vs+fBBx/MgAED0q5du5SUlGTatGlrvc4ll1yS/fbbL9tuu2122mmnVFRU5NFHH62zp2PHjikpKanzuOqqqzbIewagcRFVAAAAAGj0pkyZkmHDhmXUqFGZM2dOunXrln79+mXJkiXr3D9ixIj85Cc/yfjx4/PMM89kyJAhOfbYY/PEE0/U7lm+fHm6deuWCRMmrPe8++yzT370ox/lqaeeykMPPZSOHTvmiCOOyOuvv15n3+jRo/Paa6/VPr7xjW9smDcOQKMiqgAAAADQ6I0dOzaDBw9OZWVlunbtmokTJ6Zly5aZNGnSOvfffPPNufDCC9O/f/907tw5Z5xxRvr3759rrrmmds/nPve5XH755Tn22GPXe96TTjopFRUV6dy5cz760Y9m7NixWbZsWf785z/X2bfddtulbdu2tY9tt912w7xxABoVUQUAAACARm3VqlWZPXt2KioqatdKS0tTUVGRWbNmrfOYlStXpqysrM5aixYt8tBDD/1Hc/z0pz/NDjvskG7dutV57qqrrsouu+ySHj165Pvf/37ee++9D30eABqvpg09AAAAAAB8kKVLl2bNmjUpLy+vs15eXp558+at85h+/fpl7Nix6du3b7p06ZKqqqrcfffdWbNmTb3P/+tf/zonnHBC3nnnney2226ZMWNGWrduXfv82WefnYMOOig777xzHn744VxwwQV57bXXMnbs2HqfC4DGTVQBAAAAYItz7bXXZvDgwdlvv/1SUlKSLl26pLKycr1fF/ZBDj/88MydOzdLly7N9ddfn6985St59NFH06ZNmyTJsGHDavceeOCBadasWU4//fSMGTMmzZs332DvCYCG5+u/AAAAAGjUWrdunSZNmmTx4sV11hcvXpy2bduu85hdd90106ZNy/Lly/PSSy9l3rx5adWqVTp37lzv82+77bbZa6+98vGPfzw33HBDmjZtmhtuuGG9+3v37p333nsv8+fPr/e5AGjcRBUAAAAAGrVmzZqlZ8+eqaqqql2rrq5OVVVV+vTp84HHlpWVpX379nnvvfdy11135Qtf+MJ/PE91dXVWrly53ufnzp2b0tLS2itZANhy+PovAAAAABq9YcOGZdCgQenVq1cOPvjgjBs3LsuXL09lZWWSZODAgWnfvn3GjBmTJHn00UezcOHCdO/ePQsXLswll1yS6urqfPvb3659zbfffjvPP/987c8vvvhi5s6dm5133jl77LFHli9fniuuuCJHH310dttttyxdujQTJkzIwoULc9xxxyVJZs2alUcffTSHH354tttuu8yaNSvnnXde/uu//is77bTTJvyEANgURBUAAAAAGr3jjz8+r7/+ekaOHJlFixale/fumT59eu3N6xcsWJDS0v/9UpYVK1ZkxIgReeGFF9KqVav0798/N998c3bcccfaPY8//ngOP/zw2p/fvzfKoEGDcuONN6ZJkyaZN29ebrrppixdujS77LJLPvaxj+UPf/hDPvrRjyZJmjdvnjvuuCOXXHJJVq5cmU6dOuW8886rc58VALYcogoAAAAAm4WhQ4dm6NCh63xu5syZdX4+7LDD8swzz3zg633qU59KTU3Nep8vKyvL3Xff/YGvcdBBB+WRRx75wD0AbDncUwUAAAAAAKAAUQUAAAAAAKAAX/8FAAAAQJLkkksuaegR2IT88waoP1eqAAAAAAAAFCCqAAAAAAAAFCCqAAAAAAAAFCCqAAAAAAAAFCCqAAAAAAAAFCCqAADAJjZhwoR07NgxZWVl6d27dx577LEP3D9u3Ljsu+++adGiRTp06JDzzjsvK1asqH1+zZo1ufjii9OpU6e0aNEiXbp0yWWXXZaampraPW+//XaGDh2a3XffPS1atEjXrl0zceLEtc41a9asfPrTn862226b7bffPn379s2777674d48AADAZqxpQw8AAABbkylTpmTYsGGZOHFievfunXHjxqVfv3559tln06ZNm7X233bbbRk+fHgmTZqUQw45JM8991y++tWvpqSkJGPHjk2SfPe7382Pf/zj3HTTTfnoRz+axx9/PJWVldlhhx1y9tlnJ0mGDRuW3/72t7nlllvSsWPH/OY3v8mZZ56Zdu3a5eijj07yP0HlyCOPzAUXXJDx48enadOmefLJJ1Na6r/FAgAASEQVAADYpMaOHZvBgwensrIySTJx4sTcc889mTRpUoYPH77W/ocffjif+MQnctJJJyVJOnbsmBNPPDGPPvponT1f+MIXctRRR9Xuuf322+tcAfPwww9n0KBB+dSnPpUkOe200/KTn/wkjz32WG1UOe+883L22WfXmWPffffdsB8AAADAZsx/cgYAAJvIqlWrMnv27FRUVNSulZaWpqKiIrNmzVrnMYccckhmz55dG0heeOGF3Hvvvenfv3+dPVVVVXnuueeSJE8++WQeeuihfO5zn6uz51e/+lUWLlyYmpqa/O53v8tzzz2XI444IkmyZMmSPProo2nTpk0OOeSQlJeX57DDDstDDz20wT8HAACAzZUrVQAAYBNZunRp1qxZk/Ly8jrr5eXlmTdv3jqPOemkk7J06dJ88pOfTE1NTd57770MGTIkF154Ye2e4cOHZ9myZdlvv/3SpEmTrFmzJldccUVOPvnk2j3jx4/Paaedlt133z1NmzZNaWlprr/++vTt2zfJ/8SaJLnkkkty9dVXp3v37vn5z3+ez3zmM3n66aez9957b+iPAwAAYLPjShUAAGjEZs6cmSuvvDLXXXdd5syZk7vvvjv33HNPLrvssto9v/jFL3Lrrbfmtttuy5w5c3LTTTfl6quvzk033VS7Z/z48XnkkUfyq1/9KrNnz84111yTs846Kw888ECSpLq6Okly+umnp7KyMj169MgPfvCD7Lvvvpk0adKmfdMAAACNlCtVAABgE2ndunWaNGmSxYsX11lfvHhx2rZtu85jLr744pxyyik59dRTkyQHHHBAli9fntNOOy0XXXRRSktLc/7552f48OE54YQTave89NJLGTNmTAYNGpR33303F154YaZOnVp735UDDzwwc+fOzdVXX52KiorstttuSZKuXbvWOf9HPvKRLFiwYIN+DgAAAJsrV6oAAMAm0qxZs/Ts2TNVVVW1a9XV1amqqkqfPn3Wecw777yT0tK6/9repEmTJElNTc0H7nn/6pPVq1dn9erVH7inY8eOadeuXZ599tk6e5577rnsueee9X2rAAAAWyRXqgAAwCY0bNiwDBo0KL169crBBx+ccePGZfny5amsrEySDBw4MO3bt8+YMWOSJAMGDMjYsWPTo0eP9O7dO88//3wuvvjiDBgwoDauDBgwIFdccUX22GOPfPSjH80TTzyRsWPH5mtf+1qSZPvtt89hhx2W888/Py1atMiee+6Z3//+9/n5z3+esWPHJklKSkpy/vnnZ9SoUenWrVu6d++em266KfPmzcudd97ZAJ8UAABA4yOqAADAJnT88cfn9ddfz8iRI7No0aJ0794906dPr715/YIFC+pcUTJixIiUlJRkxIgRWbhwYXbdddfaiPK+8ePH5+KLL86ZZ56ZJUuWpF27djn99NMzcuTI2j133HFHLrjggpx88sl54403sueee+aKK67IkCFDavece+65WbFiRc4777y88cYb6datW2bMmJEuXbpsgk8GAACg8RNVAABgExs6dGiGDh26zudmzpxZ5+emTZtm1KhRGTVq1Hpfb7vttsu4ceMybty49e5p27ZtJk+e/G9nGz58eIYPH/5v9wEAAGyN3FMFAAAAAACgAFeqAACwxfnRN/9fQ4/AJjT0mgENPQIAALCVcKUKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAaIKAAAAAABAAQ0eVSZMmJCOHTumrKwsvXv3zmOPPfaB+8eNG5d99903LVq0SIcOHXLeeedlxYoVm2haAAAAAABga9WgUWXKlCkZNmxYRo0alTlz5qRbt27p169flixZss79t912W4YPH55Ro0blL3/5S2644YZMmTIlF1544SaeHAAAAAAA2No0aFQZO3ZsBg8enMrKynTt2jUTJ05My5YtM2nSpHXuf/jhh/OJT3wiJ510Ujp27JgjjjgiJ5544r+9ugUAAAAAAOA/1WBRZdWqVZk9e3YqKir+d5jS0lRUVGTWrFnrPOaQQw7J7NmzayPKCy+8kHvvvTf9+/df73lWrlyZZcuW1XkAAAAAAADUV9OGOvHSpUuzZs2alJeX11kvLy/PvHnz1nnMSSedlKVLl+aTn/xkampq8t5772XIkCEf+PVfY8aMyaWXXrpBZwcAAAAAALY+DX6j+vqYOXNmrrzyylx33XWZM2dO7r777txzzz257LLL1nvMBRdckLfeeqv28fLLL2/CiQEAAAAAgC1Fg12p0rp16zRp0iSLFy+us7548eK0bdt2ncdcfPHFOeWUU3LqqacmSQ444IAsX748p512Wi666KKUlq7diJo3b57mzZtv+DcAAAAAAABsVRrsSpVmzZqlZ8+eqaqqql2rrq5OVVVV+vTps85j3nnnnbXCSZMmTZIkNTU1G29YAAAAAABgq9dgV6okybBhwzJo0KD06tUrBx98cMaNG5fly5ensrIySTJw4MC0b98+Y8aMSZIMGDAgY8eOTY8ePdK7d+88//zzufjiizNgwIDauAIAAAAAALAxNGhUOf744/P6669n5MiRWbRoUbp3757p06fX3rx+wYIFda5MGTFiREpKSjJixIgsXLgwu+66awYMGJArrriiod4CAAAAAACwlWjQqJIkQ4cOzdChQ9f53MyZM+v83LRp04waNSqjRo3aBJMBAAAAAAD8rwa7pwoAAAAAAMDmRFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAoQFQBAAAAAAAooMGjyoQJE9KxY8eUlZWld+/eeeyxxz5w/5tvvpmzzjoru+22W5o3b5599tkn99577yaaFgAAAAAA2Fo1bciTT5kyJcOGDcvEiRPTu3fvjBs3Lv369cuzzz6bNm3arLV/1apV+exnP5s2bdrkzjvvTPv27fPSSy9lxx133PTDAwAAAAAAW5UGjSpjx47N4MGDU1lZmSSZOHFi7rnnnkyaNCnDhw9fa/+kSZPyxhtv5OGHH84222yTJOnYseOmHBkAAAAAANhKNdjXf61atSqzZ89ORUXF/w5TWpqKiorMmjVrncf86le/Sp8+fXLWWWelvLw8+++/f6688sqsWbNmvedZuXJlli1bVucBAAAAAABQXw0WVZYuXZo1a9akvLy8znp5eXkWLVq0zmNeeOGF3HnnnVmzZk3uvffeXHzxxbnmmmty+eWXr/c8Y8aMyQ477FD76NChwwZ9HwAAAAAAwNahwW9UXx/V1dVp06ZNfvrTn6Znz545/vjjc9FFF2XixInrPeaCCy7IW2+9Vft4+eWXN+HEAAAAAADAlqLB7qnSunXrNGnSJIsXL66zvnjx4rRt23adx+y2227ZZptt0qRJk9q1j3zkI1m0aFFWrVqVZs2arXVM8+bN07x58w07PAAAAAAAsNVpsCtVmjVrlp49e6aqqqp2rbq6OlVVVenTp886j/nEJz6R559/PtXV1bVrzz33XHbbbbd1BhUAAAAAAIANpUG//mvYsGG5/vrrc9NNN+Uvf/lLzjjjjCxfvjyVlZVJkoEDB+aCCy6o3X/GGWfkjTfeyDnnnJPnnnsu99xzT6688sqcddZZDfUWAAAAAACArUSDff1Xkhx//PF5/fXXM3LkyCxatCjdu3fP9OnTa29ev2DBgpSW/m/36dChQ+6///6cd955OfDAA9O+ffucc845+c53vtNQbwEAAAAAANhKNGhUSZKhQ4dm6NCh63xu5syZa6316dMnjzzyyEaeCgAAAAAAoK4G/fovAAAAAACAzYWoAgAAAAAAUICoAgAAAAAAUICoAgAAAAAAUICoAgAAAAAAUICoAgAAAAAAUICoAgAAAAAAUICoAgAAAAAAUICoAgAAAAAAUICoAgAAAAAAUICoAgAAAAAAUICoAgAAAAAAUICoAgAAAAAAUICoAgAAAAAAUICoAgAAAAAAUICoAgAAAAAAUICoAgAAAAAAUICoAgAAAAAAUICoAgAAAAAAUEC9o0rHjh0zevToLFiwYGPMAwAAAAAA0CjVO6qce+65ufvuu9O5c+d89rOfzR133JGVK1dujNkAAAAAAAAajQ8VVebOnZvHHnssH/nIR/KNb3wju+22W4YOHZo5c+ZsjBkBAAAAAAAa3Ie+p8pBBx2UH/7wh3n11VczatSo/OxnP8vHPvaxdO/ePZMmTUpNTc2GnBMAAAAAAKBBNf2wB65evTpTp07N5MmTM2PGjHz84x/P17/+9bzyyiu58MIL88ADD+S2227bkLMCAAAAAAA0mHpHlTlz5mTy5Mm5/fbbU1pamoEDB+YHP/hB9ttvv9o9xx57bD72sY9t0EEBAAAAAAAaUr2jysc+9rF89rOfzY9//OMcc8wx2Wabbdba06lTp5xwwgkbZEAAAAAAAIDGoN5R5YUXXsiee+75gXu23XbbTJ48+UMPBQAAAAAA0NjU+0b1S5YsyaOPPrrW+qOPPprHH398gwwFAAAAAADQ2NQ7qpx11ll5+eWX11pfuHBhzjrrrA0yFAAAAAAAQGNT76jyzDPP5KCDDlprvUePHnnmmWc2yFAAAAAAAACNTb2jSvPmzbN48eK11l977bU0bVrvW7QAAAAAAABsFuodVY444ohccMEFeeutt2rX3nzzzVx44YX57Gc/u0GHAwAAAAAAaCzqfWnJ1Vdfnb59+2bPPfdMjx49kiRz585NeXl5br755g0+IAAAAAAAQGNQ76jSvn37/PnPf86tt96aJ598Mi1atEhlZWVOPPHEbLPNNhtjRgAAAAAAgAb3oW6Csu222+a0007b0LMAAAAAAAA0Wh/6zvLPPPNMFixYkFWrVtVZP/roo//joQAAAAAAABqbekeVF154Iccee2yeeuqplJSUpKamJklSUlKSJFmzZs2GnRAAAAAAAKARKK3vAeecc046deqUJUuWpGXLlvnv//7vPPjgg+nVq1dmzpy5EUYEAAAAAABoePW+UmXWrFn57W9/m9atW6e0tDSlpaX55Cc/mTFjxuTss8/OE088sTHmBAAAAAAAaFD1vlJlzZo12W677ZIkrVu3zquvvpok2XPPPfPss89u2OkAAAAAAAAaiXpfqbL//vvnySefTKdOndK7d+9873vfS7NmzfLTn/40nTt33hgzAgAAAAAANLh6R5URI0Zk+fLlSZLRo0fn85//fA499NDssssumTJlygYfEAAAAAAAoDGod1Tp169f7f/ea6+9Mm/evLzxxhvZaaedUlJSskGHAwAAAAAAaCzqdU+V1atXp2nTpnn66afrrO+8886CCgAAAAAAsEWrV1TZZpttsscee2TNmjUbax4AAAAAAIBGqV5RJUkuuuiiXHjhhXnjjTc2xjwAAAAAAACNUr3vqfKjH/0ozz//fNq1a5c999wz2267bZ3n58yZs8GGAwAAAAAAaCzqHVWOOeaYjTAGAAAAAABA41bvqDJq1KiNMQcAAAAAAECjVu97qgAAAAAAAGyN6n2lSmlpaUpKStb7/Jo1a/6jgQAAAAAAABqjekeVqVOn1vl59erVeeKJJ3LTTTfl0ksv3WCDAQAAAAAANCb1jipf+MIX1lr78pe/nI9+9KOZMmVKvv71r2+QwQAAAAAAABqTDXZPlY9//OOpqqraUC8HAAAAAADQqGyQqPLuu+/mhz/8Ydq3b78hXg4AAAAAAKDRqffXf+200051blRfU1OTf/7zn2nZsmVuueWWDTocAAAAAABAY1HvqPKDH/ygTlQpLS3Nrrvumt69e2ennXbaoMMBAAAAAAA0FvWOKl/96lc3whgAAAAAAACNW73vqTJ58uT88pe/XGv9l7/8ZW666aYNMhQAAAAAAEBjU++oMmbMmLRu3Xqt9TZt2uTKK6/cIEMBAAAAAAA0NvWOKgsWLEinTp3WWt9zzz2zYMGCDTIUAAAAAABAY1PvqNKmTZv8+c9/Xmv9ySefzC677LJBhgIAAAAAAGhs6h1VTjzxxJx99tn53e9+lzVr1mTNmjX57W9/m3POOScnnHDCxpgRAAAAAACgwTWt7wGXXXZZ5s+fn8985jNp2vR/Dq+urs7AgQPdUwUAAAAAANhi1TuqNGvWLFOmTMnll1+euXPnpkWLFjnggAOy5557boz5AAAAAAAAGoV6R5X37b333tl777035CwAAAAAAACNVr3vqfKlL30p3/3ud9da/973vpfjjjtugwwFAAAAAADQ2NQ7qjz44IPp37//Wuuf+9zn8uCDD26QoQAAAAAAABqbekeVt99+O82aNVtrfZtttsmyZcs2yFAAAAAAAACNTb2jygEHHJApU6astX7HHXeka9euG2QoAAAAAACAxqbeN6q/+OKL88UvfjF/+9vf8ulPfzpJUlVVldtuuy133nnnBh8QAAAAAACgMah3VBkwYECmTZuWK6+8MnfeeWdatGiRbt265be//W123nnnjTEjAAAAAABAg6t3VEmSo446KkcddVSSZNmyZbn99tvzrW99K7Nnz86aNWs26IAAAAAAAACNQb3vqfK+Bx98MIMGDUq7du1yzTXX5NOf/nQeeeSRDTkbAAAAAABAo1GvK1UWLVqUG2+8MTfccEOWLVuWr3zlK1m5cmWmTZvmJvUAAAAAAMAWrfCVKgMGDMi+++6bP//5zxk3blxeffXVjB8/fmPOBgAAAAAA0GgUvlLlvvvuy9lnn50zzjgje++998acCQAAAAAAoNEpfKXKQw89lH/+85/p2bNnevfunR/96EdZunTpxpwNAAAAAACg0SgcVT7+8Y/n+uuvz2uvvZbTTz89d9xxR9q1a5fq6urMmDEj//znPzfmnAAAAAAAAA2qcFR537bbbpuvfe1reeihh/LUU0/lm9/8Zq666qq0adMmRx999MaYEQAAAAAAoMHVO6r8q3333Tff+9738sorr+T222/fUDMBAAAAAAA0Ov9RVHlfkyZNcswxx+RXv/rVhng5AAAAAACARmeDRBUAAAAAAIAtnagCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQgKgCAAAAAABQQKOIKhMmTEjHjh1TVlaW3r1757HHHit03B133JGSkpIcc8wxG3dAAAAAAABgq9fgUWXKlCkZNmxYRo0alTlz5qRbt27p169flixZ8oHHzZ8/P9/61rdy6KGHbqJJAQAAAACArVmDR5WxY8dm8ODBqaysTNeuXTNx4sS0bNkykyZNWu8xa9asycknn5xLL700nTt33oTTAgAAAAAAW6sGjSqrVq3K7NmzU1FRUbtWWlqaioqKzJo1a73HjR49Om3atMnXv/71f3uOlStXZtmyZXUeAAAAAAAA9dWgUWXp0qVZs2ZNysvL66yXl5dn0aJF6zzmoYceyg033JDrr7++0DnGjBmTHXbYofbRoUOH/3huAAAAAABg69PgX/9VH//85z9zyimn5Prrr0/r1q0LHXPBBRfkrbfeqn28/PLLG3lKAAAAAABgS9S0IU/eunXrNGnSJIsXL66zvnjx4rRt23at/X/7298yf/78DBgwoHaturo6SdK0adM8++yz6dKlS51jmjdvnubNm2+E6QEAAAAAgK1Jg16p0qxZs/Ts2TNVVVW1a9XV1amqqkqfPn3W2r/ffvvlqaeeyty5c2sfRx99dA4//PDMnTvXV3sBAAAAAAAbTYNeqZIkw4YNy6BBg9KrV68cfPDBGTduXJYvX57KysokycCBA9O+ffuMGTMmZWVl2X///escv+OOOybJWusAAAAAAAAbUoNHleOPPz6vv/56Ro4cmUWLFqV79+6ZPn167c3rFyxYkNLSzerWLwAAAAAAwBaowaNKkgwdOjRDhw5d53MzZ878wGNvvPHGDT8QAAAAAADA/+ESEAAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAJEFQAAAAAAgAIaRVSZMGFCOnbsmLKysvTu3TuPPfbYevdef/31OfTQQ7PTTjtlp512SkVFxQfuBwAAAAAA2BAaPKpMmTIlw4YNy6hRozJnzpx069Yt/fr1y5IlS9a5f+bMmTnxxBPzu9/9LrNmzUqHDh1yxBFHZOHChZt4cgAAAAAAYGvS4FFl7NixGTx4cCorK9O1a9dMnDgxLVu2zKRJk9a5/9Zbb82ZZ56Z7t27Z7/99svPfvazVFdXp6qqahNPDgAAAAAAbE0aNKqsWrUqs2fPTkVFRe1aaWlpKioqMmvWrEKv8c4772T16tXZeeed1/n8ypUrs2zZsjoPAAAAAACA+mrQqLJ06dKsWbMm5eXlddbLy8uzaNGiQq/xne98J+3atasTZv7VmDFjssMOO9Q+OnTo8B/PDQAAAAAAbH0a/Ou//hNXXXVV7rjjjkydOjVlZWXr3HPBBRfkrbfeqn28/PLLm3hKAAAAAABgS9C0IU/eunXrNGnSJIsXL66zvnjx4rRt2/YDj7366qtz1VVX5YEHHsiBBx643n3NmzdP8+bNN8i8AAAAAADA1qtBr1Rp1qxZevbsWecm8+/fdL5Pnz7rPe573/teLrvsskyfPj29evXaFKMCAAAAAABbuQa9UiVJhg0blkGDBqVXr145+OCDM27cuCxfvjyVlZVJkoEDB6Z9+/YZM2ZMkuS73/1uRo4cmdtuuy0dO3asvfdKq1at0qpVqwZ7HwAAAAAAwJatwaPK8ccfn9dffz0jR47MokWL0r1790yfPr325vULFixIaen/XlDz4x//OKtWrcqXv/zlOq8zatSoXHLJJZtydAAAAAAAYCvS4FElSYYOHZqhQ4eu87mZM2fW+Xn+/PkbfyAAAAAAAID/o0HvqQIAAAAAALC5EFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAAAAAAAKEFUAAACoY8KECenYsWPKysrSu3fvPPbYYx+4/5e//GX222+/lJWV5YADDsi99967iSYFAIBNS1QBAACg1pQpUzJs2LCMGjUqc+bMSbdu3dKvX78sWbJknfsffvjhnHjiifn617+eJ554Isccc0yOOeaYPP3005t4cgAA2PhEFQAAAGqNHTs2gwcPTmVlZbp27ZqJEyemZcuWmTRp0jr3X3vttTnyyCNz/vnn5yMf+Uguu+yyHHTQQfnRj360iScHAICNT1QBAAAgSbJq1arMnj07FRUVtWulpaWpqKjIrFmz1nnMrFmz6uxPkn79+q13PwAAbM5EFQAAAJIkS5cuzZo1a1JeXl5nvby8PIsWLVrnMYsWLarXfgAA2JyJKgAAAAAAAAWIKgAAACRJWrdunSZNmmTx4sV11hcvXpy2bduu85i2bdvWaz8AAGzORBUAAACSJM2aNUvPnj1TVVVVu1ZdXZ2qqqr06dNnncf06dOnzv4kmTFjxnr3AwDA5qxpQw8AAABA4zFs2LAMGjQovXr1ysEHH5xx48Zl+fLlqaysTJIMHDgw7du3z5gxY5Ik55xzTg477LBcc801Oeqoo3LHHXfk8ccfz09/+tOGfBsAALBRNIorVSZMmJCOHTumrKwsvXv3zmOPPfaB+3/5y19mv/32S1lZWQ444IDce++9m2hSAACALdvxxx+fq6++OiNHjkz37t0zd+7cTJ8+vfZm9AsWLMhrr71Wu/+QQw7Jbbfdlp/+9Kfp1q1b7rzzzkybNi37779/Q70FAADYaBr8SpUpU6Zk2LBhmThxYnr37p1x48alX79+efbZZ9OmTZu19j/88MM58cQTM2bMmHz+85/PbbfdlmOOOSZz5szxL+0AAAAbwNChQzN06NB1Pjdz5sy11o477rgcd9xxG3kqAABoeA1+pcrYsWMzePDgVFZWpmvXrpk4cWJatmyZSZMmrXP//9/evQdVdZ19HP+do3IRgxdMRK1AU+SmNcaKLRgH1KZoG6JWDSitEmzVRiMOJCFGUZTYWK+YaKlGG2xHEi+xFmtiaohxEqpGGLxVRGq9zVTjNVHQYOTs948O5/VUUFA424Pfzwwz7rXX2udZzOPasBZ77aVLl2rQoEF6+eWXFRoaqszMTPXq1UvLli1zcuQAAAAAAAAAAOBhYuqTKjdu3FBRUZGmTZtmL7Narfrxj3+sXbt21dhm165dSklJcSiLiYnR5s2ba6xfWVmpyspK+/HXX38tSbpy5co9x11Vef2e28L13E+u3K+r31SZ9tlwPjNz7eb1m6Z9NpzPzFyruEmuPUzMzLXrlddM+2w4n5m5BjhL+TcVZocAJzJzXLt1DgVNn5m5du0acx4PEzNzreoa99CHyb3mWnU7wzDuWtfURZULFy6oqqrKvjdvtQ4dOujIkSM1tjl79myN9c+ePVtj/TfeeEOzZ8++rbxLly73GDUeNq3fmmh2CHhYvNHa7AjwkGidRq7BSVqTa3COV5abHQEANLDXzQ4AD4t58+aZHQIeEs8n8rsBnON+M+3q1atqfZffZU1/p0pjmzZtmsOTLTabTZcuXZKPj48sFouJkbmWK1euqEuXLjp9+rS8vb3NDgdNGLkGZyHX4CzkGpyFXIOzkGtwFnINzkKuwVnINTgLuVZ/hmHo6tWr6tSp013rmrqo0r59ezVr1kxffvmlQ/mXX34pX1/fGtv4+vrWq767u7vc3d0dytq0aXPvQT/kvL29+Y8IpyDX4CzkGpyFXIOzkGtwFnINzkKuwVnINTgLuQZnIdfq525PqFQz9UX1bm5u+sEPfqD8/Hx7mc1mU35+viIiImpsExER4VBfkrZv315rfQAAAAAAAAAAgIZg+vZfKSkpGjt2rHr37q0+ffooKytLFRUVev755yVJY8aMUefOnfXGG29IkpKTkxUVFaVFixbpZz/7md577z0VFhZq5cqVZnYDAAAAAAAAAAA0caYvqsTFxen8+fOaOXOmzp49q549e2rbtm32l9GfOnVKVuv/P1ATGRmp3NxczZgxQ6+99pq6du2qzZs3q3v37mZ14aHg7u6uWbNm3baVGtDQyDU4C7kGZyHX4CzkGpyFXIOzkGtwFnINzkKuwVnItcZlMQzDMDsIAAAAAAAAAACAB52p71QBAAAAAAAAAABwFSyqAAAAAAAAAAAA1AGLKgAAAAAAAAAAAHXAogruyYkTJ2SxWLRv374ajwGgqYmOjtbUqVPNDgMAAAAAAKBOmLNtHM3NDgBNQ5cuXXTmzBm1b9/e7FAAoFFs2rRJLVq0MDsMAAAAAEATk5OTo6lTp+qrr74yOxQAdcCiChpEs2bN5Ovra3YYANBo2rVrZ3YIcDE3btyQm5ub2WEAAOByuIcCeJh8++23ZocAoJ7Y/guSpG3btumpp55SmzZt5OPjo2eeeUbHjh2zn//iiy/05JNPysPDQ71791ZxcbFDex4lQ0Ow2WyaP3++AgMD5e7uLj8/P82dO9fssOAi7pQ/Bw8e1IABA+Tp6SkfHx+NHz9e5eXl9raJiYkaOnSoFi5cqI4dO8rHx0eTJk1y+OGW7b8QHR2tyZMna/LkyWrdurXat2+v9PR0GYYhSQoICFBmZqbGjBkjb29vjR8/XpL0+eefq1+/fvL09FSXLl00ZcoUVVRU2K9b3W7UqFHy8vJS586dtXz5clP6iAdfdHS0pkyZoldeeUXt2rWTr6+vMjIy7OctFotWrVqlYcOGqWXLluratavy8vLMCxhNyt3GQaA293oPff/999WtWze5u7srICBAixYtcrhuQECAfvvb3yopKUmPPPKI/Pz8tHLlSqf3D65p5cqV6tSpk2w2m0P5kCFDlJSUZFJUaAruNMdWPX+2bt06RUVFycPDQ2vXrtXzzz+vr7/+WhaLRRaLxeHnO+BW9zOHa7PZ9J3vfEfZ2dkO1ywuLpbVatXJkyed1g9Xx6IKJEkVFRVKSUlRYWGh8vPzZbVaNWzYMNlsNpWXl+uZZ55RWFiYioqKlJGRoZdeesnskNEETZs2TfPmzVN6eroOHz6s3NxcdejQweyw4CJqy5+KigrFxMSobdu22rt3rzZs2KCPP/5YkydPdmi/Y8cOHTt2TDt27NCaNWuUk5OjnJwcczqDB9aaNWvUvHlzffHFF1q6dKkWL16sVatW2c8vXLhQTzzxhIqLi5Wenq5jx45p0KBBGj58uA4cOKB169bp888/vy3/FixYYG/36quvKjk5Wdu3b3d29+Ai1qxZIy8vL+3Zs0fz58/XnDlzHPJl9uzZeu6553TgwAH99Kc/VUJCgi5dumRixGhK7jYOArWp7z20qKhIzz33nOLj43Xw4EFlZGQoPT39tp/PFi1aZJ80euGFF/Sb3/xGpaWlTu4dXNHIkSN18eJF7dixw1526dIlbdu2TQkJCSZGBld3pzm2atU/85eUlKh///7KysqSt7e3zpw5ozNnzjDvhlrdzxyu1WrVqFGjlJub63DNtWvXqm/fvvL393d2d1yXAdTg/PnzhiTj4MGDxooVKwwfHx/j+vXr9vPZ2dmGJKO4uNgwDMM4fvy4wzFQX1euXDHc3d2Nt99+2+xQ4ILulD8rV6402rZta5SXl9vLtm7dalitVuPs2bOGYRjG2LFjDX9/f+PmzZv2OiNHjjTi4uLsx1FRUUZycnLjdQIPvKioKCM0NNSw2Wz2srS0NCM0NNQwDMPw9/c3hg4d6tBm3Lhxxvjx4x3KPvvsM8Nqtdrvq/7+/sagQYMc6sTFxRmDBw9ujG7AxUVFRRlPPfWUQ1l4eLiRlpZmGIZhSDJmzJhhP1deXm5IMj788EOnxomm6W7jIFCbe7mHjh492nj66acdyl5++WUjLCzMfuzv72/84he/sB/bbDbjscceM7KzsxujG2iChgwZYiQlJdmPV6xYYXTq1MmoqqoyMSo0NbfOsVXPn2VlZTnUeeedd4zWrVubEyBcWn3ncIuLiw2LxWKcPHnSMAzDqKqqMjp37sy9s554UgWSpLKyMo0aNUqPP/64vL29FRAQIEk6deqUSkpK1KNHD3l4eNjrR0REmBQpmqqSkhJVVlZq4MCBZocCF3Sn/CkpKdETTzwhLy8ve1nfvn1ls9kc/oqxW7duatasmf24Y8eOOnfuXOMGDpfzox/9SBaLxX4cERGhsrIyVVVVSZJ69+7tUH///v3KyclRq1at7F8xMTGy2Ww6fvy4w3VuFRERoZKSkkbsCVxZjx49HI7/d7y69byXl5e8vb0Zz9Bg7jYOArWp7z20pKREffv2dSjr27fvbfl265hnsVjk6+vLmIc6S0hI0Pvvv6/KykpJ//1r7fj4eFmtTJfh3t1pjq3a/455QF3d7xxuz549FRoaan9aZefOnTp37pxGjhzptD40BbyoHpKk2NhY+fv76+2337bvKdq9e3fduHHD7NDwkPD09DQ7BLiwhsifFi1aOBxbLJbb9lcG7ubWxTtJKi8v14QJEzRlypTb6vr5+TkrLDQxdxuvGM8AuKL/vYfWFWMe7kdsbKwMw9DWrVsVHh6uzz77TEuWLDE7LLi4usyx3euYBzTEHG5CQoJyc3P16quvKjc3V4MGDZKPj08jRt30sPQOXbx4UaWlpZoxY4YGDhyo0NBQXb582X4+NDRUBw4c0DfffGMv2717txmhognr2rWrPD09lZ+fb3YocEF3yp/Q0FDt37/f4cXgBQUFslqtCg4OdmaYaAL27NnjcLx792517drV4SmnW/Xq1UuHDx9WYGDgbV9ubm4O1/nf64aGhjZ8BwDgPtV3HASq1Td3QkNDVVBQ4FBWUFCgoKAg8g0NxsPDQz//+c+1du1avfvuuwoODlavXr3MDgsu7G5zbLVxc3PjqU/cVUPN4Y4ePVqHDh1SUVGRNm7cyHuk7gGLKlDbtm3l4+OjlStX6l//+pc++eQTpaSk2M+PHj1aFotFv/71r3X48GF98MEHWrhwoYkRoyny8PBQWlqaXnnlFf3pT3/SsWPHtHv3bq1evdrs0OAC7pQ/CQkJ8vDw0NixY3Xo0CHt2LFDL774on75y1+qQ4cOZocOF3Pq1CmlpKSotLRU7777rt566y0lJyfXWj8tLU3/+Mc/NHnyZO3bt09lZWX661//etuL6gsKCjR//nwdPXpUy5cv14YNG+54XQAwS33HQaBafXMnNTVV+fn5yszM1NGjR7VmzRotW7aMlzejwSUkJGjr1q364x//yMQi7tvd5thqExAQoPLycuXn5+vChQu6du2aE6KFq2moOdyAgABFRkZq3Lhxqqqq0rPPPuvMbjQJbP8FWa1Wvffee5oyZYq6d++u4OBgvfnmm4qOjpYktWrVSlu2bNHEiRP15JNPKiwsTL/73e80fPhwcwNHk5Oenq7mzZtr5syZ+s9//qOOHTtq4sSJZocFF1Fb/rRs2VIfffSRkpOTFR4erpYtW2r48OFavHix2SHDBY0ZM0bXr19Xnz591KxZMyUnJ2v8+PG11u/Ro4d27typ6dOnq1+/fjIMQ9/73vcUFxfnUC81NVWFhYWaPXu2vL29tXjxYsXExDR2dwCg3uo7DgLV6ps7vXr10vr16zVz5kxlZmaqY8eOmjNnjhITE50XNB4KAwYMULt27VRaWqrRo0ebHQ5c3N3m2GoTGRmpiRMnKi4uThcvXtSsWbOUkZHhlJjhOhpyDjchIUEvvPCCxowZw5b898BiGIZhdhBwfaWlpQoJCVFZWZkCAwPNDgcAGlxERIQGDhyo119/3exQYJLo6Gj17NlTWVlZDXrdgIAATZ06VVOnTm3Q6wJAQ2uscRBNH7kDAACaErb/wn27dOmSNm7cKG9vb3Xp0sXscACgQVVWVqqwsFD//Oc/1a1bN7PDAQAAAAAAgInY/gv3bdy4cSoqKlJ2drbc3d3NDgcAGtSHH36oMWPG6Nlnn9WIESPMDgcAAAAAAAAmYvsvAAAAAAAAAACAOmD7LwAAAAAAAAAAgDpgUQUAAAAAAAAAAKAOWFQBAAAAAAAAAACoAxZVAAAAAAAAAAAA6oBFFQAAAAAAAAAAgDpgUQUAAAAAAAAAAKAOWFQBAAAA8MBJTEyUxWKRxWKRm5ubAgMDNWfOHN28edNep6qqSkuWLNH3v/99eXh4qG3btho8eLAKCgocrlVVVaV58+YpJCREnp6eateunX74wx9q1apVtX5+Tk6O2rRp01jdAwAAAOCimpsdAAAAAADUZNCgQXrnnXdUWVmpDz74QJMmTVKLFi00bdo0GYah+Ph4ffzxx1qwYIEGDhyoK1euaPny5YqOjtaGDRs0dOhQSdLs2bO1YsUKLVu2TL1799aVK1dUWFioy5cvm9tBAAAAAC7HYhiGYXYQAAAAAHCrxMREffXVV9q8ebO97Cc/+YmuXr2qXbt2ad26dYqPj1deXp5iY2Md2g4fPlw7d+7UyZMn5eXlpZ49e2rYsGGaNWtWnT77008/Vf/+/R3KZs2apYyMDP35z3/W0qVLVVpaKi8vLw0YMEBZWVl67LHH7HXz8vKUmpqq06dPKyIiQomJiUpMTNTly5d5+gUAAABwcWz/BQAAAMAleHp66saNG5Kk3NxcBQUF3bagIkmpqam6ePGitm/fLkny9fXVJ598ovPnz9fpcyIjI5WVlSVvb2+dOXNGZ86c0UsvvSRJ+vbbb5WZman9+/dr8+bNOnHihBITE+1tjx8/rhEjRmjo0KHav3+/JkyYoOnTp99nzwEAAAA8KNj+CwAAAMADzTAM5efn66OPPtKLL74oSTp69KhCQ0NrrF9dfvToUUnS4sWLNWLECPn6+qpbt26KjIzUkCFDNHjw4Brbu7m5qXXr1rJYLPL19XU4l5SUZP/3448/rjfffFPh4eEqLy9Xq1attGLFCgUHB2vBggWSpODgYB06dEhz5869v28CAAAAgAcCT6oAAAAAeCD97W9/U6tWreTh4aHBgwcrLi5OGRkZ9vN13ck4LCxMhw4d0u7du5WUlKRz584pNjZWv/rVr+odU1FRkWJjY+Xn56dHHnlEUVFRkqRTp05JkkpLSxUeHu7Qpk+fPvX+HAAAAAAPJhZVAAAAADyQ+vfvr3379qmsrEzXr1/XmjVr5OXlJUkKCgpSSUlJje2qy4OCguxlVqtV4eHhmjp1qjZt2qScnBytXr1ax48fr3M8FRUViomJkbe3t9auXau9e/fqL3/5iyTZtyUDAAAA0LSxqAIAAADggeTl5aXAwED5+fmpeXPHnYvj4+NVVlamLVu23NZu0aJF8vHx0dNPP13rtcPCwiT9d6GkJm5ubqqqqnIoO3LkiC5evKh58+apX79+CgkJ0blz5xzqBAcHq7Cw0KFs7969tXcSAAAAgEthUQUAAACAy4mPj9ewYcM0duxYrV69WidOnNCBAwc0YcIE5eXladWqVfanWkaMGKElS5Zoz549OnnypD799FNNmjRJQUFBCgkJqfH6AQEBKi8vV35+vi5cuKBr167Jz89Pbm5ueuutt/Tvf/9beXl5yszMdGg3YcIEHTlyRGlpaTp69KjWr1+vnJwcSZLFYmnU7wkAAACAxseiCgAAAACXY7FYtH79er322mtasmSJgoOD1a9fP/uiydChQ+11Y2JitGXLFsXGxiooKEhjx45VSEiI/v73v9/2BEy1yMhITZw4UXFxcXr00Uc1f/58Pfroo8rJydGGDRsUFhamefPmaeHChQ7tvvvd72rjxo3atGmTevTooezsbE2fPl2S5O7u3mjfDwAAAADOYTHq+nZHAAAAAEC9zZ07V3/4wx90+vRps0MBAAAAcJ9q/rMsAAAAAMA9+f3vf6/w8HD5+PiooKBACxYs0OTJk80OCwAAAEADYFEFAAAAABpQWVmZXn/9dV26dEl+fn5KTU3VtGnTzA4LAAAAQANg+y8AAAAAAAAAAIA64EX1AAAAAAAAAAAAdcCiCgAAAAAAAAAAQB2wqAIAAAAAAAAAAFAHLKoAAAAAAAAAAADUAYsqAAAAAAAAAAAAdcCiCgAAAAAAAAAAQB2wqAIAAAAAAAAAAFAHLKoAAAAAAAAAAADUwf8B2WVH2ECgvd4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate predictions for the test set\n",
    "predictions = model.predict([word_test, tag_test], verbose=0)\n",
    "\n",
    "# Convert predictions to lemmas\n",
    "predicted_lemmas = [decode_word(pred) for pred in predictions]\n",
    "\n",
    "total_counter = {}\n",
    "correct_counter = {}\n",
    "accuracies = {}\n",
    "\n",
    "tags = set()\n",
    "\n",
    "for t in tag_list:\n",
    "    t = t.split(\"_\")[0]\n",
    "    total_counter[t] = 0\n",
    "    correct_counter[t] = 0\n",
    "\n",
    "# Compare predictions to actual lemmas\n",
    "for i, lemma in enumerate(predicted_lemmas):\n",
    "    tag = tag_list[i].split(\"_\")[0]\n",
    "    tags.add(tag)\n",
    "    total_counter[tag] += 1\n",
    "    if lemma == decode_word(y_test[i]):\n",
    "        correct_counter[tag] += 1\n",
    "\n",
    "    if tag == \"nan\":\n",
    "        print(\"### Tag is nan for word\", decode_word(word_test[i]))\n",
    "\n",
    "# Calculate accuracy\n",
    "for t in tags:\n",
    "    accuracies[t] = round(correct_counter[t]/total_counter[t], 4)\n",
    "\n",
    "# accuracies plot\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.barplot(x=list(accuracies.keys()), y=list(accuracies.values()))\n",
    "for index, value in enumerate(list(accuracies.values())):\n",
    "    plt.text(index, value, str(value), ha=\"center\", va=\"bottom\")\n",
    "plt.title(\"Per Tag Accuracy\")\n",
    "plt.xlabel(\"POS tag\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Word: ['frattura                  ']\n",
      "### Tag: ['nn']\n",
      "### Lemma: ['frattura                  ']\n",
      "### Lemma prediction: ['frattura                  ']\n"
     ]
    }
   ],
   "source": [
    "# try the model with an example\n",
    "n = np.random.randint(0, len(word_test))\n",
    "word = word_test[n]\n",
    "tag = tag_test[n]\n",
    "y = y_test[n]\n",
    "\n",
    "print(\"### Word:\", decode_word(word))\n",
    "print(\"### Tag:\", tag_enc.inverse_transform([tag])[0])\n",
    "print(\"### Lemma:\", decode_word(y))\n",
    "\n",
    "prediction = model.predict([np.array([word]), np.array([tag])], verbose=0)\n",
    "print(\"### Lemma prediction:\", decode_word(prediction[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:25:29) [Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08eac26dc1f80337b7d87e94e7159a5bad95c2e85f47efef91c61359b3afbfe9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
