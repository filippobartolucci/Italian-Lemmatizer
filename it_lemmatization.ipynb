{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### DF shape: (5113, 3)\n",
      "\n",
      "### NaN values:\n",
      "word    0\n",
      "tag     0\n",
      "lemm    0\n",
      "dtype: int64\n",
      "\n",
      "### DF shape after removing rows where tag is nan: (5113, 3)\n",
      "\n",
      "### Unique values:\n",
      "word    5113\n",
      "tag       31\n",
      "lemm    3952\n",
      "dtype: int64\n",
      "\n",
      "### Number of word that are equals to lemm:\n",
      "2886\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "      <th>lemm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mi</td>\n",
       "      <td>pron_per</td>\n",
       "      <td>mi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>riferisco</td>\n",
       "      <td>v_gvrb</td>\n",
       "      <td>riferire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>al</td>\n",
       "      <td>prep_a</td>\n",
       "      <td>al</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lavoro</td>\n",
       "      <td>nn</td>\n",
       "      <td>lavoro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dove</td>\n",
       "      <td>conj_s</td>\n",
       "      <td>dove</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word       tag      lemm\n",
       "1         mi  pron_per        mi\n",
       "2  riferisco    v_gvrb  riferire\n",
       "3         al    prep_a        al\n",
       "4     lavoro        nn    lavoro\n",
       "5       dove    conj_s      dove"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Embedding, Concatenate, Bidirectional, TimeDistributed, RepeatVector, Activation, Dot, Lambda\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "dataset_path = \"./out.csv\"\n",
    "df = pd.read_csv(dataset_path, sep=\"\\t\", header=None, names=[\"word\", \"tag\", \"lemm\"])\n",
    "\n",
    "df[\"word\"] = df[\"word\"].astype(str) \n",
    "df[\"tag\"] = df[\"tag\"].astype(str)\n",
    "df[\"lemm\"] = df[\"lemm\"].astype(str)\n",
    "\n",
    "# remove duplicates in word columns\n",
    "df = df.drop_duplicates(subset=[\"word\"])\n",
    "\n",
    "# remove head\n",
    "df = df.iloc[1:]\n",
    "\n",
    "# # removing punctuation and numbers\n",
    "# df = df[df[\"tag\"] != \"p_oth\"]\n",
    "# df = df[df[\"tag\"] != \"c_num\"]\n",
    "\n",
    "print(\"### DF shape:\" ,df.shape)\n",
    "print(\"\\n### NaN values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# removing rows where tag is nan\n",
    "df = df.dropna(subset=[\"tag\"])\n",
    "print(\"\\n### DF shape after removing rows where tag is nan:\" ,df.shape)\n",
    "\n",
    "# print number of unique values for each column\n",
    "print(\"\\n### Unique values:\")\n",
    "print(df.nunique())\n",
    "\n",
    "# lower case all words\n",
    "df[\"word\"] = df[\"word\"].str.lower()\n",
    "\n",
    "# count number of row where word is equal to lemm\n",
    "print(\"\\n### Number of word that are equals to lemm:\")\n",
    "print(df[df[\"word\"] == df[\"lemm\"]].shape[0])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Number of unique characters: 57\n",
      "\n",
      "### Max word length: 22\n"
     ]
    }
   ],
   "source": [
    "# get all unique letter in words\n",
    "characters = set()\n",
    "\n",
    "for word in df[\"word\"]:\n",
    "    for letter in word:\n",
    "        characters.add(letter)\n",
    "\n",
    "for lemma in df[\"lemm\"]:\n",
    "    for letter in lemma:\n",
    "        characters.add(letter)\n",
    "\n",
    "# add padding and unknown to characters\n",
    "characters.add(\" \")\n",
    "\n",
    "# the length of the vocab for one-hot encoded char\n",
    "vocab_size = len(characters)\n",
    "\n",
    "print(\"\\n### Number of unique characters:\", vocab_size)\n",
    "\n",
    "# Input in a LSTM must have all the same length\n",
    "# so we pad the words with spaces to have the same length\n",
    "def pad_word(word, max_word_length):\n",
    "    return word + \" \" * (max_word_length - len(word))\n",
    "\n",
    "max_word_length = max(df[\"word\"].str.len().max(), df[\"lemm\"].str.len().max())\n",
    "print(\"\\n### Max word length:\", max_word_length)\n",
    "max_word_length +=1\n",
    "max_word_length = int(max_word_length)\n",
    "\n",
    "df[\"word\"] = df[\"word\"].apply(lambda x: pad_word(x, max_word_length))\n",
    "df[\"lemm\"] = df[\"lemm\"].apply(lambda x: pad_word(x, max_word_length))\n",
    "\n",
    "# order characters\n",
    "characters = sorted(list(characters))\n",
    "\n",
    "def word2int(word):\n",
    "    return [float(characters.index(letter)) for letter in word]\n",
    "\n",
    "def int2word(ints):\n",
    "    return \"\".join([characters[i] for i in ints])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each word is encoded as a list of one-hot encoded characters\n",
    "char_enc = OneHotEncoder(sparse_output=False)\n",
    "char_enc.fit([[char] for char in characters])\n",
    "\n",
    "def encode_word(word):\n",
    "    return char_enc.transform([[char] for char in word])\n",
    "\n",
    "def decode_word(word):\n",
    "    decoded_word = \"\"\n",
    "    for c in word:\n",
    "        decoded_word += char_enc.inverse_transform([c])[0]\n",
    "    return decoded_word\n",
    "\n",
    "# Applying the encoding to the words in the dataframe        \n",
    "df[\"word_e\"] = df[\"word\"].apply(encode_word)\n",
    "df[\"lemm_e\"] = df[\"lemm\"].apply(encode_word)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tag Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Number of POS tags: 31\n"
     ]
    }
   ],
   "source": [
    "tag_enc = OneHotEncoder(sparse_output=False)\n",
    "tag_enc.fit(df[[\"tag\"]])\n",
    "df[\"tag_e\"] = tag_enc.transform(df[[\"tag\"]]).tolist()\n",
    "\n",
    "# the length of the vocab for one-hot encoded pos\n",
    "pos_size = len(tag_enc.categories_[0])\n",
    "print(\"### Number of POS tags:\", pos_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Word train shape: (4554, 23, 57)\n",
      "### Tag train shape: (4554, 31)\n",
      "### Y train shape: (4554, 23, 57)\n",
      "\n",
      "### Word val shape: (47, 23, 57)\n",
      "### Tag val shape: (47, 31)\n",
      "### Y val shape: (47, 23, 57)\n",
      "\n",
      "### Word test shape: (512, 23, 57)\n",
      "### Tag test shape: (512, 31)\n",
      "### Y test shape: (512, 23, 57)\n",
      "\n",
      "### Vocab size: 57\n",
      "### POS tag size: 31\n"
     ]
    }
   ],
   "source": [
    "x_word  = np.array(df[\"word_e\"].tolist())\n",
    "x_tag   = np.array(df[\"tag_e\"].tolist())\n",
    "y = np.array(df[\"lemm_e\"].tolist())\n",
    "word_train, word_test, tag_train, tag_test, y_train, y_test = train_test_split(x_word, x_tag, y , test_size=0.1, random_state=42)\n",
    "word_train, word_val, tag_train, tag_val, y_train, y_val = train_test_split(word_train, tag_train, y_train, test_size=0.01, random_state=42)\n",
    "\n",
    "print(\"### Word train shape:\", word_train.shape)\n",
    "print(\"### Tag train shape:\", tag_train.shape)\n",
    "print(\"### Y train shape:\", y_train.shape)\n",
    "\n",
    "print(\"\\n### Word val shape:\", word_val.shape)\n",
    "print(\"### Tag val shape:\", tag_val.shape)\n",
    "print(\"### Y val shape:\", y_val.shape)\n",
    "\n",
    "print(\"\\n### Word test shape:\", word_test.shape)\n",
    "print(\"### Tag test shape:\", tag_test.shape)\n",
    "print(\"### Y test shape:\", y_test.shape)\n",
    "\n",
    "print(\"\\n### Vocab size:\", vocab_size)\n",
    "print(\"### POS tag size:\", pos_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-14 12:36:49.710829: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-01-14 12:36:49.710970: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " word_input (InputLayer)        [(None, 23, 57)]     0           []                               \n",
      "                                                                                                  \n",
      " tag_input (InputLayer)         [(None, 31)]         0           []                               \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 23, 128)      62464       ['word_input[0][0]']             \n",
      "                                                                                                  \n",
      " tag_dense (Dense)              (None, 64)           2048        ['tag_input[0][0]']              \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, 23, 128)     98816       ['bidirectional[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " repeat_vector (RepeatVector)   (None, 23, 64)       0           ['tag_dense[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 23, 192)      0           ['bidirectional_1[0][0]',        \n",
      "                                                                  'repeat_vector[0][0]']          \n",
      "                                                                                                  \n",
      " lstm2dense (Dense)             (None, 23, 64)       12352       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 23, 57)       3705        ['lstm2dense[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 179,385\n",
      "Trainable params: 179,385\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    # Inputs\n",
    "    word_input = tf.keras.layers.Input(name=\"word_input\", shape=(max_word_length, vocab_size))\n",
    "    tag_input = tf.keras.layers.Input(name=\"tag_input\", shape=(pos_size))\n",
    "\n",
    "    # Bidirectional LSTM layer\n",
    "    lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True))(word_input)\n",
    "    lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True))(lstm)\n",
    "\n",
    "    # Fully connected layer for tag_input\n",
    "    tag_fc = tf.keras.layers.Dense(64, name=\"tag_dense\", activation='relu')(tag_input)\n",
    "    tag_fc = tf.keras.layers.RepeatVector(max_word_length)(tag_fc)\n",
    "\n",
    "    # Concatenate the two inputs\n",
    "    concat = tf.keras.layers.Concatenate()([lstm, tag_fc])\n",
    "\n",
    "    # Fully connected layer\n",
    "    fc = tf.keras.layers.Dense(64, name=\"lstm2dense\", activation='relu')(concat)\n",
    "\n",
    "    # Output layer\n",
    "    output = tf.keras.layers.Dense(vocab_size, name=\"output\", activation='softmax')(fc)\n",
    "\n",
    "    # Create model\n",
    "    return tf.keras.models.Model(inputs=[word_input, tag_input], outputs=output)\n",
    "\n",
    "\n",
    "# Create model\n",
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-14 12:36:50.436223: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-01-14 12:36:52.872066: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-14 12:36:53.243910: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-14 12:36:53.265969: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-14 12:36:53.451239: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-14 12:36:53.468114: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-14 12:36:53.687124: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-14 12:36:53.740068: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/18 [>.............................] - ETA: 1:03 - loss: 4.0360 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-14 12:36:53.969032: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-14 12:36:53.993488: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - ETA: 0s - loss: 2.8915 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-14 12:36:56.181795: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-14 12:36:56.327628: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-14 12:36:56.339576: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-14 12:36:56.435630: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-14 12:36:56.447555: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 6s 146ms/step - loss: 2.8915 - accuracy: 0.0000e+00 - val_loss: 1.8092 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 1s 61ms/step - loss: 1.3755 - accuracy: 0.0000e+00 - val_loss: 1.2616 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 1s 60ms/step - loss: 1.1281 - accuracy: 0.0000e+00 - val_loss: 1.1262 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 1.0279 - accuracy: 0.0000e+00 - val_loss: 1.0690 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.9836 - accuracy: 0.0000e+00 - val_loss: 1.0458 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.9642 - accuracy: 0.0000e+00 - val_loss: 1.0278 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.9487 - accuracy: 0.0000e+00 - val_loss: 1.0125 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.9316 - accuracy: 4.3403e-04 - val_loss: 0.9936 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.9084 - accuracy: 4.3403e-04 - val_loss: 0.9669 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.8738 - accuracy: 4.3403e-04 - val_loss: 0.9343 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.8241 - accuracy: 0.0013 - val_loss: 0.8666 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.7456 - accuracy: 0.0044 - val_loss: 0.7598 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 1s 60ms/step - loss: 0.6363 - accuracy: 0.0177 - val_loss: 0.6305 - val_accuracy: 0.0213\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.5122 - accuracy: 0.0579 - val_loss: 0.4994 - val_accuracy: 0.0426\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 1s 60ms/step - loss: 0.4000 - accuracy: 0.1369 - val_loss: 0.3797 - val_accuracy: 0.1489\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.3084 - accuracy: 0.2731 - val_loss: 0.2925 - val_accuracy: 0.3617\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.2468 - accuracy: 0.4133 - val_loss: 0.2334 - val_accuracy: 0.4043\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.2051 - accuracy: 0.5013 - val_loss: 0.1906 - val_accuracy: 0.4681\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 1s 60ms/step - loss: 0.1766 - accuracy: 0.5409 - val_loss: 0.1663 - val_accuracy: 0.5745\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.1562 - accuracy: 0.5783 - val_loss: 0.1411 - val_accuracy: 0.5532\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.1427 - accuracy: 0.6051 - val_loss: 0.1284 - val_accuracy: 0.5745\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.1323 - accuracy: 0.6274 - val_loss: 0.1196 - val_accuracy: 0.6170\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.1233 - accuracy: 0.6519 - val_loss: 0.1109 - val_accuracy: 0.6809\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.1143 - accuracy: 0.6816 - val_loss: 0.1024 - val_accuracy: 0.6809\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.1080 - accuracy: 0.6871 - val_loss: 0.0976 - val_accuracy: 0.7021\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.1032 - accuracy: 0.7040 - val_loss: 0.0903 - val_accuracy: 0.7021\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0982 - accuracy: 0.7097 - val_loss: 0.1051 - val_accuracy: 0.6596\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.0967 - accuracy: 0.7172 - val_loss: 0.0841 - val_accuracy: 0.7234\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0916 - accuracy: 0.7290 - val_loss: 0.0888 - val_accuracy: 0.7021\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.0874 - accuracy: 0.7387 - val_loss: 0.0790 - val_accuracy: 0.7021\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.0831 - accuracy: 0.7538 - val_loss: 0.0757 - val_accuracy: 0.7234\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0806 - accuracy: 0.7560 - val_loss: 0.0735 - val_accuracy: 0.7447\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0778 - accuracy: 0.7681 - val_loss: 0.0702 - val_accuracy: 0.7660\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0752 - accuracy: 0.7679 - val_loss: 0.0696 - val_accuracy: 0.7447\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0728 - accuracy: 0.7715 - val_loss: 0.0668 - val_accuracy: 0.7660\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.0716 - accuracy: 0.7765 - val_loss: 0.0673 - val_accuracy: 0.7447\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.0683 - accuracy: 0.7807 - val_loss: 0.0642 - val_accuracy: 0.7660\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.0658 - accuracy: 0.7904 - val_loss: 0.0616 - val_accuracy: 0.7660\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.0640 - accuracy: 0.7959 - val_loss: 0.0603 - val_accuracy: 0.7447\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.0632 - accuracy: 0.7910 - val_loss: 0.0637 - val_accuracy: 0.7447\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0607 - accuracy: 0.7968 - val_loss: 0.0622 - val_accuracy: 0.7021\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0600 - accuracy: 0.7998 - val_loss: 0.0590 - val_accuracy: 0.7447\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0591 - accuracy: 0.7964 - val_loss: 0.0584 - val_accuracy: 0.7660\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.0566 - accuracy: 0.8085 - val_loss: 0.0592 - val_accuracy: 0.7447\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.0549 - accuracy: 0.8125 - val_loss: 0.0583 - val_accuracy: 0.7234\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.0528 - accuracy: 0.8217 - val_loss: 0.0573 - val_accuracy: 0.7234\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0534 - accuracy: 0.8168 - val_loss: 0.0528 - val_accuracy: 0.7447\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.0518 - accuracy: 0.8158 - val_loss: 0.0522 - val_accuracy: 0.7447\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.0505 - accuracy: 0.8225 - val_loss: 0.0542 - val_accuracy: 0.7234\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.0502 - accuracy: 0.8202 - val_loss: 0.0537 - val_accuracy: 0.7234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e80cce50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "epochs = 50\n",
    "batch_size = 256\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.argmax(y_true, axis=-1)\n",
    "    y_pred = tf.argmax(y_pred, axis=-1)\n",
    "    correct_predictions = tf.reduce_all(tf.equal(y_true, y_pred), axis=-1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
    "    return accuracy\n",
    "\n",
    "model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=[accuracy])\n",
    "model.fit([word_train, tag_train], y_train, epochs=epochs, batch_size=batch_size, validation_data=([word_val, tag_val], y_val))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Test Accuracy: 81.054688\n",
      "### Test Loss: 0.059654\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loss, acc = model.evaluate([word_test, tag_test], y_test, verbose=0)\n",
    "print('### Test Accuracy: %f' % (acc*100))\n",
    "print('### Test Loss: %f' % (loss))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization Accuracy\n",
    "\n",
    "Lemmatisation accuracy is defined as the number of correct lemma assignment divided by the total number of tokens in the test set belonging to the considered lexical classes (ADJ_, ADV,NN, V_). \n",
    "\n",
    "(Evalita2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-14 12:37:49.629589: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-14 12:37:49.750224: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-14 12:37:49.750283: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-14 12:37:49.853008: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-14 12:37:49.864540: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatization accuracy: 0.810546875\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for the test set\n",
    "predictions = model.predict([word_test, tag_test], verbose=0)\n",
    "\n",
    "# Convert predictions to lemmas\n",
    "predicted_lemmas = [decode_word(pred) for pred in predictions]\n",
    "\n",
    "# Compare predictions to actual lemmas\n",
    "correct = 0\n",
    "for i, lemma in enumerate(predicted_lemmas):\n",
    "    if lemma == decode_word(y_test[i]):\n",
    "        correct += 1\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct / len(y_test)\n",
    "print(\"Lemmatization accuracy:\", accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Word: ['sgraziata              ']\n",
      "### Tag: ['adj']\n",
      "### Lemma: ['sgraziato              ']\n",
      "### Lemma prediction: ['sgraziato              ']\n"
     ]
    }
   ],
   "source": [
    "# try the model with an example\n",
    "n = np.random.randint(0, len(word_test))\n",
    "word = word_test[n]\n",
    "tag = tag_test[n]\n",
    "y = y_test[n]\n",
    "\n",
    "print(\"### Word:\", decode_word(word))\n",
    "print(\"### Tag:\", tag_enc.inverse_transform([tag])[0])\n",
    "print(\"### Lemma:\", decode_word(y))\n",
    "\n",
    "prediction = model.predict([np.array([word]), np.array([tag])], verbose=0)\n",
    "print(\"### Lemma prediction:\", decode_word(prediction[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"lemmatizer.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08eac26dc1f80337b7d87e94e7159a5bad95c2e85f47efef91c61359b3afbfe9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
