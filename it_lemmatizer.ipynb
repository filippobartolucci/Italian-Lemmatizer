{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlXK_WPhCXve"
      },
      "source": [
        "# Italian Word Lemmatizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfFQpeq7CXvj"
      },
      "source": [
        "### Import\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "1m3hfyemCXvj"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import backend as K\n",
        "from keras.layers import Input, LSTM, Dense, Embedding, Concatenate, Bidirectional, TimeDistributed, RepeatVector, Activation, Dot, Lambda, Dropout, Add, Multiply, Masking, Attention\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import gensim\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "# set all random seeds\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEeIQWgECXvk"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcBN-hJ3CXvl",
        "outputId": "840d4153-1800-4c70-d994-973b1bd1aade"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max sentence length:  95\n",
            "Max sentence length:  107\n",
            "Number of sentences in dev set:  703\n",
            "Number of sentences in test set:  5596\n",
            "Number of unique tags:  32\n"
          ]
        }
      ],
      "source": [
        "\n",
        "dataset_path = \"./dev.csv\"\n",
        "df_dev = pd.read_csv(dataset_path, sep=\"\\t\", header=None,\n",
        "                     names=[\"word\", \"tag\", \"lemm\"])\n",
        "\n",
        "dataset_path = \"./test.csv\"\n",
        "df_test = pd.read_csv(dataset_path, sep=\"\\t\", header=None,\n",
        "                      names=[\"word\", \"tag\", \"lemm\"])\n",
        "\n",
        "df_dev[\"word\"] = df_dev[\"word\"].astype(str)\n",
        "df_dev[\"tag\"] = df_dev[\"tag\"].astype(str)\n",
        "df_dev[\"lemm\"] = df_dev[\"lemm\"].astype(str)\n",
        "\n",
        "df_test[\"word\"] = df_test[\"word\"].astype(str)\n",
        "df_test[\"tag\"] = df_test[\"tag\"].astype(str)\n",
        "df_test[\"lemm\"] = df_test[\"lemm\"].astype(str)\n",
        "\n",
        "# remove head\n",
        "df_dev = df_dev.iloc[1:]\n",
        "df_test = df_test.iloc[1:]\n",
        "\n",
        "# lower case all words\n",
        "df_test[\"word\"] = df_test[\"word\"].str.lower()\n",
        "df_dev[\"word\"] = df_dev[\"word\"].str.lower()\n",
        "\n",
        "def get_sentences(df):\n",
        "    words = []\n",
        "    tags = []\n",
        "    lemmas = []\n",
        "    sentence = []\n",
        "    max_s = 0\n",
        "    for index, row in df.iterrows():\n",
        "        word = row[\"word\"]\n",
        "        tag = row[\"tag\"]\n",
        "        lemm = row[\"lemm\"]\n",
        "        sentence.append([word, tag, lemm])\n",
        "\n",
        "        if row[\"word\"] in [\".\", \"?\", \"!\", \";\"]:\n",
        "            words.append([word for word, tag, lemm in sentence])\n",
        "            tags.append([tag for word, tag, lemm in sentence])\n",
        "            lemmas.append([lemm for word, tag, lemm in sentence])\n",
        "            max_s = max(max_s, len(sentence))\n",
        "            sentence = []\n",
        "\n",
        "    print(\"Max sentence length: \", max_s)\n",
        "    return words, tags, lemmas\n",
        "\n",
        "# _s is for string\n",
        "dev_words_s, dev_tags_s, dev_lemmas_s = get_sentences(df_dev)\n",
        "test_words_s, test_tags_s, test_lemmas_s = get_sentences(df_test)\n",
        "print(\"Number of sentences in dev set: \", len(dev_words_s))\n",
        "print(\"Number of sentences in test set: \", len(test_words_s))\n",
        "\n",
        "# print number of unique tags\n",
        "print(\"Number of unique tags: \", len(df_dev[\"tag\"].unique()))\n",
        "\n",
        "for i in range(len(dev_words_s)):\n",
        "    if len(dev_words_s[i]) != len(dev_tags_s[i]) or len(dev_words_s[i]) != len(dev_lemmas_s[i]):\n",
        "        print(\"Dimension mismatch in sentence: \", i)\n",
        "        print(\"Words: \", dev_words_s[i])\n",
        "        print(\"Tags: \", dev_tags_s[i])\n",
        "        print(\"Lemmas: \", dev_lemmas_s[i])\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "yJ04hS-bCXvl",
        "outputId": "bf44d144-799a-441f-adb7-823d3661d376"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plot tag distribution\n",
        "tags = []\n",
        "for tag_list in dev_tags_s:\n",
        "    tags.extend(tag_list)\n",
        "\n",
        "tags = pd.Series(tags)\n",
        "tags.value_counts().plot(kind=\"bar\", figsize=(20, 10))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QieUyx1CCXvo"
      },
      "source": [
        "## Word Context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9dkBA-zCXvo",
        "outputId": "5255301a-17c9-41fa-86a5-309f55e655e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of sample in dev set:  16447\n",
            "Number of sample in val set:  866\n",
            "Number of sample in test set:  133756\n"
          ]
        }
      ],
      "source": [
        "CTX_DIM = 12            # context dimension, 12 words on each side\n",
        "PRE_VALUE = \"<PRE>\"     # value for padding pre \n",
        "POST_VALUE = \"<POST>\"   # value for padding post\n",
        "NONE_TAG = \"<NONE>\"     # value for padding tags\n",
        "\n",
        "def get_context(words, tags, lemmas):\n",
        "    ctx = []    # context list\n",
        "    w = []      # word list\n",
        "    tag = []    # context tags list\n",
        "    t = []      # word tags list\n",
        "    lemma = []  # lemma list\n",
        "\n",
        "    for s_index in range(len(words)):\n",
        "        s = words[s_index]\n",
        "        s_tags = tags[s_index]\n",
        "        sentence = \" \".join(s)\n",
        "        s = [PRE_VALUE] * CTX_DIM + s + [POST_VALUE] * CTX_DIM\n",
        "        s_tags = [NONE_TAG] * CTX_DIM + s_tags + [NONE_TAG] * CTX_DIM\n",
        "\n",
        "        for w_index in range(len(s)):\n",
        "            if w_index < CTX_DIM or w_index >= len(s) - CTX_DIM:\n",
        "                continue\n",
        "\n",
        "            context = s[w_index - CTX_DIM:w_index] + [s[w_index]] +s[w_index + 1:w_index  + CTX_DIM + 1]\n",
        "            context = \" \".join(context)\n",
        "            ctx.append(context)\n",
        "            w.append(words[s_index][w_index-CTX_DIM])\n",
        "\n",
        "            ctx_tags = s_tags[w_index - CTX_DIM:w_index] + [s_tags[w_index]] + s_tags[w_index + 1:w_index  + CTX_DIM + 1]\n",
        "            tag.append(ctx_tags)\n",
        "            t.append(tags[s_index][w_index-CTX_DIM])\n",
        "\n",
        "            lemma.append(lemmas[s_index][w_index-CTX_DIM])\n",
        "    return ctx, w, tag, t, lemma\n",
        "\n",
        "dev_ctx, dev_words, dev_tags, dev_tag,dev_lemmas = get_context(dev_words_s, dev_tags_s, dev_lemmas_s)\n",
        "test_ctx, test_words, test_tags, test_tag,test_lemmas = get_context(test_words_s, test_tags_s, test_lemmas_s)\n",
        "\n",
        "dev_ctx, val_ctx, dev_words, val_words, dev_tags, val_tags, dev_tag, val_tag, dev_lemmas, val_lemmas = train_test_split(dev_ctx, dev_words, dev_tags, dev_tag, dev_lemmas, test_size=0.05, random_state=42)\n",
        "\n",
        "print(\"Number of sample in dev set: \", len(dev_lemmas))\n",
        "print(\"Number of sample in val set: \", len(val_lemmas))\n",
        "print(\"Number of sample in test set: \", len(test_lemmas))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfMwZrgcCXvo"
      },
      "source": [
        "### Example of context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVoxwHO4CXvp",
        "outputId": "0fa1e03e-0a7c-4338-9d2d-b5cedf8a9e97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CTX Dim: 12 \n",
            "\n",
            "CTX:  <PRE> ma i blair , con i ragazzi da distrarre , avevano altre idee . <POST> <POST> <POST> <POST> <POST> <POST> <POST> <POST> <POST> <POST>\n",
            "CTX Tags:  ['<NONE>', 'conj_c', 'art', 'nn_p', 'p_oth', 'prep', 'art', 'nn', 'prep', 'v_gvrb', 'p_oth', 'v_avere', 'adj_ind', 'nn', 'p_eos', '<NONE>', '<NONE>', '<NONE>', '<NONE>', '<NONE>', '<NONE>', '<NONE>', '<NONE>', '<NONE>', '<NONE>']\n",
            "Word:  altre\n",
            "Tag:  adj_ind\n",
            "Lemma:  altro\n",
            "\n",
            "CTX:  rigorosamente accademico , corredata da una ricca e del tutto inverosimile bibliografia e arricchita da numerose tavole iconografiche , &egrave; stata recentemente pubblicata anche in\n",
            "CTX Tags:  ['adv', 'adj', 'p_oth', 'v_pp', 'prep', 'art', 'adj', 'conj_c', 'prep_a', 'nn', 'adj', 'nn', 'conj_c', 'v_pp', 'prep', 'adj', 'nn', 'adj', 'p_oth', 'v_essere', 'v_essere', 'adv', 'v_pp', 'conj_c', 'prep']\n",
            "Word:  e\n",
            "Tag:  conj_c\n",
            "Lemma:  e\n",
            "\n",
            "CTX:  * difesa dei diritti dei curdi l' italia porter&agrave; davanti_ai fori internazionali la questione dei diritti del popolo curdo . <POST> <POST> <POST> <POST> <POST>\n",
            "CTX Tags:  ['p_oth', 'nn', 'prep_a', 'nn', 'prep_a', 'nn', 'art', 'nn_p', 'v_gvrb', 'prep_a', 'nn', 'adj', 'art', 'nn', 'prep_a', 'nn', 'prep_a', 'nn', 'adj', 'p_eos', '<NONE>', '<NONE>', '<NONE>', '<NONE>', '<NONE>']\n",
            "Word:  la\n",
            "Tag:  art\n",
            "Lemma:  la\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"CTX Dim:\", CTX_DIM, \"\\n\")\n",
        "for i in range(3):\n",
        "    index = np.random.randint(0, len(dev_ctx))\n",
        "    print(\"CTX: \", dev_ctx[index])\n",
        "    print(\"CTX Tags: \", dev_tags[index])\n",
        "    print(\"Word: \", dev_words[index])\n",
        "    print(\"Tag: \", dev_tag[index])\n",
        "    print(\"Lemma: \", dev_lemmas[index])\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDN8khxaCXvp"
      },
      "source": [
        "## Open Class Words\n",
        "The evaluation is done only on open-class words and not to functional words: only the tokens having a PoS-tag comprised in the set ADJ *, ADV, NN, V * had to be lemmatised, in all the other cases the token could be copied unchanged into the lemma column as they were not considered for the evaluation (the asterisk indicates all PoS-tag possibilities beginning with that prefix)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Su-C7kFTCXvp",
        "outputId": "d79dd705-5c69-48f4-8e0e-a579b0c9ad28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of open class words in dev set:  8045\n",
            "Number of open class words in val set:  421\n",
            "Number of open class words in test set:  65210\n"
          ]
        }
      ],
      "source": [
        "def get_open_class_words(ctx, words, tags, tag, lemmas):\n",
        "    open_class_words = []   # open class words\n",
        "    open_class_ctx = []     # open class context \n",
        "    open_class_tags = []    # open class tags\n",
        "    open_class_tag = []     # open class tag\n",
        "    open_class_lemmas = []  # open class lemmas\n",
        "\n",
        "    open_classes = [\"nn\", \"v_gvrb\", \"v_essere\", \"v_avere\", \"v_pp\", \"v_mod\", \"v_clit\", \"adv\", \"adj_ind\", \"adj_num\", \"adj\", \"adj_pos\", \"adj_dim\", \"adj_ies\"]\n",
        "\n",
        "    for i in range(len(words)):\n",
        "        t = tag[i]\n",
        "        if t in open_classes:\n",
        "            open_class_words.append(words[i])\n",
        "            open_class_ctx.append(ctx[i])\n",
        "            open_class_tags.append(tags[i])\n",
        "            open_class_tag.append(t)\n",
        "            open_class_lemmas.append(lemmas[i])\n",
        "\n",
        "    return open_class_ctx, open_class_words, open_class_tags, open_class_tag, open_class_lemmas\n",
        "\n",
        "\n",
        "test_ctx, test_words, test_tags, test_tag, test_lemmas = get_open_class_words(test_ctx, test_words, test_tags, test_tag, test_lemmas)\n",
        "dev_ctx, dev_words, dev_tags, dev_tag, dev_lemmas = get_open_class_words(dev_ctx, dev_words, dev_tags, dev_tag, dev_lemmas)\n",
        "val_ctx, val_words, val_tags, val_tag, val_lemmas = get_open_class_words(val_ctx, val_words, val_tags, val_tag, val_lemmas)\n",
        "\n",
        "print(\"Number of open class words in dev set: \", len(dev_words))\n",
        "print(\"Number of open class words in val set: \", len(val_words)) \n",
        "print(\"Number of open class words in test set: \", len(test_words))  \n",
        "# total 79984"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4TNe-0-CXvq"
      },
      "source": [
        "## Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDgvmCucCXvq",
        "outputId": "2eaca1a9-39d5-477e-c725-ee2e5f9ff89a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocab size:  41\n",
            "Max word length:  25\n",
            "\n",
            "Context: \n",
            " , l' unico espediente a disposizione &egrave; l' appropriato uso di esplosioni nucleari . <POST> <POST> <POST> <POST> <POST> <POST> <POST> <POST> <POST> <POST> <POST> \n",
            " [3, 19, 471, 11863, 10, 580, 13, 19, 4975, 424, 4, 6870, 4664, 6, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
            "\n",
            "Tags: \n",
            " ['p_oth', 'art', 'adj', 'nn', 'prep', 'nn', 'v_essere', 'art', 'adj', 'nn', 'prep', 'nn', 'adj', 'p_eos', '<NONE>', '<NONE>', '<NONE>', '<NONE>', '<NONE>', '<NONE>', '<NONE>', '<NONE>', '<NONE>', '<NONE>', '<NONE>'] \n",
            " [5, 4, 6, 2, 3, 2, 13, 4, 6, 2, 3, 2, 6, 14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "\n",
            "Words: \n",
            " nucleari \n",
            " [28 35 17 26 19 15 32 23  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0]\n",
            "\n",
            "Lemma: \n",
            " nucleare \n",
            " [28 35 17 26 19 15 32 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0]\n"
          ]
        }
      ],
      "source": [
        "# word encoder\n",
        "word_tokenizer = Tokenizer(filters=\"\")\n",
        "word_tokenizer.fit_on_texts(dev_ctx + test_ctx + val_ctx)\n",
        "\n",
        "# tag encoder\n",
        "tag_tokenizer = Tokenizer(filters=\"\")\n",
        "tag_tokenizer.fit_on_texts(dev_tags + test_tags + val_tags)\n",
        "\n",
        "# lemma encoder\n",
        "lemma_tokenizer = Tokenizer(filters=\"\")\n",
        "lemma_tokenizer.fit_on_texts(dev_lemmas_s + test_lemmas_s)\n",
        "\n",
        "dev_ctx_e = word_tokenizer.texts_to_sequences(dev_ctx)\n",
        "val_ctx_e = word_tokenizer.texts_to_sequences(val_ctx)\n",
        "test_ctx_e = word_tokenizer.texts_to_sequences(test_ctx)\n",
        "\n",
        "dev_tags_e = tag_tokenizer.texts_to_sequences(dev_tags)\n",
        "val_tags_e = tag_tokenizer.texts_to_sequences(val_tags)\n",
        "test_tags_e = tag_tokenizer.texts_to_sequences(test_tags)\n",
        "\n",
        "\n",
        "# get all unique letter in words\n",
        "characters = set()\n",
        "\n",
        "MAX_WORD_LENGTH = 0\n",
        "\n",
        "for w in dev_words + test_words + dev_lemmas + test_lemmas + val_words + val_lemmas:\n",
        "    MAX_WORD_LENGTH = max(MAX_WORD_LENGTH, len(w))\n",
        "\n",
        "    for letter in w:\n",
        "        characters.add(letter)\n",
        "\n",
        "# add padding and unknown to characters\n",
        "characters.add(\" \")\n",
        "\n",
        "# the length of the vocab for one-hot encoded char\n",
        "VOCAB_SIZE = len(characters)\n",
        "\n",
        "print (\"Vocab size: \", VOCAB_SIZE)\n",
        "print(\"Max word length: \", MAX_WORD_LENGTH)\n",
        "\n",
        "characters = sorted(list(characters))\n",
        "\n",
        "char2idx = {char: idx for idx, char in enumerate(characters)}\n",
        "idx2char = {idx: char for idx, char in enumerate(characters)}\n",
        "\n",
        "def encode_words(words):\n",
        "    encoded_words = []\n",
        "    for word in words:\n",
        "        word_e = []\n",
        "        for letter in word:\n",
        "            word_e.append(characters.index(letter))\n",
        "        encoded_words.append(word_e)\n",
        "    return encoded_words\n",
        "\n",
        "dev_words_e = encode_words(dev_words)\n",
        "test_words_e = encode_words(test_words)\n",
        "val_words_e = encode_words(val_words)\n",
        "\n",
        "dev_lemmas_e = encode_words(dev_lemmas)\n",
        "test_lemmas_e = encode_words(test_lemmas)\n",
        "val_lemmas_e = encode_words(val_lemmas)\n",
        "\n",
        "dev_words_e = tf.keras.preprocessing.sequence.pad_sequences(dev_words_e, maxlen=MAX_WORD_LENGTH, padding=\"post\")\n",
        "test_words_e = tf.keras.preprocessing.sequence.pad_sequences(test_words_e, maxlen=MAX_WORD_LENGTH, padding=\"post\")\n",
        "val_words_e = tf.keras.preprocessing.sequence.pad_sequences(val_words_e, maxlen=MAX_WORD_LENGTH, padding=\"post\")\n",
        "\n",
        "dev_lemmas_e = tf.keras.preprocessing.sequence.pad_sequences(dev_lemmas_e, maxlen=MAX_WORD_LENGTH, padding=\"post\")\n",
        "test_lemmas_e = tf.keras.preprocessing.sequence.pad_sequences(test_lemmas_e, maxlen=MAX_WORD_LENGTH, padding=\"post\")\n",
        "val_lemmas_e = tf.keras.preprocessing.sequence.pad_sequences(val_lemmas_e, maxlen=MAX_WORD_LENGTH, padding=\"post\")\n",
        "\n",
        "index = np.random.randint(0, len(dev_ctx))\n",
        "print(\"\\nContext: \\n\", dev_ctx[index], \"\\n\", dev_ctx_e[index])\n",
        "print(\"\\nTags: \\n\", dev_tags[index], \"\\n\", dev_tags_e[index])\n",
        "print(\"\\nWords: \\n\", dev_words[index], \"\\n\", dev_words_e[index])\n",
        "print(\"\\nLemma: \\n\", dev_lemmas[index], \"\\n\", dev_lemmas_e[index])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "pXlZTReRCXvq"
      },
      "outputs": [],
      "source": [
        "# one hot encode the characters for the lemmas\n",
        "dev_lemmas_e = tf.one_hot(dev_lemmas_e, VOCAB_SIZE)\n",
        "test_lemmas_e = tf.one_hot(test_lemmas_e, VOCAB_SIZE)\n",
        "val_lemmas_e = tf.one_hot(val_lemmas_e, VOCAB_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtsh2qnGCXvs",
        "outputId": "38d99e8a-611b-452c-82c9-813b095fe05a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape\n",
            "Context shape:  (8045, 25)\n",
            "Words shape:  (8045, 25)\n",
            "Tags shape:  (8045, 25)\n",
            "Lemmas shape:  (8045, 25, 41)\n",
            "\n",
            "Test shape\n",
            "Context shape:  (65210, 25)\n",
            "Words shape:  (65210, 25)\n",
            "Tags shape:  (65210, 25)\n",
            "Lemmas shape:  (65210, 25, 41)\n"
          ]
        }
      ],
      "source": [
        "# trnasform to numpy array\n",
        "dev_ctx_e = np.array(dev_ctx_e)\n",
        "dev_words_e = np.array(dev_words_e)\n",
        "dev_tags_e = np.array(dev_tags_e)\n",
        "dev_lemmas_e = np.array(dev_lemmas_e)\n",
        "\n",
        "test_ctx_e = np.array(test_ctx_e)\n",
        "test_words_e = np.array(test_words_e)\n",
        "test_tags_e = np.array(test_tags_e)\n",
        "test_lemmas_e = np.array(test_lemmas_e)\n",
        "\n",
        "val_ctx_e = np.array(val_ctx_e)\n",
        "val_words_e = np.array(val_words_e)\n",
        "val_tags_e = np.array(val_tags_e)\n",
        "val_lemmas_e = np.array(val_lemmas_e)\n",
        "\n",
        "print(\"Train shape\")\n",
        "print(\"Context shape: \", dev_ctx_e.shape)\n",
        "print(\"Words shape: \", dev_words_e.shape)\n",
        "print(\"Tags shape: \", dev_tags_e.shape)\n",
        "print(\"Lemmas shape: \", dev_lemmas_e.shape)\n",
        "\n",
        "print(\"\\nTest shape\")\n",
        "print(\"Context shape: \", test_ctx_e.shape)\n",
        "print(\"Words shape: \", test_words_e.shape)\n",
        "print(\"Tags shape: \", test_tags_e.shape)\n",
        "print(\"Lemmas shape: \", test_lemmas_e.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLAyRU0RCXvs"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xj8391mwCXvs"
      },
      "source": [
        "### Lemmatization Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2YpdToIbCXvs"
      },
      "outputs": [],
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "    y_true = tf.argmax(y_true, axis=-1)\n",
        "    y_pred = tf.argmax(y_pred, axis=-1)\n",
        "    correct_predictions = tf.reduce_all(tf.equal(y_true, y_pred), axis=-1)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
        "    return accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqY9BzpyCXvv"
      },
      "source": [
        "### Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wY0OBxc2CXvv",
        "outputId": "d77667c2-cd2a-4c06-d585-38aae1a162af"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n"
          ]
        }
      ],
      "source": [
        "EMBEDDING_DIM = 384\n",
        "VOCABULARY_SIZE = len(word_tokenizer.word_index) + 1\n",
        "\n",
        "def get_word2vec_weights(DIM):\n",
        "    # train word2vec model\n",
        "    word2vec = gensim.models.Word2Vec(dev_words + test_words_s, size=DIM, window=10, min_count=1, workers=8)\n",
        "\n",
        "    # create an empty embedding matix\n",
        "    embedding_weights = np.zeros((VOCABULARY_SIZE, DIM))\n",
        "\n",
        "    # create a word to index dictionary mapping\n",
        "    word2id = word_tokenizer.word_index\n",
        "\n",
        "    # copy vectors from word2vec model to the words present in corpus\n",
        "    for word, index in word2id.items():\n",
        "        try:\n",
        "            embedding_weights[index, :] = word2vec.wv[word]\n",
        "        except KeyError:\n",
        "            pass\n",
        "\n",
        "    return embedding_weights\n",
        "\n",
        "embedding_weights = get_word2vec_weights(EMBEDDING_DIM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flAnhFU9CXvv",
        "outputId": "c6c89d3e-b656-4ed7-c87e-e2f74ad6fcfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_14 (InputLayer)          [(None, 25)]         0           []                               \n",
            "                                                                                                  \n",
            " input_13 (InputLayer)          [(None, 25)]         0           []                               \n",
            "                                                                                                  \n",
            " tags_embedding (Embedding)     (None, 25, 64)       2176        ['input_14[0][0]']               \n",
            "                                                                                                  \n",
            " context_embedding (Embedding)  (None, 25, 384)      7593216     ['input_13[0][0]']               \n",
            "                                                                                                  \n",
            " bidirectional_13 (Bidirectiona  (None, 25, 128)     66048       ['tags_embedding[1][0]']         \n",
            " l)                                                                                               \n",
            "                                                                                                  \n",
            " input_15 (InputLayer)          [(None, 25)]         0           []                               \n",
            "                                                                                                  \n",
            " bidirectional_12 (Bidirectiona  (None, 25, 768)     2362368     ['context_embedding[1][0]']      \n",
            " l)                                                                                               \n",
            "                                                                                                  \n",
            " time_distributed_20 (TimeDistr  (None, 25, 768)     99072       ['bidirectional_13[1][0]']       \n",
            " ibuted)                                                                                          \n",
            "                                                                                                  \n",
            " words_embedding (Embedding)    (None, 25, 64)       2624        ['input_15[0][0]']               \n",
            "                                                                                                  \n",
            " attention (Attention)          (None, 25, 768)      0           ['bidirectional_12[1][0]',       \n",
            "                                                                  'time_distributed_20[1][0]']    \n",
            "                                                                                                  \n",
            " bidirectional_14 (Bidirectiona  (None, 25, 768)     1379328     ['words_embedding[1][0]']        \n",
            " l)                                                                                               \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 25, 1536)     0           ['attention[1][0]',              \n",
            "                                                                  'bidirectional_14[1][0]']       \n",
            "                                                                                                  \n",
            " lstm (Bidirectional)           (None, 25, 768)      5901312     ['concatenate_3[1][0]']          \n",
            "                                                                                                  \n",
            " dropout_13 (Dropout)           (None, 25, 768)      0           ['lstm[1][0]']                   \n",
            "                                                                                                  \n",
            " lstm2 (Bidirectional)          (None, 25, 768)      3542016     ['dropout_13[1][0]']             \n",
            "                                                                                                  \n",
            " time_distributed_21 (TimeDistr  (None, 25, 384)     295296      ['lstm2[1][0]']                  \n",
            " ibuted)                                                                                          \n",
            "                                                                                                  \n",
            " dropout_14 (Dropout)           (None, 25, 384)      0           ['time_distributed_21[1][0]']    \n",
            "                                                                                                  \n",
            " time_distributed_22 (TimeDistr  (None, 25, 384)     147840      ['dropout_14[1][0]']             \n",
            " ibuted)                                                                                          \n",
            "                                                                                                  \n",
            " dropout_15 (Dropout)           (None, 25, 384)      0           ['time_distributed_22[1][0]']    \n",
            "                                                                                                  \n",
            " time_distributed_23 (TimeDistr  (None, 25, 384)     147840      ['dropout_15[1][0]']             \n",
            " ibuted)                                                                                          \n",
            "                                                                                                  \n",
            " dropout_16 (Dropout)           (None, 25, 384)      0           ['time_distributed_23[1][0]']    \n",
            "                                                                                                  \n",
            " time_distributed_24 (TimeDistr  (None, 25, 384)     147840      ['dropout_16[1][0]']             \n",
            " ibuted)                                                                                          \n",
            "                                                                                                  \n",
            " output (TimeDistributed)       (None, 25, 41)       15785       ['time_distributed_24[1][0]']    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 21,702,761\n",
            "Trainable params: 14,109,545\n",
            "Non-trainable params: 7,593,216\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Neural network model\n",
        "# inputs:\n",
        "#   - context: (batch_size, CTX_DIM * 2) \n",
        "#   - tags: encoded tags: (batch_size, MAX_WORD_LENGTH)\n",
        "#   - words: encoded words: (batch_size, MAX_WORD_LENGTH)\n",
        "# outputs:\n",
        "#  - lemma: encoded lemma: (batch_size, MAX_WORD_LENGTH)\n",
        "\n",
        "def get_model():\n",
        "    # context\n",
        "    context_input = Input(shape=(CTX_DIM * 2 + 1,), name=\"context_input\")\n",
        "    context_input = Masking(mask_value=1)(context_input)\n",
        "    context_input = Masking(mask_value=2)(context_input)\n",
        "    context_embedding = Embedding(len(word_tokenizer.word_index) + 1, EMBEDDING_DIM, input_length=CTX_DIM * 2 + 1,name=\"context_embedding\", trainable=False, weights=[embedding_weights])(context_input)\n",
        "    context_embedding = Bidirectional(LSTM(EMBEDDING_DIM, return_sequences=True))(context_embedding)\n",
        "\n",
        "    # tags\n",
        "    tags_input = Input(shape=(CTX_DIM * 2 + 1,), name=\"tags_input\")\n",
        "    tags_input = Masking(mask_value=1)(tags_input)\n",
        "    tags_embedding = Embedding(len(tag_tokenizer.word_index) + 1, 64, input_length=CTX_DIM * 2 + 1, name=\"tags_embedding\", trainable=True)(tags_input)\n",
        "    tags_embedding = Bidirectional(LSTM(64, return_sequences=True))(tags_embedding)\n",
        "    tags_embedding = TimeDistributed(Dense(EMBEDDING_DIM*2))(tags_embedding)\n",
        "    \n",
        "    # words\n",
        "    words_input = Input(shape=(MAX_WORD_LENGTH,), name=\"words_input\")\n",
        "    words_input = Masking(mask_value=0)(words_input)\n",
        "    words_embedding = Embedding(VOCAB_SIZE, 64, input_length=MAX_WORD_LENGTH, name=\"words_embedding\", trainable=True)(words_input)\n",
        "    words_embedding = Bidirectional(LSTM(EMBEDDING_DIM, return_sequences=True))(words_embedding)\n",
        "\n",
        "    # combine\n",
        "    attention = Attention(name=\"attention\")([context_embedding, tags_embedding])\n",
        "    combine = Concatenate(axis=-1)([attention, words_embedding])\n",
        "    \n",
        "    lstm = Bidirectional(LSTM(EMBEDDING_DIM, return_sequences=True), name=\"lstm\")(combine)\n",
        "    lstm = Dropout(0.5)(lstm)\n",
        "    lstm = Bidirectional(LSTM(EMBEDDING_DIM, return_sequences=True), name=\"lstm2\")(lstm)\n",
        "\n",
        "    dense = TimeDistributed(Dense(EMBEDDING_DIM, activation=\"relu\", name=\"dense\"))(lstm)\n",
        "    dense = Dropout(0.3)(dense)\n",
        "    dense = TimeDistributed(Dense(EMBEDDING_DIM, activation=\"relu\", name=\"dense\"))(dense)\n",
        "    dense = Dropout(0.2)(dense)\n",
        "    dense = TimeDistributed(Dense(EMBEDDING_DIM, activation=\"relu\", name=\"dense\"))(dense)\n",
        "    dense = Dropout(0.2)(dense)\n",
        "    dense = TimeDistributed(Dense(EMBEDDING_DIM, activation=\"relu\", name=\"dense\"))(dense)\n",
        "\n",
        "    output = TimeDistributed(Dense(VOCAB_SIZE, activation=\"softmax\"), name=\"output\")(dense)\n",
        "    return Model(inputs=[context_input, tags_input, words_input], outputs=[output])\n",
        "\n",
        "model = get_model()\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPzq5zAJCXvx"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGNU9pxyCXvx",
        "outputId": "75282844-b685-4c58-ae3a-833ff299b204"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "126/126 [==============================] - 22s 60ms/step - loss: 0.9230 - accuracy: 0.0000e+00 - val_loss: 0.7636 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.7551 - accuracy: 1.2401e-04 - val_loss: 0.6514 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 4s 34ms/step - loss: 0.3790 - accuracy: 0.1494 - val_loss: 0.1870 - val_accuracy: 0.4879\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.1785 - accuracy: 0.4536 - val_loss: 0.1523 - val_accuracy: 0.5381\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 4s 34ms/step - loss: 0.1458 - accuracy: 0.5085 - val_loss: 0.1252 - val_accuracy: 0.5614\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.1266 - accuracy: 0.5226 - val_loss: 0.1058 - val_accuracy: 0.5799\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.1007 - accuracy: 0.5782 - val_loss: 0.0911 - val_accuracy: 0.6284\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 4s 34ms/step - loss: 0.0768 - accuracy: 0.6501 - val_loss: 0.0637 - val_accuracy: 0.7080\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0632 - accuracy: 0.6990 - val_loss: 0.0620 - val_accuracy: 0.7057\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0529 - accuracy: 0.7464 - val_loss: 0.0575 - val_accuracy: 0.7420\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 4s 34ms/step - loss: 0.0477 - accuracy: 0.7683 - val_loss: 0.0464 - val_accuracy: 0.7944\n",
            "Epoch 12/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0392 - accuracy: 0.8049 - val_loss: 0.0424 - val_accuracy: 0.8378\n",
            "Epoch 13/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0370 - accuracy: 0.8139 - val_loss: 0.0428 - val_accuracy: 0.8167\n",
            "Epoch 14/100\n",
            "126/126 [==============================] - 4s 34ms/step - loss: 0.0313 - accuracy: 0.8357 - val_loss: 0.0331 - val_accuracy: 0.8407\n",
            "Epoch 15/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0278 - accuracy: 0.8457 - val_loss: 0.0359 - val_accuracy: 0.8289\n",
            "Epoch 16/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0396 - accuracy: 0.8132 - val_loss: 0.0410 - val_accuracy: 0.8301\n",
            "Epoch 17/100\n",
            "126/126 [==============================] - 4s 34ms/step - loss: 0.0243 - accuracy: 0.8633 - val_loss: 0.0316 - val_accuracy: 0.8774\n",
            "Epoch 18/100\n",
            "126/126 [==============================] - 4s 34ms/step - loss: 0.0197 - accuracy: 0.8829 - val_loss: 0.0263 - val_accuracy: 0.8863\n",
            "Epoch 19/100\n",
            "126/126 [==============================] - 4s 34ms/step - loss: 0.0172 - accuracy: 0.8994 - val_loss: 0.0251 - val_accuracy: 0.8969\n",
            "Epoch 20/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0162 - accuracy: 0.9038 - val_loss: 0.0249 - val_accuracy: 0.8953\n",
            "Epoch 21/100\n",
            "126/126 [==============================] - 4s 34ms/step - loss: 0.0158 - accuracy: 0.9092 - val_loss: 0.0278 - val_accuracy: 0.9036\n",
            "Epoch 22/100\n",
            "126/126 [==============================] - 4s 34ms/step - loss: 0.0130 - accuracy: 0.9222 - val_loss: 0.0233 - val_accuracy: 0.9275\n",
            "Epoch 23/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0104 - accuracy: 0.9356 - val_loss: 0.0239 - val_accuracy: 0.9215\n",
            "Epoch 24/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0107 - accuracy: 0.9347 - val_loss: 0.0218 - val_accuracy: 0.9142\n",
            "Epoch 25/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0103 - accuracy: 0.9357 - val_loss: 0.0270 - val_accuracy: 0.9286\n",
            "Epoch 26/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0096 - accuracy: 0.9429 - val_loss: 0.0255 - val_accuracy: 0.9231\n",
            "Epoch 27/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0090 - accuracy: 0.9446 - val_loss: 0.0262 - val_accuracy: 0.9135\n",
            "Epoch 28/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0079 - accuracy: 0.9526 - val_loss: 0.0193 - val_accuracy: 0.9192\n",
            "Epoch 29/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0065 - accuracy: 0.9568 - val_loss: 0.0238 - val_accuracy: 0.9420\n",
            "Epoch 30/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0176 - accuracy: 0.9254 - val_loss: 0.0288 - val_accuracy: 0.9081\n",
            "Epoch 31/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0240 - accuracy: 0.8972 - val_loss: 0.0239 - val_accuracy: 0.9420\n",
            "Epoch 32/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0054 - accuracy: 0.9646 - val_loss: 0.0259 - val_accuracy: 0.9275\n",
            "Epoch 33/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0048 - accuracy: 0.9703 - val_loss: 0.0249 - val_accuracy: 0.9403\n",
            "Epoch 34/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0056 - accuracy: 0.9681 - val_loss: 0.0231 - val_accuracy: 0.9336\n",
            "Epoch 35/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0059 - accuracy: 0.9645 - val_loss: 0.0262 - val_accuracy: 0.9314\n",
            "Epoch 36/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0035 - accuracy: 0.9770 - val_loss: 0.0287 - val_accuracy: 0.9381\n",
            "Epoch 37/100\n",
            "126/126 [==============================] - 4s 34ms/step - loss: 0.0024 - accuracy: 0.9833 - val_loss: 0.0343 - val_accuracy: 0.9397\n",
            "Epoch 38/100\n",
            "126/126 [==============================] - 4s 34ms/step - loss: 0.0027 - accuracy: 0.9825 - val_loss: 0.0260 - val_accuracy: 0.9509\n",
            "Epoch 39/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0034 - accuracy: 0.9803 - val_loss: 0.0245 - val_accuracy: 0.9403\n",
            "Epoch 40/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0033 - accuracy: 0.9782 - val_loss: 0.0250 - val_accuracy: 0.9464\n",
            "Epoch 41/100\n",
            "126/126 [==============================] - 4s 34ms/step - loss: 0.0109 - accuracy: 0.9511 - val_loss: 0.0366 - val_accuracy: 0.9018\n",
            "Epoch 42/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0051 - accuracy: 0.9715 - val_loss: 0.0329 - val_accuracy: 0.9397\n",
            "Epoch 43/100\n",
            "126/126 [==============================] - 4s 34ms/step - loss: 0.0055 - accuracy: 0.9713 - val_loss: 0.0234 - val_accuracy: 0.9509\n",
            "Epoch 44/100\n",
            "126/126 [==============================] - 4s 34ms/step - loss: 0.0135 - accuracy: 0.9458 - val_loss: 0.0285 - val_accuracy: 0.9231\n",
            "Epoch 45/100\n",
            "126/126 [==============================] - 4s 35ms/step - loss: 0.0051 - accuracy: 0.9742 - val_loss: 0.0261 - val_accuracy: 0.9426\n",
            "Epoch 46/100\n",
            "126/126 [==============================] - 4s 34ms/step - loss: 0.0033 - accuracy: 0.9807 - val_loss: 0.0238 - val_accuracy: 0.9353\n",
            "Epoch 47/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0030 - accuracy: 0.9834 - val_loss: 0.0273 - val_accuracy: 0.9448\n",
            "Epoch 48/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0019 - accuracy: 0.9891 - val_loss: 0.0302 - val_accuracy: 0.9403\n",
            "Epoch 49/100\n",
            "126/126 [==============================] - 4s 34ms/step - loss: 0.0011 - accuracy: 0.9923 - val_loss: 0.0359 - val_accuracy: 0.9464\n",
            "Epoch 50/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0023 - accuracy: 0.9861 - val_loss: 0.0298 - val_accuracy: 0.9554\n",
            "Epoch 51/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0043 - accuracy: 0.9756 - val_loss: 0.0225 - val_accuracy: 0.9330\n",
            "Epoch 52/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0035 - accuracy: 0.9789 - val_loss: 0.0334 - val_accuracy: 0.9253\n",
            "Epoch 53/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0024 - accuracy: 0.9866 - val_loss: 0.0282 - val_accuracy: 0.9509\n",
            "Epoch 54/100\n",
            "126/126 [==============================] - 4s 34ms/step - loss: 0.0018 - accuracy: 0.9882 - val_loss: 0.0362 - val_accuracy: 0.9420\n",
            "Epoch 55/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0013 - accuracy: 0.9929 - val_loss: 0.0280 - val_accuracy: 0.9509\n",
            "Epoch 56/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0019 - accuracy: 0.9891 - val_loss: 0.0338 - val_accuracy: 0.9464\n",
            "Epoch 57/100\n",
            "126/126 [==============================] - 4s 34ms/step - loss: 0.0016 - accuracy: 0.9912 - val_loss: 0.0362 - val_accuracy: 0.9464\n",
            "Epoch 58/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0112 - accuracy: 0.9534 - val_loss: 0.0534 - val_accuracy: 0.8322\n",
            "Epoch 59/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0076 - accuracy: 0.9645 - val_loss: 0.0284 - val_accuracy: 0.9531\n",
            "Epoch 60/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0018 - accuracy: 0.9909 - val_loss: 0.0243 - val_accuracy: 0.9487\n",
            "Epoch 61/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0021 - accuracy: 0.9862 - val_loss: 0.0324 - val_accuracy: 0.9509\n",
            "Epoch 62/100\n",
            "126/126 [==============================] - 4s 34ms/step - loss: 0.0030 - accuracy: 0.9834 - val_loss: 0.0250 - val_accuracy: 0.9576\n",
            "Epoch 63/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0019 - accuracy: 0.9887 - val_loss: 0.0289 - val_accuracy: 0.9515\n",
            "Epoch 64/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0021 - accuracy: 0.9849 - val_loss: 0.0325 - val_accuracy: 0.9470\n",
            "Epoch 65/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0020 - accuracy: 0.9903 - val_loss: 0.0313 - val_accuracy: 0.9509\n",
            "Epoch 66/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0034 - accuracy: 0.9831 - val_loss: 0.0318 - val_accuracy: 0.9353\n",
            "Epoch 67/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0018 - accuracy: 0.9901 - val_loss: 0.0385 - val_accuracy: 0.9531\n",
            "Epoch 68/100\n",
            "126/126 [==============================] - 4s 34ms/step - loss: 0.0038 - accuracy: 0.9787 - val_loss: 0.0380 - val_accuracy: 0.9426\n",
            "Epoch 69/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0022 - accuracy: 0.9866 - val_loss: 0.0379 - val_accuracy: 0.9487\n",
            "Epoch 70/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0033 - accuracy: 0.9820 - val_loss: 0.0379 - val_accuracy: 0.9432\n",
            "Epoch 71/100\n",
            "126/126 [==============================] - 4s 34ms/step - loss: 0.0015 - accuracy: 0.9911 - val_loss: 0.0373 - val_accuracy: 0.9531\n",
            "Epoch 72/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 7.9648e-04 - accuracy: 0.9947 - val_loss: 0.0381 - val_accuracy: 0.9598\n",
            "Epoch 73/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0011 - accuracy: 0.9945 - val_loss: 0.0354 - val_accuracy: 0.9531\n",
            "Epoch 74/100\n",
            "126/126 [==============================] - 4s 34ms/step - loss: 9.5196e-04 - accuracy: 0.9939 - val_loss: 0.0334 - val_accuracy: 0.9643\n",
            "Epoch 75/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0150 - accuracy: 0.9497 - val_loss: 0.0249 - val_accuracy: 0.9576\n",
            "Epoch 76/100\n",
            "126/126 [==============================] - 4s 34ms/step - loss: 0.0057 - accuracy: 0.9792 - val_loss: 0.0273 - val_accuracy: 0.9442\n",
            "Epoch 77/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0078 - accuracy: 0.9655 - val_loss: 0.0299 - val_accuracy: 0.9442\n",
            "Epoch 78/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0016 - accuracy: 0.9906 - val_loss: 0.0332 - val_accuracy: 0.9509\n",
            "Epoch 79/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0010 - accuracy: 0.9941 - val_loss: 0.0319 - val_accuracy: 0.9576\n",
            "Epoch 80/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 7.4246e-04 - accuracy: 0.9959 - val_loss: 0.0315 - val_accuracy: 0.9576\n",
            "Epoch 81/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 3.8080e-04 - accuracy: 0.9980 - val_loss: 0.0417 - val_accuracy: 0.9576\n",
            "Epoch 82/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0012 - accuracy: 0.9939 - val_loss: 0.0355 - val_accuracy: 0.9464\n",
            "Epoch 83/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0025 - accuracy: 0.9895 - val_loss: 0.0290 - val_accuracy: 0.9643\n",
            "Epoch 84/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0020 - accuracy: 0.9887 - val_loss: 0.0312 - val_accuracy: 0.9531\n",
            "Epoch 85/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0017 - accuracy: 0.9914 - val_loss: 0.0319 - val_accuracy: 0.9560\n",
            "Epoch 86/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0013 - accuracy: 0.9923 - val_loss: 0.0365 - val_accuracy: 0.9509\n",
            "Epoch 87/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0018 - accuracy: 0.9898 - val_loss: 0.0342 - val_accuracy: 0.9576\n",
            "Epoch 88/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0069 - accuracy: 0.9694 - val_loss: 0.0515 - val_accuracy: 0.9081\n",
            "Epoch 89/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0086 - accuracy: 0.9670 - val_loss: 0.0373 - val_accuracy: 0.9487\n",
            "Epoch 90/100\n",
            "126/126 [==============================] - 4s 34ms/step - loss: 0.0015 - accuracy: 0.9915 - val_loss: 0.0378 - val_accuracy: 0.9448\n",
            "Epoch 91/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0013 - accuracy: 0.9924 - val_loss: 0.0292 - val_accuracy: 0.9420\n",
            "Epoch 92/100\n",
            "126/126 [==============================] - 4s 34ms/step - loss: 0.0011 - accuracy: 0.9944 - val_loss: 0.0343 - val_accuracy: 0.9554\n",
            "Epoch 93/100\n",
            "126/126 [==============================] - 4s 34ms/step - loss: 0.0017 - accuracy: 0.9908 - val_loss: 0.0352 - val_accuracy: 0.9509\n",
            "Epoch 94/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0012 - accuracy: 0.9933 - val_loss: 0.0320 - val_accuracy: 0.9531\n",
            "Epoch 95/100\n",
            "126/126 [==============================] - 4s 34ms/step - loss: 0.0014 - accuracy: 0.9914 - val_loss: 0.0345 - val_accuracy: 0.9509\n",
            "Epoch 96/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0014 - accuracy: 0.9913 - val_loss: 0.0293 - val_accuracy: 0.9464\n",
            "Epoch 97/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0011 - accuracy: 0.9936 - val_loss: 0.0339 - val_accuracy: 0.9576\n",
            "Epoch 98/100\n",
            "126/126 [==============================] - 4s 34ms/step - loss: 0.0012 - accuracy: 0.9937 - val_loss: 0.0366 - val_accuracy: 0.9576\n",
            "Epoch 99/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.0014 - accuracy: 0.9911 - val_loss: 0.0366 - val_accuracy: 0.9509\n"
          ]
        }
      ],
      "source": [
        "early_stopping = EarlyStopping(monitor=\"val_accuracy\", patience=25, restore_best_weights=True)\n",
        "\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[accuracy])\n",
        "\n",
        "# train model\n",
        "history = model.fit([dev_ctx_e, dev_tags_e, dev_words_e], dev_lemmas_e, epochs=100, batch_size=64, validation_data=([val_ctx_e, val_tags_e, val_words_e], val_lemmas_e), callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7AMK_4pCXvx"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oR3saAaeCXvy",
        "outputId": "bdb3e0cf-c7ee-48ed-d976-c9b6cf77c83c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2038/2038 [==============================] - 25s 12ms/step - loss: 0.0323 - accuracy: 0.9507\n",
            "Test loss:  0.0322524830698967\n",
            "Test accuracy:  0.9507447481155396\n"
          ]
        }
      ],
      "source": [
        "# evaluate model\n",
        "result = model.evaluate([test_ctx_e, test_tags_e, test_words_e], test_lemmas_e)\n",
        "print(\"Test loss: \", result[0])\n",
        "print(\"Test accuracy: \", result[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nz_GK7n-M8u8",
        "outputId": "89a20925-ebba-4527-d585-d0d800ed2b42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2038/2038 [==============================] - 28s 12ms/step\n",
            "Absolute error with respect to the PoS tag: \n",
            "v 0.531\n",
            "adj 0.128\n",
            "nn 0.297\n",
            "adv 0.045\n",
            "\n",
            "Relative error with respect to the PoS tag: \n",
            "v 0.083\n",
            "adj 0.031\n",
            "nn 0.034\n",
            "adv 0.02\n"
          ]
        }
      ],
      "source": [
        "# Absolute error with respect to the PoS tag\n",
        "\n",
        "pred = model.predict([test_ctx_e, test_tags_e, test_words_e])\n",
        "\n",
        "tot_error = 0\n",
        "error_per_tag = {}\n",
        "tag_count = {}\n",
        "\n",
        "for i in range(len(test_lemmas_e)): \n",
        "    tag = test_tag[i].split(\"_\")[0]\n",
        "\n",
        "    if tag not in tag_count:\n",
        "            tag_count[tag] = 1\n",
        "    else:\n",
        "        tag_count[tag] += 1\n",
        "\n",
        "    if test_lemmas_e[i].argmax() != pred[i].argmax():\n",
        "        tot_error += 1\n",
        "        \n",
        "        if tag not in error_per_tag:\n",
        "            error_per_tag[tag] = 1\n",
        "        else:\n",
        "            error_per_tag[tag] += 1\n",
        "\n",
        "print(\"Absolute error with respect to the PoS tag: \")\n",
        "for tag in error_per_tag:\n",
        "    print(tag, round(error_per_tag[tag] / tot_error,3))\n",
        "\n",
        "print(\"\\nRelative error with respect to the PoS tag: \")\n",
        "for tag in error_per_tag:\n",
        "    print(tag, round(error_per_tag[tag] / tag_count[tag], 3))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "08eac26dc1f80337b7d87e94e7159a5bad95c2e85f47efef91c61359b3afbfe9"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
