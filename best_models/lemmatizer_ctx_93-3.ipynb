{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlXK_WPhCXve"
      },
      "source": [
        "# Italian Word Lemmatizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfFQpeq7CXvj"
      },
      "source": [
        "### Import\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "1m3hfyemCXvj"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import backend as K\n",
        "from keras.layers import Input, LSTM, Dense, Embedding, Concatenate, Bidirectional, TimeDistributed, RepeatVector, Activation, Dot, Lambda, Dropout, Add, Multiply, Masking, Attention\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import gensim\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "# set all random seeds\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEeIQWgECXvk"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcBN-hJ3CXvl",
        "outputId": "c89037c5-fa97-4a4e-c929-431b88774f0e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-45-75ad934a2086>:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_test[\"word\"] = df_test[\"word\"].str.lower()\n",
            "<ipython-input-45-75ad934a2086>:24: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_dev[\"word\"] = df_dev[\"word\"].str.lower()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max sentence length:  95\n",
            "Max sentence length:  107\n",
            "Number of sentences in dev set:  703\n",
            "Number of sentences in test set:  5596\n",
            "Number of unique tags:  32\n"
          ]
        }
      ],
      "source": [
        "\n",
        "dataset_path = \"./dev.csv\"\n",
        "df_dev = pd.read_csv(dataset_path, sep=\"\\t\", header=None,\n",
        "                     names=[\"word\", \"tag\", \"lemm\"])\n",
        "\n",
        "dataset_path = \"./test.csv\"\n",
        "df_test = pd.read_csv(dataset_path, sep=\"\\t\", header=None,\n",
        "                      names=[\"word\", \"tag\", \"lemm\"])\n",
        "\n",
        "df_dev[\"word\"] = df_dev[\"word\"].astype(str)\n",
        "df_dev[\"tag\"] = df_dev[\"tag\"].astype(str)\n",
        "df_dev[\"lemm\"] = df_dev[\"lemm\"].astype(str)\n",
        "\n",
        "df_test[\"word\"] = df_test[\"word\"].astype(str)\n",
        "df_test[\"tag\"] = df_test[\"tag\"].astype(str)\n",
        "df_test[\"lemm\"] = df_test[\"lemm\"].astype(str)\n",
        "\n",
        "# remove head\n",
        "df_dev = df_dev.iloc[1:]\n",
        "df_test = df_test.iloc[1:]\n",
        "\n",
        "\n",
        "# lower case all words\n",
        "df_test[\"word\"] = df_test[\"word\"].str.lower()\n",
        "df_dev[\"word\"] = df_dev[\"word\"].str.lower()\n",
        "\n",
        "\n",
        "def get_sentences(df):\n",
        "    words = []\n",
        "    tags = []\n",
        "    lemmas = []\n",
        "    sentence = []\n",
        "    max_s = 0\n",
        "    for index, row in df.iterrows():\n",
        "        word = row[\"word\"]\n",
        "        tag = row[\"tag\"]\n",
        "        lemm = row[\"lemm\"]\n",
        "        sentence.append([word, tag, lemm])\n",
        "\n",
        "        if row[\"word\"] in [\".\", \"?\", \"!\", \";\"]:\n",
        "            words.append([word for word, tag, lemm in sentence])\n",
        "            tags.append([tag for word, tag, lemm in sentence])\n",
        "            lemmas.append([lemm for word, tag, lemm in sentence])\n",
        "            max_s = max(max_s, len(sentence))\n",
        "            sentence = []\n",
        "\n",
        "    print(\"Max sentence length: \", max_s)\n",
        "    return words, tags, lemmas\n",
        "\n",
        "# _s is for string\n",
        "dev_words_s, dev_tags_s, dev_lemmas_s = get_sentences(df_dev)\n",
        "test_words_s, test_tags_s, test_lemmas_s = get_sentences(df_test)\n",
        "print(\"Number of sentences in dev set: \", len(dev_words_s))\n",
        "print(\"Number of sentences in test set: \", len(test_words_s))\n",
        "\n",
        "# print number of unique tags\n",
        "print(\"Number of unique tags: \", len(df_dev[\"tag\"].unique()))\n",
        "\n",
        "for i in range(len(dev_words_s)):\n",
        "    if len(dev_words_s[i]) != len(dev_tags_s[i]) or len(dev_words_s[i]) != len(dev_lemmas_s[i]):\n",
        "        print(\"Dimension mismatch in sentence: \", i)\n",
        "        print(\"Words: \", dev_words_s[i])\n",
        "        print(\"Tags: \", dev_tags_s[i])\n",
        "        print(\"Lemmas: \", dev_lemmas_s[i])\n",
        "        break\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "yJ04hS-bCXvl",
        "outputId": "591611a1-36fa-4844-e809-85c4ac6830d8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plot tag distribution\n",
        "tags = []\n",
        "for tag_list in dev_tags_s:\n",
        "    tags.extend(tag_list)\n",
        "\n",
        "tags = pd.Series(tags)\n",
        "tags.value_counts().plot(kind=\"bar\", figsize=(20, 10))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QieUyx1CCXvo"
      },
      "source": [
        "## Word Context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9dkBA-zCXvo",
        "outputId": "bedfb779-a16b-46db-b31c-902991e2a18f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of sample in dev set:  16447\n",
            "Number of sample in val set:  866\n",
            "Number of sample in test set:  133756\n"
          ]
        }
      ],
      "source": [
        "CTX_DIM = 12            # context dimension, 12 words on each side\n",
        "PRE_VALUE = \"<PRE>\"     # value for padding pre \n",
        "POST_VALUE = \"<POST>\"   # value for padding post\n",
        "NONE_TAG = \"<NONE>\"     # value for padding tags\n",
        "\n",
        "def get_context(words, tags, lemmas):\n",
        "    ctx = []    # context list\n",
        "    w = []      # word list\n",
        "    tag = []    # context tags list\n",
        "    t = []      # word tags list\n",
        "    lemma = []  # lemma list\n",
        "\n",
        "    for s_index in range(len(words)):\n",
        "        s = words[s_index]\n",
        "        s_tags = tags[s_index]\n",
        "        sentence = \" \".join(s)\n",
        "        s = [PRE_VALUE] * CTX_DIM + s + [POST_VALUE] * CTX_DIM\n",
        "        s_tags = [NONE_TAG] * CTX_DIM + s_tags + [NONE_TAG] * CTX_DIM\n",
        "\n",
        "        for w_index in range(len(s)):\n",
        "            if w_index < CTX_DIM or w_index >= len(s) - CTX_DIM:\n",
        "                continue\n",
        "\n",
        "            context = s[w_index - CTX_DIM:w_index] + [s[w_index]] +s[w_index + 1:w_index  + CTX_DIM + 1]\n",
        "            context = \" \".join(context)\n",
        "            ctx.append(context)\n",
        "            w.append(words[s_index][w_index-CTX_DIM])\n",
        "\n",
        "            ctx_tags = s_tags[w_index - CTX_DIM:w_index] + [s_tags[w_index]] + s_tags[w_index + 1:w_index  + CTX_DIM + 1]\n",
        "            tag.append(ctx_tags)\n",
        "            t.append(tags[s_index][w_index-CTX_DIM])\n",
        "\n",
        "            lemma.append(lemmas[s_index][w_index-CTX_DIM])\n",
        "    return ctx, w, tag, t, lemma\n",
        "\n",
        "dev_ctx, dev_words, dev_tags, dev_tag,dev_lemmas = get_context(dev_words_s, dev_tags_s, dev_lemmas_s)\n",
        "test_ctx, test_words, test_tags, test_tag,test_lemmas = get_context(test_words_s, test_tags_s, test_lemmas_s)\n",
        "\n",
        "dev_ctx, val_ctx, dev_words, val_words, dev_tags, val_tags, dev_tag, val_tag, dev_lemmas, val_lemmas = train_test_split(dev_ctx, dev_words, dev_tags, dev_tag, dev_lemmas, test_size=0.05, random_state=42)\n",
        "\n",
        "print(\"Number of sample in dev set: \", len(dev_lemmas))\n",
        "print(\"Number of sample in val set: \", len(val_lemmas))\n",
        "print(\"Number of sample in test set: \", len(test_lemmas))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfMwZrgcCXvo"
      },
      "source": [
        "### Example of context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVoxwHO4CXvp",
        "outputId": "0f020c70-b9ab-4232-ae6e-fe97160fdf31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CTX Dim: 12 \n",
            "\n",
            "CTX:  <PRE> ma i blair , con i ragazzi da distrarre , avevano altre idee . <POST> <POST> <POST> <POST> <POST> <POST> <POST> <POST> <POST> <POST>\n",
            "CTX Tags:  ['<NONE>', 'conj_c', 'art', 'nn_p', 'p_oth', 'prep', 'art', 'nn', 'prep', 'v_gvrb', 'p_oth', 'v_avere', 'adj_ind', 'nn', 'p_eos', '<NONE>', '<NONE>', '<NONE>', '<NONE>', '<NONE>', '<NONE>', '<NONE>', '<NONE>', '<NONE>', '<NONE>']\n",
            "Word:  altre\n",
            "Tag:  adj_ind\n",
            "Lemma:  altro\n",
            "\n",
            "CTX:  rigorosamente accademico , corredata da una ricca e del tutto inverosimile bibliografia e arricchita da numerose tavole iconografiche , &egrave; stata recentemente pubblicata anche in\n",
            "CTX Tags:  ['adv', 'adj', 'p_oth', 'v_pp', 'prep', 'art', 'adj', 'conj_c', 'prep_a', 'nn', 'adj', 'nn', 'conj_c', 'v_pp', 'prep', 'adj', 'nn', 'adj', 'p_oth', 'v_essere', 'v_essere', 'adv', 'v_pp', 'conj_c', 'prep']\n",
            "Word:  e\n",
            "Tag:  conj_c\n",
            "Lemma:  e\n",
            "\n",
            "CTX:  * difesa dei diritti dei curdi l' italia porter&agrave; davanti_ai fori internazionali la questione dei diritti del popolo curdo . <POST> <POST> <POST> <POST> <POST>\n",
            "CTX Tags:  ['p_oth', 'nn', 'prep_a', 'nn', 'prep_a', 'nn', 'art', 'nn_p', 'v_gvrb', 'prep_a', 'nn', 'adj', 'art', 'nn', 'prep_a', 'nn', 'prep_a', 'nn', 'adj', 'p_eos', '<NONE>', '<NONE>', '<NONE>', '<NONE>', '<NONE>']\n",
            "Word:  la\n",
            "Tag:  art\n",
            "Lemma:  la\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"CTX Dim:\", CTX_DIM, \"\\n\")\n",
        "for i in range(3):\n",
        "    index = np.random.randint(0, len(dev_ctx))\n",
        "    print(\"CTX: \", dev_ctx[index])\n",
        "    print(\"CTX Tags: \", dev_tags[index])\n",
        "    print(\"Word: \", dev_words[index])\n",
        "    print(\"Tag: \", dev_tag[index])\n",
        "    print(\"Lemma: \", dev_lemmas[index])\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDN8khxaCXvp"
      },
      "source": [
        "## Open Class Words\n",
        "The evaluation is done only on open-class words and not to functional words: only the tokens having a PoS-tag comprised in the set ADJ *, ADV, NN, V * had to be lemmatised, in all the other cases the token could be copied unchanged into the lemma column as they were not considered for the evaluation (the asterisk indicates all PoS-tag possibilities beginning with that prefix)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Su-C7kFTCXvp",
        "outputId": "236178de-137c-4176-c6cd-d596a9249e95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of open class words in dev set:  8741\n",
            "Number of open class words in val set:  448\n",
            "Number of open class words in test set:  70795\n"
          ]
        }
      ],
      "source": [
        "def get_open_class_words(ctx, words, tags, tag, lemmas):\n",
        "    open_class_words = []\n",
        "    open_class_ctx = []\n",
        "    open_class_tags = []\n",
        "    open_class_lemmas = []\n",
        "\n",
        "    open_classes = [\"nn\", \"nn_p\", \"v_gvrb\", \"v_essere\", \"v_avere\", \"v_pp\", \"v_mod\", \"v_clit\", \"adv\", \"adj_ind\", \"adj_num\", \"adj\", \"adj_pos\", \"adj_dim\", \"adj_ies\"]\n",
        "\n",
        "    for i in range(len(words)):\n",
        "        t = tag[i]\n",
        "        if t in open_classes:\n",
        "            open_class_words.append(words[i])\n",
        "            open_class_ctx.append(ctx[i])\n",
        "            open_class_tags.append(tags[i])\n",
        "            open_class_lemmas.append(lemmas[i])\n",
        "\n",
        "    return open_class_ctx, open_class_words, open_class_tags, open_class_lemmas\n",
        "\n",
        "\n",
        "test_ctx, test_words, test_tags, test_lemmas = get_open_class_words(test_ctx, test_words, test_tags, test_tag, test_lemmas)\n",
        "dev_ctx, dev_words, dev_tags, dev_lemmas = get_open_class_words(dev_ctx, dev_words, dev_tags, dev_tag, dev_lemmas)\n",
        "val_ctx, val_words, val_tags, val_lemmas = get_open_class_words(val_ctx, val_words, val_tags, val_tag, val_lemmas)\n",
        "\n",
        "print(\"Number of open class words in dev set: \", len(dev_words))\n",
        "print(\"Number of open class words in val set: \", len(val_words)) \n",
        "print(\"Number of open class words in test set: \", len(test_words))  \n",
        "# total 79984"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4TNe-0-CXvq"
      },
      "source": [
        "## Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDgvmCucCXvq",
        "outputId": "4dbb3ea3-d7f3-4bac-c359-f7e1a7fd7f80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocab size:  60\n",
            "Max word length:  25\n",
            "\n",
            "Context: \n",
            " <PRE> <PRE> <PRE> <PRE> <PRE> <PRE> <PRE> <PRE> <PRE> un dovere da compiere , visto_che le loro altezze con tono scherzoso hanno subito precisato che \n",
            " [1, 1, 1, 1, 1, 1, 1, 1, 1, 11, 4746, 26, 1941, 3, 621, 20, 52, 6147, 23, 1997, 10599, 55, 387, 6148, 7]\n",
            "\n",
            "Tags: \n",
            " ['<NONE>', '<NONE>', '<NONE>', '<NONE>', '<NONE>', '<NONE>', '<NONE>', '<NONE>', '<NONE>', 'art', 'nn', 'prep', 'v_gvrb', 'p_oth', 'conj_s', 'art', 'adj_pos', 'nn', 'prep', 'nn', 'adj', 'v_avere', 'adv', 'v_pp', 'conj_s'] \n",
            " [1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 2, 3, 7, 5, 17, 4, 20, 2, 3, 2, 6, 18, 9, 12, 17]\n",
            "\n",
            "Words: \n",
            " compiere \n",
            " [36 48 46 49 42 38 51 38  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0]\n",
            "\n",
            "Lemma: \n",
            " compiere \n",
            " [36 48 46 49 42 38 51 38  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0]\n"
          ]
        }
      ],
      "source": [
        "# word encoder\n",
        "word_tokenizer = Tokenizer(filters=\"\")\n",
        "word_tokenizer.fit_on_texts(dev_ctx + test_ctx + val_ctx)\n",
        "\n",
        "# tag encoder\n",
        "tag_tokenizer = Tokenizer(filters=\"\")\n",
        "tag_tokenizer.fit_on_texts(dev_tags + test_tags + val_tags)\n",
        "\n",
        "# lemma encoder\n",
        "lemma_tokenizer = Tokenizer(filters=\"\")\n",
        "lemma_tokenizer.fit_on_texts(dev_lemmas_s + test_lemmas_s)\n",
        "\n",
        "dev_ctx_e = word_tokenizer.texts_to_sequences(dev_ctx)\n",
        "val_ctx_e = word_tokenizer.texts_to_sequences(val_ctx)\n",
        "test_ctx_e = word_tokenizer.texts_to_sequences(test_ctx)\n",
        "\n",
        "dev_tags_e = tag_tokenizer.texts_to_sequences(dev_tags)\n",
        "val_tags_e = tag_tokenizer.texts_to_sequences(val_tags)\n",
        "test_tags_e = tag_tokenizer.texts_to_sequences(test_tags)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# get all unique letter in words\n",
        "characters = set()\n",
        "\n",
        "for lemma in df_dev[\"lemm\"].unique():\n",
        "    for letter in lemma:\n",
        "        characters.add(letter)\n",
        "\n",
        "for lemma in df_test[\"lemm\"].unique():\n",
        "    for letter in lemma:\n",
        "        characters.add(letter)\n",
        "\n",
        "for word in df_dev[\"word\"].unique():\n",
        "    for letter in word:\n",
        "        characters.add(letter)\n",
        "\n",
        "for word in df_test[\"word\"].unique():\n",
        "    for letter in word:\n",
        "        characters.add(letter)\n",
        "    \n",
        "\n",
        "# add padding and unknown to characters\n",
        "characters.add(\" \")\n",
        "\n",
        "# the length of the vocab for one-hot encoded char\n",
        "VOCAB_SIZE = len(characters)\n",
        "\n",
        "print (\"Vocab size: \", VOCAB_SIZE)\n",
        "# order characters\n",
        "characters = sorted(list(characters))\n",
        "\n",
        "\n",
        "char2idx = {char: idx for idx, char in enumerate(characters)}\n",
        "idx2char = {idx: char for idx, char in enumerate(characters)}\n",
        "\n",
        "MAX_WORD_LENGTH = 0\n",
        "for w in dev_words + test_words + dev_lemmas + test_lemmas + val_words + val_lemmas:\n",
        "    MAX_WORD_LENGTH = max(MAX_WORD_LENGTH, len(w))\n",
        "print(\"Max word length: \", MAX_WORD_LENGTH)\n",
        "\n",
        "def encode_words(words):\n",
        "    encoded_words = []\n",
        "    for word in words:\n",
        "        word_e = []\n",
        "        for letter in word:\n",
        "            word_e.append(characters.index(letter))\n",
        "        encoded_words.append(word_e)\n",
        "    return encoded_words\n",
        "\n",
        "dev_words_e = encode_words(dev_words)\n",
        "test_words_e = encode_words(test_words)\n",
        "val_words_e = encode_words(val_words)\n",
        "\n",
        "dev_lemmas_e = encode_words(dev_lemmas)\n",
        "test_lemmas_e = encode_words(test_lemmas)\n",
        "val_lemmas_e = encode_words(val_lemmas)\n",
        "\n",
        "dev_words_e = tf.keras.preprocessing.sequence.pad_sequences(dev_words_e, maxlen=MAX_WORD_LENGTH, padding=\"post\")\n",
        "test_words_e = tf.keras.preprocessing.sequence.pad_sequences(test_words_e, maxlen=MAX_WORD_LENGTH, padding=\"post\")\n",
        "val_words_e = tf.keras.preprocessing.sequence.pad_sequences(val_words_e, maxlen=MAX_WORD_LENGTH, padding=\"post\")\n",
        "\n",
        "dev_lemmas_e = tf.keras.preprocessing.sequence.pad_sequences(dev_lemmas_e, maxlen=MAX_WORD_LENGTH, padding=\"post\")\n",
        "test_lemmas_e = tf.keras.preprocessing.sequence.pad_sequences(test_lemmas_e, maxlen=MAX_WORD_LENGTH, padding=\"post\")\n",
        "val_lemmas_e = tf.keras.preprocessing.sequence.pad_sequences(val_lemmas_e, maxlen=MAX_WORD_LENGTH, padding=\"post\")\n",
        "\n",
        "index = np.random.randint(0, len(dev_ctx))\n",
        "print(\"\\nContext: \\n\", dev_ctx[index], \"\\n\", dev_ctx_e[index])\n",
        "print(\"\\nTags: \\n\", dev_tags[index], \"\\n\", dev_tags_e[index])\n",
        "print(\"\\nWords: \\n\", dev_words[index], \"\\n\", dev_words_e[index])\n",
        "print(\"\\nLemma: \\n\", dev_lemmas[index], \"\\n\", dev_lemmas_e[index])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "pXlZTReRCXvq"
      },
      "outputs": [],
      "source": [
        "# one hot encode the characters for the lemmas\n",
        "dev_lemmas_e = tf.one_hot(dev_lemmas_e, VOCAB_SIZE)\n",
        "test_lemmas_e = tf.one_hot(test_lemmas_e, VOCAB_SIZE)\n",
        "val_lemmas_e = tf.one_hot(val_lemmas_e, VOCAB_SIZE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtsh2qnGCXvs",
        "outputId": "d9a4abe3-ea2b-4c32-9594-2bcac2293b7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape\n",
            "Context shape:  (8741, 25)\n",
            "Words shape:  (8741, 25)\n",
            "Tags shape:  (8741, 25)\n",
            "Lemmas shape:  (8741, 25, 60)\n",
            "\n",
            "Test shape\n",
            "Context shape:  (70795, 25)\n",
            "Words shape:  (70795, 25)\n",
            "Tags shape:  (70795, 25)\n",
            "Lemmas shape:  (70795, 25, 60)\n"
          ]
        }
      ],
      "source": [
        "# trnasform to numpy array\n",
        "dev_ctx_e = np.array(dev_ctx_e)\n",
        "dev_words_e = np.array(dev_words_e)\n",
        "dev_tags_e = np.array(dev_tags_e)\n",
        "dev_lemmas_e = np.array(dev_lemmas_e)\n",
        "\n",
        "test_ctx_e = np.array(test_ctx_e)\n",
        "test_words_e = np.array(test_words_e)\n",
        "test_tags_e = np.array(test_tags_e)\n",
        "test_lemmas_e = np.array(test_lemmas_e)\n",
        "\n",
        "val_ctx_e = np.array(val_ctx_e)\n",
        "val_words_e = np.array(val_words_e)\n",
        "val_tags_e = np.array(val_tags_e)\n",
        "val_lemmas_e = np.array(val_lemmas_e)\n",
        "\n",
        "print(\"Train shape\")\n",
        "print(\"Context shape: \", dev_ctx_e.shape)\n",
        "print(\"Words shape: \", dev_words_e.shape)\n",
        "print(\"Tags shape: \", dev_tags_e.shape)\n",
        "print(\"Lemmas shape: \", dev_lemmas_e.shape)\n",
        "\n",
        "print(\"\\nTest shape\")\n",
        "print(\"Context shape: \", test_ctx_e.shape)\n",
        "print(\"Words shape: \", test_words_e.shape)\n",
        "print(\"Tags shape: \", test_tags_e.shape)\n",
        "print(\"Lemmas shape: \", test_lemmas_e.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLAyRU0RCXvs"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xj8391mwCXvs"
      },
      "source": [
        "### Lemmatization Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "2YpdToIbCXvs"
      },
      "outputs": [],
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "    y_true = tf.argmax(y_true, axis=-1)\n",
        "    y_pred = tf.argmax(y_pred, axis=-1)\n",
        "    correct_predictions = tf.reduce_all(tf.equal(y_true, y_pred), axis=-1)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
        "    return accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqY9BzpyCXvv"
      },
      "source": [
        "### Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wY0OBxc2CXvv",
        "outputId": "583838fa-2536-4896-d43e-20ca03fe1175"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n"
          ]
        }
      ],
      "source": [
        "EMBEDDING_DIM = 512\n",
        "VOCABULARY_SIZE = len(word_tokenizer.word_index) + 1\n",
        "\n",
        "def get_word2vec_weights(DIM):\n",
        "    # train word2vec model\n",
        "    word2vec = gensim.models.Word2Vec(dev_ctx + val_ctx + test_ctx, size=DIM, window=10, min_count=1, workers=8)\n",
        "\n",
        "    # create an empty embedding matix\n",
        "    embedding_weights = np.zeros((VOCABULARY_SIZE, DIM))\n",
        "\n",
        "    # create a word to index dictionary mapping\n",
        "    word2id = word_tokenizer.word_index\n",
        "\n",
        "    # copy vectors from word2vec model to the words present in corpus\n",
        "    for word, index in word2id.items():\n",
        "        try:\n",
        "            embedding_weights[index, :] = word2vec.wv[word]\n",
        "        except KeyError:\n",
        "            pass\n",
        "\n",
        "    return embedding_weights\n",
        "\n",
        "embedding_weights = get_word2vec_weights(EMBEDDING_DIM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flAnhFU9CXvv",
        "outputId": "9f17c9ee-0d45-4372-ee7e-5222365b22b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " tags_input (InputLayer)        [(None, 25)]         0           []                               \n",
            "                                                                                                  \n",
            " input_7 (InputLayer)           [(None, 25)]         0           []                               \n",
            "                                                                                                  \n",
            " tags_embedding (Embedding)     (None, 25, 64)       2176        ['tags_input[0][0]']             \n",
            "                                                                                                  \n",
            " context_embedding (Embedding)  (None, 25, 512)      10131968    ['input_7[0][0]']                \n",
            "                                                                                                  \n",
            " bidirectional_10 (Bidirectiona  (None, 25, 128)     66048       ['tags_embedding[1][0]']         \n",
            " l)                                                                                               \n",
            "                                                                                                  \n",
            " input_8 (InputLayer)           [(None, 25)]         0           []                               \n",
            "                                                                                                  \n",
            " bidirectional_9 (Bidirectional  (None, 25, 1024)    4198400     ['context_embedding[1][0]']      \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " time_distributed_15 (TimeDistr  (None, 25, 1024)    132096      ['bidirectional_10[1][0]']       \n",
            " ibuted)                                                                                          \n",
            "                                                                                                  \n",
            " words_embedding (Embedding)    (None, 25, 512)      30720       ['input_8[0][0]']                \n",
            "                                                                                                  \n",
            " attention (Attention)          (None, 25, 1024)     0           ['bidirectional_9[1][0]',        \n",
            "                                                                  'time_distributed_15[1][0]']    \n",
            "                                                                                                  \n",
            " bidirectional_11 (Bidirectiona  (None, 25, 1024)    4198400     ['words_embedding[1][0]']        \n",
            " l)                                                                                               \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 25, 2048)     0           ['attention[1][0]',              \n",
            "                                                                  'bidirectional_11[1][0]']       \n",
            "                                                                                                  \n",
            " lstm (Bidirectional)           (None, 25, 1024)     10489856    ['concatenate_3[1][0]']          \n",
            "                                                                                                  \n",
            " dropout_12 (Dropout)           (None, 25, 1024)     0           ['lstm[1][0]']                   \n",
            "                                                                                                  \n",
            " lstm2 (Bidirectional)          (None, 25, 1024)     6295552     ['dropout_12[1][0]']             \n",
            "                                                                                                  \n",
            " time_distributed_16 (TimeDistr  (None, 25, 512)     524800      ['lstm2[1][0]']                  \n",
            " ibuted)                                                                                          \n",
            "                                                                                                  \n",
            " dropout_13 (Dropout)           (None, 25, 512)      0           ['time_distributed_16[1][0]']    \n",
            "                                                                                                  \n",
            " time_distributed_17 (TimeDistr  (None, 25, 512)     262656      ['dropout_13[1][0]']             \n",
            " ibuted)                                                                                          \n",
            "                                                                                                  \n",
            " dropout_14 (Dropout)           (None, 25, 512)      0           ['time_distributed_17[1][0]']    \n",
            "                                                                                                  \n",
            " time_distributed_18 (TimeDistr  (None, 25, 512)     262656      ['dropout_14[1][0]']             \n",
            " ibuted)                                                                                          \n",
            "                                                                                                  \n",
            " dropout_15 (Dropout)           (None, 25, 512)      0           ['time_distributed_18[1][0]']    \n",
            "                                                                                                  \n",
            " time_distributed_19 (TimeDistr  (None, 25, 512)     262656      ['dropout_15[1][0]']             \n",
            " ibuted)                                                                                          \n",
            "                                                                                                  \n",
            " output (TimeDistributed)       (None, 25, 60)       30780       ['time_distributed_19[1][0]']    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 36,888,764\n",
            "Trainable params: 26,756,796\n",
            "Non-trainable params: 10,131,968\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Neural network model\n",
        "# inputs:\n",
        "#   - context: (batch_size, CTX_DIM * 2) \n",
        "#   - tags: encoded tags: (batch_size, MAX_WORD_LENGTH)\n",
        "#   - words: encoded words: (batch_size, MAX_WORD_LENGTH)\n",
        "# outputs:\n",
        "#  - lemma: encoded lemma: (batch_size, MAX_WORD_LENGTH)\n",
        "\n",
        "def get_model():\n",
        "    # context\n",
        "    context_input = Input(shape=(CTX_DIM * 2 + 1,), name=\"context_input\")\n",
        "    context_input = Masking(mask_value=1)(context_input)\n",
        "    context_input = Masking(mask_value=2)(context_input)\n",
        "    context_embedding = Embedding(len(word_tokenizer.word_index) + 1, EMBEDDING_DIM, input_length=CTX_DIM * 2 + 1,name=\"context_embedding\", trainable=False, weights=[embedding_weights])(context_input)\n",
        "    context_embedding = Bidirectional(LSTM(EMBEDDING_DIM, return_sequences=True))(context_embedding)\n",
        "\n",
        "    # tags\n",
        "    tags_input = Input(shape=(CTX_DIM * 2 + 1,), name=\"tags_input\")\n",
        "    tags_embedding = Embedding(len(tag_tokenizer.word_index) + 1, 64, input_length=CTX_DIM * 2 + 1, name=\"tags_embedding\", trainable=True)(tags_input)\n",
        "    tags_embedding = Bidirectional(LSTM(64, return_sequences=True))(tags_embedding)\n",
        "    tags_embedding = TimeDistributed(Dense(EMBEDDING_DIM*2))(tags_embedding)\n",
        "    \n",
        "    # words\n",
        "    words_input = Input(shape=(MAX_WORD_LENGTH,), name=\"words_input\")\n",
        "    words_input = Masking(mask_value=0)(words_input)\n",
        "    words_embedding = Embedding(VOCAB_SIZE, int(EMBEDDING_DIM), input_length=MAX_WORD_LENGTH, name=\"words_embedding\", trainable=True)(words_input)\n",
        "    words_embedding = Bidirectional(LSTM(EMBEDDING_DIM, return_sequences=True))(words_embedding)\n",
        "\n",
        "    # combine\n",
        "    attention = Attention(name=\"attention\")([context_embedding, tags_embedding])\n",
        "    combine = Concatenate(axis=-1)([attention, words_embedding])\n",
        "    \n",
        "    lstm = Bidirectional(LSTM(EMBEDDING_DIM, return_sequences=True), name=\"lstm\")(combine)\n",
        "    lstm = Dropout(0.5)(lstm)\n",
        "    lstm = Bidirectional(LSTM(EMBEDDING_DIM, return_sequences=True), name=\"lstm2\")(lstm)\n",
        "\n",
        "    dense = TimeDistributed(Dense(EMBEDDING_DIM, activation=\"swish\", name=\"dense\"))(lstm)\n",
        "    dense = Dropout(0.3)(dense)\n",
        "    dense = TimeDistributed(Dense(EMBEDDING_DIM, activation=\"swish\", name=\"dense\"))(dense)\n",
        "    dense = Dropout(0.2)(dense)\n",
        "    dense = TimeDistributed(Dense(EMBEDDING_DIM, activation=\"swish\", name=\"dense\"))(dense)\n",
        "    dense = Dropout(0.1)(dense)\n",
        "    dense = TimeDistributed(Dense(EMBEDDING_DIM, activation=\"swish\", name=\"dense\"))(dense)\n",
        "\n",
        "    output = TimeDistributed(Dense(VOCAB_SIZE, activation=\"softmax\"), name=\"output\")(dense)\n",
        "    return Model(inputs=[context_input, tags_input, words_input], outputs=[output])\n",
        "\n",
        "model = get_model()\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPzq5zAJCXvx"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGNU9pxyCXvx",
        "outputId": "3c2294a1-a1d5-459a-b39f-829e7fe6bbd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "35/35 [==============================] - 28s 415ms/step - loss: 1.2169 - accuracy: 0.0000e+00 - val_loss: 0.7903 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "35/35 [==============================] - 11s 326ms/step - loss: 0.7948 - accuracy: 0.0000e+00 - val_loss: 0.7662 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "35/35 [==============================] - 12s 334ms/step - loss: 0.7759 - accuracy: 0.0000e+00 - val_loss: 0.7452 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "35/35 [==============================] - 11s 328ms/step - loss: 0.7352 - accuracy: 0.0000e+00 - val_loss: 0.6255 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "35/35 [==============================] - 11s 327ms/step - loss: 0.5106 - accuracy: 0.0115 - val_loss: 0.3806 - val_accuracy: 0.0645\n",
            "Epoch 6/100\n",
            "35/35 [==============================] - 11s 324ms/step - loss: 0.3391 - accuracy: 0.0880 - val_loss: 0.2596 - val_accuracy: 0.1979\n",
            "Epoch 7/100\n",
            "35/35 [==============================] - 11s 324ms/step - loss: 0.2636 - accuracy: 0.1716 - val_loss: 0.2195 - val_accuracy: 0.2448\n",
            "Epoch 8/100\n",
            "35/35 [==============================] - 11s 326ms/step - loss: 0.2018 - accuracy: 0.2950 - val_loss: 0.1746 - val_accuracy: 0.3841\n",
            "Epoch 9/100\n",
            "35/35 [==============================] - 11s 327ms/step - loss: 0.1563 - accuracy: 0.4375 - val_loss: 0.1409 - val_accuracy: 0.5299\n",
            "Epoch 10/100\n",
            "35/35 [==============================] - 12s 329ms/step - loss: 0.1280 - accuracy: 0.5238 - val_loss: 0.1223 - val_accuracy: 0.5586\n",
            "Epoch 11/100\n",
            "35/35 [==============================] - 12s 329ms/step - loss: 0.1122 - accuracy: 0.5710 - val_loss: 0.1174 - val_accuracy: 0.6016\n",
            "Epoch 12/100\n",
            "35/35 [==============================] - 11s 328ms/step - loss: 0.1039 - accuracy: 0.5944 - val_loss: 0.1031 - val_accuracy: 0.6165\n",
            "Epoch 13/100\n",
            "35/35 [==============================] - 11s 327ms/step - loss: 0.0907 - accuracy: 0.6249 - val_loss: 0.0942 - val_accuracy: 0.6426\n",
            "Epoch 14/100\n",
            "35/35 [==============================] - 11s 323ms/step - loss: 0.0819 - accuracy: 0.6545 - val_loss: 0.0902 - val_accuracy: 0.6361\n",
            "Epoch 15/100\n",
            "35/35 [==============================] - 11s 326ms/step - loss: 0.0773 - accuracy: 0.6585 - val_loss: 0.0870 - val_accuracy: 0.6576\n",
            "Epoch 16/100\n",
            "35/35 [==============================] - 11s 325ms/step - loss: 0.0755 - accuracy: 0.6737 - val_loss: 0.0851 - val_accuracy: 0.6458\n",
            "Epoch 17/100\n",
            "35/35 [==============================] - 11s 327ms/step - loss: 0.0651 - accuracy: 0.7015 - val_loss: 0.0631 - val_accuracy: 0.7363\n",
            "Epoch 18/100\n",
            "35/35 [==============================] - 11s 328ms/step - loss: 0.0508 - accuracy: 0.7543 - val_loss: 0.0538 - val_accuracy: 0.7500\n",
            "Epoch 19/100\n",
            "35/35 [==============================] - 11s 328ms/step - loss: 0.0471 - accuracy: 0.7670 - val_loss: 0.0507 - val_accuracy: 0.7793\n",
            "Epoch 20/100\n",
            "35/35 [==============================] - 11s 324ms/step - loss: 0.0399 - accuracy: 0.7929 - val_loss: 0.0467 - val_accuracy: 0.7663\n",
            "Epoch 21/100\n",
            "35/35 [==============================] - 11s 327ms/step - loss: 0.0354 - accuracy: 0.8127 - val_loss: 0.0390 - val_accuracy: 0.8125\n",
            "Epoch 22/100\n",
            "35/35 [==============================] - 11s 327ms/step - loss: 0.0300 - accuracy: 0.8328 - val_loss: 0.0363 - val_accuracy: 0.8164\n",
            "Epoch 23/100\n",
            "35/35 [==============================] - 11s 327ms/step - loss: 0.0291 - accuracy: 0.8381 - val_loss: 0.0327 - val_accuracy: 0.8405\n",
            "Epoch 24/100\n",
            "35/35 [==============================] - 11s 327ms/step - loss: 0.0243 - accuracy: 0.8634 - val_loss: 0.0330 - val_accuracy: 0.8522\n",
            "Epoch 25/100\n",
            "35/35 [==============================] - 11s 324ms/step - loss: 0.0231 - accuracy: 0.8637 - val_loss: 0.0344 - val_accuracy: 0.8444\n",
            "Epoch 26/100\n",
            "35/35 [==============================] - 11s 326ms/step - loss: 0.0206 - accuracy: 0.8782 - val_loss: 0.0341 - val_accuracy: 0.8724\n",
            "Epoch 27/100\n",
            "35/35 [==============================] - 11s 324ms/step - loss: 0.0194 - accuracy: 0.8852 - val_loss: 0.0289 - val_accuracy: 0.8717\n",
            "Epoch 28/100\n",
            "35/35 [==============================] - 11s 326ms/step - loss: 0.0156 - accuracy: 0.9043 - val_loss: 0.0307 - val_accuracy: 0.8939\n",
            "Epoch 29/100\n",
            "35/35 [==============================] - 11s 324ms/step - loss: 0.0219 - accuracy: 0.8779 - val_loss: 0.0775 - val_accuracy: 0.8008\n",
            "Epoch 30/100\n",
            "35/35 [==============================] - 11s 325ms/step - loss: 0.0456 - accuracy: 0.8032 - val_loss: 0.0350 - val_accuracy: 0.8581\n",
            "Epoch 31/100\n",
            "35/35 [==============================] - 11s 323ms/step - loss: 0.0206 - accuracy: 0.8892 - val_loss: 0.0284 - val_accuracy: 0.8906\n",
            "Epoch 32/100\n",
            "35/35 [==============================] - 11s 326ms/step - loss: 0.0138 - accuracy: 0.9159 - val_loss: 0.0243 - val_accuracy: 0.9069\n",
            "Epoch 33/100\n",
            "35/35 [==============================] - 11s 326ms/step - loss: 0.0106 - accuracy: 0.9332 - val_loss: 0.0258 - val_accuracy: 0.9108\n",
            "Epoch 34/100\n",
            "35/35 [==============================] - 11s 325ms/step - loss: 0.0098 - accuracy: 0.9392 - val_loss: 0.0241 - val_accuracy: 0.9180\n",
            "Epoch 35/100\n",
            "35/35 [==============================] - 11s 327ms/step - loss: 0.0083 - accuracy: 0.9462 - val_loss: 0.0254 - val_accuracy: 0.9193\n",
            "Epoch 36/100\n",
            "35/35 [==============================] - 11s 329ms/step - loss: 0.0089 - accuracy: 0.9434 - val_loss: 0.0237 - val_accuracy: 0.9212\n",
            "Epoch 37/100\n",
            "35/35 [==============================] - 11s 327ms/step - loss: 0.0084 - accuracy: 0.9464 - val_loss: 0.0227 - val_accuracy: 0.9316\n",
            "Epoch 38/100\n",
            "35/35 [==============================] - 11s 324ms/step - loss: 0.0074 - accuracy: 0.9489 - val_loss: 0.0283 - val_accuracy: 0.9297\n",
            "Epoch 39/100\n",
            "35/35 [==============================] - 11s 323ms/step - loss: 0.0074 - accuracy: 0.9503 - val_loss: 0.0232 - val_accuracy: 0.9271\n",
            "Epoch 40/100\n",
            "35/35 [==============================] - 11s 323ms/step - loss: 0.0062 - accuracy: 0.9627 - val_loss: 0.0236 - val_accuracy: 0.9264\n",
            "Epoch 41/100\n",
            "35/35 [==============================] - 11s 326ms/step - loss: 0.0048 - accuracy: 0.9675 - val_loss: 0.0234 - val_accuracy: 0.9323\n",
            "Epoch 42/100\n",
            "35/35 [==============================] - 11s 326ms/step - loss: 0.0039 - accuracy: 0.9739 - val_loss: 0.0249 - val_accuracy: 0.9473\n",
            "Epoch 43/100\n",
            "35/35 [==============================] - 11s 323ms/step - loss: 0.0040 - accuracy: 0.9722 - val_loss: 0.0264 - val_accuracy: 0.9290\n",
            "Epoch 44/100\n",
            "35/35 [==============================] - 11s 323ms/step - loss: 0.0047 - accuracy: 0.9710 - val_loss: 0.0279 - val_accuracy: 0.9154\n",
            "Epoch 45/100\n",
            "35/35 [==============================] - 11s 323ms/step - loss: 0.0055 - accuracy: 0.9671 - val_loss: 0.0232 - val_accuracy: 0.9277\n",
            "Epoch 46/100\n",
            "35/35 [==============================] - 11s 324ms/step - loss: 0.0037 - accuracy: 0.9747 - val_loss: 0.0240 - val_accuracy: 0.9375\n",
            "Epoch 47/100\n",
            "35/35 [==============================] - 11s 323ms/step - loss: 0.0031 - accuracy: 0.9771 - val_loss: 0.0263 - val_accuracy: 0.9316\n",
            "Epoch 48/100\n",
            "35/35 [==============================] - 11s 323ms/step - loss: 0.0029 - accuracy: 0.9811 - val_loss: 0.0235 - val_accuracy: 0.9355\n",
            "Epoch 49/100\n",
            "35/35 [==============================] - 11s 322ms/step - loss: 0.0023 - accuracy: 0.9832 - val_loss: 0.0266 - val_accuracy: 0.9421\n",
            "Epoch 50/100\n",
            "35/35 [==============================] - 11s 323ms/step - loss: 0.0051 - accuracy: 0.9605 - val_loss: 0.1127 - val_accuracy: 0.8073\n",
            "Epoch 51/100\n",
            "35/35 [==============================] - 11s 324ms/step - loss: 0.1291 - accuracy: 0.6683 - val_loss: 0.0462 - val_accuracy: 0.8385\n",
            "Epoch 52/100\n",
            "35/35 [==============================] - 11s 324ms/step - loss: 0.0176 - accuracy: 0.9120 - val_loss: 0.0173 - val_accuracy: 0.9264\n",
            "Epoch 53/100\n",
            "35/35 [==============================] - 11s 323ms/step - loss: 0.0056 - accuracy: 0.9641 - val_loss: 0.0200 - val_accuracy: 0.9342\n",
            "Epoch 54/100\n",
            "35/35 [==============================] - 11s 323ms/step - loss: 0.0031 - accuracy: 0.9797 - val_loss: 0.0227 - val_accuracy: 0.9453\n",
            "Epoch 55/100\n",
            "35/35 [==============================] - 11s 327ms/step - loss: 0.0023 - accuracy: 0.9827 - val_loss: 0.0210 - val_accuracy: 0.9505\n",
            "Epoch 56/100\n",
            "35/35 [==============================] - 11s 324ms/step - loss: 0.0022 - accuracy: 0.9835 - val_loss: 0.0207 - val_accuracy: 0.9466\n",
            "Epoch 57/100\n",
            "35/35 [==============================] - 11s 323ms/step - loss: 0.0016 - accuracy: 0.9903 - val_loss: 0.0224 - val_accuracy: 0.9447\n",
            "Epoch 58/100\n",
            "35/35 [==============================] - 11s 322ms/step - loss: 0.0019 - accuracy: 0.9835 - val_loss: 0.0224 - val_accuracy: 0.9453\n",
            "Epoch 59/100\n",
            "35/35 [==============================] - 11s 323ms/step - loss: 0.0014 - accuracy: 0.9890 - val_loss: 0.0224 - val_accuracy: 0.9460\n",
            "Epoch 60/100\n",
            "35/35 [==============================] - 11s 323ms/step - loss: 0.0014 - accuracy: 0.9899 - val_loss: 0.0224 - val_accuracy: 0.9492\n",
            "Epoch 61/100\n",
            "35/35 [==============================] - 11s 324ms/step - loss: 0.0018 - accuracy: 0.9883 - val_loss: 0.0235 - val_accuracy: 0.9486\n",
            "Epoch 62/100\n",
            "35/35 [==============================] - 11s 323ms/step - loss: 0.0013 - accuracy: 0.9889 - val_loss: 0.0230 - val_accuracy: 0.9505\n",
            "Epoch 63/100\n",
            "35/35 [==============================] - 11s 326ms/step - loss: 0.0017 - accuracy: 0.9875 - val_loss: 0.0174 - val_accuracy: 0.9538\n",
            "Epoch 64/100\n",
            "35/35 [==============================] - 11s 327ms/step - loss: 8.9532e-04 - accuracy: 0.9935 - val_loss: 0.0264 - val_accuracy: 0.9544\n",
            "Epoch 65/100\n",
            "35/35 [==============================] - 11s 323ms/step - loss: 7.3653e-04 - accuracy: 0.9945 - val_loss: 0.0268 - val_accuracy: 0.9512\n",
            "Epoch 66/100\n",
            "35/35 [==============================] - 11s 326ms/step - loss: 8.4332e-04 - accuracy: 0.9955 - val_loss: 0.0236 - val_accuracy: 0.9603\n",
            "Epoch 67/100\n",
            "35/35 [==============================] - 11s 323ms/step - loss: 7.5141e-04 - accuracy: 0.9953 - val_loss: 0.0253 - val_accuracy: 0.9570\n",
            "Epoch 68/100\n",
            "35/35 [==============================] - 11s 324ms/step - loss: 7.1218e-04 - accuracy: 0.9942 - val_loss: 0.0241 - val_accuracy: 0.9538\n",
            "Epoch 69/100\n",
            "35/35 [==============================] - 11s 324ms/step - loss: 7.5768e-04 - accuracy: 0.9946 - val_loss: 0.0285 - val_accuracy: 0.9492\n",
            "Epoch 70/100\n",
            "35/35 [==============================] - 11s 324ms/step - loss: 9.0474e-04 - accuracy: 0.9940 - val_loss: 0.0247 - val_accuracy: 0.9401\n",
            "Epoch 71/100\n",
            "35/35 [==============================] - 11s 323ms/step - loss: 0.0018 - accuracy: 0.9867 - val_loss: 0.0255 - val_accuracy: 0.9473\n",
            "Epoch 72/100\n",
            "35/35 [==============================] - 11s 323ms/step - loss: 0.0020 - accuracy: 0.9864 - val_loss: 0.0269 - val_accuracy: 0.9368\n",
            "Epoch 73/100\n",
            "35/35 [==============================] - 11s 323ms/step - loss: 0.0012 - accuracy: 0.9914 - val_loss: 0.0277 - val_accuracy: 0.9401\n",
            "Epoch 74/100\n",
            "35/35 [==============================] - 11s 323ms/step - loss: 0.0014 - accuracy: 0.9905 - val_loss: 0.0263 - val_accuracy: 0.9434\n",
            "Epoch 75/100\n",
            "35/35 [==============================] - 11s 323ms/step - loss: 0.0011 - accuracy: 0.9917 - val_loss: 0.0234 - val_accuracy: 0.9518\n",
            "Epoch 76/100\n",
            "35/35 [==============================] - 11s 323ms/step - loss: 7.0759e-04 - accuracy: 0.9948 - val_loss: 0.0248 - val_accuracy: 0.9603\n",
            "Epoch 77/100\n",
            "35/35 [==============================] - 11s 322ms/step - loss: 4.2786e-04 - accuracy: 0.9970 - val_loss: 0.0292 - val_accuracy: 0.9499\n",
            "Epoch 78/100\n",
            "35/35 [==============================] - 11s 323ms/step - loss: 4.6808e-04 - accuracy: 0.9961 - val_loss: 0.0264 - val_accuracy: 0.9551\n",
            "Epoch 79/100\n",
            "35/35 [==============================] - 11s 323ms/step - loss: 5.0074e-04 - accuracy: 0.9967 - val_loss: 0.0281 - val_accuracy: 0.9531\n",
            "Epoch 80/100\n",
            "35/35 [==============================] - 11s 322ms/step - loss: 6.6009e-04 - accuracy: 0.9952 - val_loss: 0.0272 - val_accuracy: 0.9603\n",
            "Epoch 81/100\n",
            "35/35 [==============================] - 11s 323ms/step - loss: 6.5185e-04 - accuracy: 0.9940 - val_loss: 0.0257 - val_accuracy: 0.9427\n",
            "Epoch 82/100\n",
            "35/35 [==============================] - 11s 324ms/step - loss: 0.0045 - accuracy: 0.9766 - val_loss: 0.0312 - val_accuracy: 0.9388\n",
            "Epoch 83/100\n",
            "35/35 [==============================] - 11s 324ms/step - loss: 0.0036 - accuracy: 0.9779 - val_loss: 0.0286 - val_accuracy: 0.9466\n",
            "Epoch 84/100\n",
            "35/35 [==============================] - 11s 324ms/step - loss: 0.0019 - accuracy: 0.9876 - val_loss: 0.0373 - val_accuracy: 0.9336\n",
            "Epoch 85/100\n",
            "35/35 [==============================] - 11s 325ms/step - loss: 0.0259 - accuracy: 0.9249 - val_loss: 0.1206 - val_accuracy: 0.6979\n",
            "Epoch 86/100\n",
            "35/35 [==============================] - 11s 327ms/step - loss: 0.0484 - accuracy: 0.7989 - val_loss: 0.0356 - val_accuracy: 0.8835\n"
          ]
        }
      ],
      "source": [
        "early_stopping = EarlyStopping(monitor=\"val_accuracy\", patience=20, restore_best_weights=True)\n",
        "\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[accuracy])\n",
        "\n",
        "# train model\n",
        "history = model.fit([dev_ctx_e, dev_tags_e, dev_words_e], dev_lemmas_e, epochs=100, batch_size=256, validation_data=([val_ctx_e, val_tags_e, val_words_e], val_lemmas_e), callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7AMK_4pCXvx"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oR3saAaeCXvy",
        "outputId": "0e5107d3-b295-46ed-b54d-9f4424818899"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2213/2213 [==============================] - 57s 26ms/step - loss: 0.0261 - accuracy: 0.9516\n",
            "Test loss:  0.026086971163749695\n",
            "Test accuracy:  0.951564610004425\n"
          ]
        }
      ],
      "source": [
        "# evaluate model\n",
        "result = model.evaluate([test_ctx_e, test_tags_e, test_words_e], test_lemmas_e)\n",
        "print(\"Test loss: \", result[0])\n",
        "print(\"Test accuracy: \", result[1])\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "08eac26dc1f80337b7d87e94e7159a5bad95c2e85f47efef91c61359b3afbfe9"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
