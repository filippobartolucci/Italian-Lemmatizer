{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Italian Word Lemmatizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, LSTM, Dense, Embedding, Concatenate, Bidirectional, TimeDistributed, RepeatVector, Activation, Dot, Lambda, Dropout, Add, Multiply, Masking, Attention\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import gensim\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# set all random seeds\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  320\n",
      "Max sentence length:  107\n",
      "Number of sentences in dev set:  2730\n",
      "Number of sentences in test set:  5596\n",
      "Number of unique tags:  16\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_path = \"./dev_new1.csv\"\n",
    "df_dev = pd.read_csv(dataset_path, sep=\"\\t\", header=None,\n",
    "                     names=[\"word\", \"tag\", \"lemm\"])\n",
    "\n",
    "dataset_path = \"./test_new1.csv\"\n",
    "df_test = pd.read_csv(dataset_path, sep=\"\\t\", header=None,\n",
    "                      names=[\"word\", \"tag\", \"lemm\"])\n",
    "\n",
    "df_dev[\"word\"] = df_dev[\"word\"].astype(str)\n",
    "df_dev[\"tag\"] = df_dev[\"tag\"].astype(str)\n",
    "df_dev[\"lemm\"] = df_dev[\"lemm\"].astype(str)\n",
    "\n",
    "df_test[\"word\"] = df_test[\"word\"].astype(str)\n",
    "df_test[\"tag\"] = df_test[\"tag\"].astype(str)\n",
    "df_test[\"lemm\"] = df_test[\"lemm\"].astype(str)\n",
    "\n",
    "# remove head\n",
    "df_dev = df_dev.iloc[1:]\n",
    "df_test = df_test.iloc[1:]\n",
    "\n",
    "\n",
    "# lower case all words\n",
    "df_test[\"word\"] = df_test[\"word\"].str.lower()\n",
    "df_dev[\"word\"] = df_dev[\"word\"].str.lower()\n",
    "\n",
    "\n",
    "def get_sentences(df):\n",
    "    words = []\n",
    "    tags = []\n",
    "    lemmas = []\n",
    "    sentence = []\n",
    "    max_s = 0\n",
    "    for index, row in df.iterrows():\n",
    "        word = row[\"word\"]\n",
    "        tag = row[\"tag\"]\n",
    "        lemm = row[\"lemm\"]\n",
    "        sentence.append([word, tag, lemm])\n",
    "\n",
    "        if row[\"word\"] in [\".\", \"?\", \"!\", \";\"]:\n",
    "            words.append([word for word, tag, lemm in sentence])\n",
    "            tags.append([tag for word, tag, lemm in sentence])\n",
    "            lemmas.append([lemm for word, tag, lemm in sentence])\n",
    "            max_s = max(max_s, len(sentence))\n",
    "            sentence = []\n",
    "\n",
    "    print(\"Max sentence length: \", max_s)\n",
    "    return words, tags, lemmas\n",
    "\n",
    "# _s is for string\n",
    "dev_words_s, dev_tags_s, dev_lemmas_s = get_sentences(df_dev)\n",
    "test_words_s, test_tags_s, test_lemmas_s = get_sentences(df_test)\n",
    "print(\"Number of sentences in dev set: \", len(dev_words_s))\n",
    "print(\"Number of sentences in test set: \", len(test_words_s))\n",
    "\n",
    "# print number of unique tags\n",
    "print(\"Number of unique tags: \", len(df_dev[\"tag\"].unique()))\n",
    "\n",
    "for i in range(len(dev_words_s)):\n",
    "    if len(dev_words_s[i]) != len(dev_tags_s[i]) or len(dev_words_s[i]) != len(dev_lemmas_s[i]):\n",
    "        print(\"Dimension mismatch in sentence: \", i)\n",
    "        print(\"Words: \", dev_words_s[i])\n",
    "        print(\"Tags: \", dev_tags_s[i])\n",
    "        print(\"Lemmas: \", dev_lemmas_s[i])\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot tag distribution\n",
    "tags = []\n",
    "for tag_list in dev_tags_s:\n",
    "    tags.extend(tag_list)\n",
    "\n",
    "tags = pd.Series(tags)\n",
    "tags.value_counts().plot(kind=\"bar\", figsize=(20, 10))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sample in dev set:  69120\n",
      "Number of sample in val set:  7681\n",
      "Number of sample in test set:  133660\n"
     ]
    }
   ],
   "source": [
    "CTX_DIM = 12            # context dimension, 12 words on each side\n",
    "PRE_VALUE = \"<PRE>\"     # value for padding pre \n",
    "POST_VALUE = \"<POST>\"   # value for padding post\n",
    "NONE_TAG = \"<NONE>\"     # value for padding tags\n",
    "\n",
    "def get_context(words, tags, lemmas):\n",
    "    ctx = []    # context list\n",
    "    w = []      # word list\n",
    "    tag = []    # context tags list\n",
    "    t = []      # word tags list\n",
    "    lemma = []  # lemma list\n",
    "\n",
    "    for s_index in range(len(words)):\n",
    "        s = words[s_index]\n",
    "        s_tags = tags[s_index]\n",
    "        sentence = \" \".join(s)\n",
    "        s = [PRE_VALUE] * CTX_DIM + s + [POST_VALUE] * CTX_DIM\n",
    "        s_tags = [NONE_TAG] * CTX_DIM + s_tags + [NONE_TAG] * CTX_DIM\n",
    "\n",
    "        for w_index in range(len(s)):\n",
    "            if w_index < CTX_DIM or w_index >= len(s) - CTX_DIM:\n",
    "                continue\n",
    "\n",
    "            context = s[w_index - CTX_DIM:w_index] + [s[w_index]] +s[w_index + 1:w_index  + CTX_DIM + 1]\n",
    "            context = \" \".join(context)\n",
    "            ctx.append(context)\n",
    "            w.append(words[s_index][w_index-CTX_DIM])\n",
    "\n",
    "            ctx_tags = s_tags[w_index - CTX_DIM:w_index] + [s_tags[w_index]] + s_tags[w_index + 1:w_index  + CTX_DIM + 1]\n",
    "            tag.append(ctx_tags)\n",
    "            t.append(tags[s_index][w_index-CTX_DIM])\n",
    "\n",
    "            lemma.append(lemmas[s_index][w_index-CTX_DIM])\n",
    "    return ctx, w, tag, t, lemma\n",
    "\n",
    "dev_ctx, dev_words, dev_tags, dev_tag,dev_lemmas = get_context(dev_words_s, dev_tags_s, dev_lemmas_s)\n",
    "test_ctx, test_words, test_tags, test_tag,test_lemmas = get_context(test_words_s, test_tags_s, test_lemmas_s)\n",
    "\n",
    "dev_ctx, val_ctx, dev_words, val_words, dev_tags, val_tags, dev_tag, val_tag, dev_lemmas, val_lemmas = train_test_split(dev_ctx, dev_words, dev_tags, dev_tag, dev_lemmas, test_size=0.1, random_state=42)\n",
    "\n",
    "print(\"Number of sample in dev set: \", len(dev_lemmas))\n",
    "print(\"Number of sample in val set: \", len(val_lemmas))\n",
    "print(\"Number of sample in test set: \", len(test_lemmas))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTX Dim: 12 \n",
      "\n",
      "CTX:  \" rimane la migliore garanzia contro la guerra e le prove di forza irresponsabili \" . <POST> <POST> <POST> <POST> <POST> <POST> <POST> <POST> <POST>\n",
      "CTX Tags:  ['punct', 'verb', 'det', 'adj', 'noun', 'adp', 'det', 'noun', 'cconj', 'det', 'noun', 'adp', 'noun', 'adj', 'punct', 'punct', '<NONE>', '<NONE>', '<NONE>', '<NONE>', '<NONE>', '<NONE>', '<NONE>', '<NONE>', '<NONE>']\n",
      "Word:  forza\n",
      "Tag:  noun\n",
      "Lemma:  forza\n",
      "\n",
      "CTX:  <PRE> <PRE> <PRE> <PRE> <PRE> <PRE> <PRE> <PRE> <PRE> <PRE> <PRE> pur così , le sue prospettive di crescita appaiono vacillanti , e questo a\n",
      "CTX Tags:  ['<NONE>', '<NONE>', '<NONE>', '<NONE>', '<NONE>', '<NONE>', '<NONE>', '<NONE>', '<NONE>', '<NONE>', '<NONE>', 'adv', 'adv', 'punct', 'det', 'det', 'noun', 'adp', 'noun', 'verb', 'verb', 'punct', 'cconj', 'pron', 'adp']\n",
      "Word:  così\n",
      "Tag:  adv\n",
      "Lemma:  così\n",
      "\n",
      "CTX:  il loro attuale livello di rappresentanza , e le posizioni e le voci dei di i paesi a medio e basso reddito dovrebbero essere rafforzate\n",
      "CTX Tags:  ['det', 'det', 'adj', 'noun', 'adp', 'noun', 'punct', 'cconj', 'det', 'noun', 'cconj', 'det', 'noun', '_', 'adp', 'det', 'noun', 'adp', 'adj', 'cconj', 'adj', 'noun', 'aux', 'aux', 'verb']\n",
      "Word:  voci\n",
      "Tag:  noun\n",
      "Lemma:  voce\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"CTX Dim:\", CTX_DIM, \"\\n\")\n",
    "for i in range(3):\n",
    "    index = np.random.randint(0, len(dev_ctx))\n",
    "    print(\"CTX: \", dev_ctx[index])\n",
    "    print(\"CTX Tags: \", dev_tags[index])\n",
    "    print(\"Word: \", dev_words[index])\n",
    "    print(\"Tag: \", dev_tag[index])\n",
    "    print(\"Lemma: \", dev_lemmas[index])\n",
    "    print()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Class Words\n",
    "The evaluation is done only on open-class words and not to functional words: only the tokens having a PoS-tag comprised in the set ADJ *, ADV, NN, V * had to be lemmatised, in all the other cases the token could be copied unchanged into the lemma column as they were not considered for the evaluation (the asterisk indicates all PoS-tag possibilities beginning with that prefix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of open class words in dev set:  27782\n",
      "Number of open class words in val set:  3029\n",
      "Number of open class words in test set:  65210\n"
     ]
    }
   ],
   "source": [
    "def get_open_class_words(ctx, words, tags, tag, lemmas):\n",
    "    open_class_words = []\n",
    "    open_class_ctx = []\n",
    "    open_class_tags = []\n",
    "    open_class_lemmas = []\n",
    "\n",
    "    for i in range(len(words)):\n",
    "        t = tag[i]\n",
    "        if \"adj\" in t or \"adv\" in t or \"noun\" in t or \"verb\" in t:\n",
    "            open_class_words.append(words[i])\n",
    "            open_class_ctx.append(ctx[i])\n",
    "            open_class_tags.append(tags[i])\n",
    "            open_class_lemmas.append(lemmas[i])\n",
    "\n",
    "    return open_class_ctx, open_class_words, open_class_tags, open_class_lemmas\n",
    "\n",
    "\n",
    "test_ctx, test_words, test_tags, test_lemmas = get_open_class_words(test_ctx, test_words, test_tags, test_tag, test_lemmas)\n",
    "dev_ctx, dev_words, dev_tags, dev_lemmas = get_open_class_words(dev_ctx, dev_words, dev_tags, dev_tag, dev_lemmas)\n",
    "val_ctx, val_words, val_tags, val_lemmas = get_open_class_words(val_ctx, val_words, val_tags, val_tag, val_lemmas)\n",
    "\n",
    "print(\"Number of open class words in dev set: \", len(dev_words))\n",
    "print(\"Number of open class words in val set: \", len(val_words)) \n",
    "print(\"Number of open class words in test set: \", len(test_words)) # 62597"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size:  77\n",
      "Max word length:  25\n",
      "\n",
      "Context: \n",
      " naturalmente , il fmi solleva grandi passioni nei in i paesi che ricevono assistenza - come la grecia degli di gli ultimi anni . <POST> \n",
      " [500, 3, 7, 2273, 10079, 196, 19445, 98, 11, 14, 168, 9, 8212, 1023, 38, 33, 8, 4575, 67, 4, 27, 422, 68, 6, 2]\n",
      "\n",
      "Tags: \n",
      " ['adv', 'punct', 'det', 'propn', 'verb', 'adj', 'noun', '_', 'adp', 'det', 'noun', 'pron', 'verb', 'noun', 'punct', 'adp', 'det', 'propn', '_', 'adp', 'det', 'adj', 'noun', 'punct', '<NONE>'] \n",
      " [8, 3, 6, 11, 4, 7, 2, 12, 5, 6, 2, 9, 4, 2, 3, 5, 6, 11, 12, 5, 6, 7, 2, 3, 1]\n",
      "\n",
      "Words: \n",
      " ricevono \n",
      " [51 42 36 38 55 48 47 48  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0]\n",
      "\n",
      "Lemma: \n",
      " ricevere \n",
      " [51 42 36 38 55 38 51 38  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0]\n"
     ]
    }
   ],
   "source": [
    "# word encoder\n",
    "word_tokenizer = Tokenizer(filters=\"\")\n",
    "word_tokenizer.fit_on_texts(dev_ctx + test_ctx + val_ctx)\n",
    "\n",
    "# tag encoder\n",
    "tag_tokenizer = Tokenizer(filters=\"\")\n",
    "tag_tokenizer.fit_on_texts(dev_tags + test_tags + val_tags)\n",
    "\n",
    "# lemma encoder\n",
    "lemma_tokenizer = Tokenizer(filters=\"\")\n",
    "lemma_tokenizer.fit_on_texts(dev_lemmas_s + test_lemmas_s)\n",
    "\n",
    "dev_ctx_e = word_tokenizer.texts_to_sequences(dev_ctx)\n",
    "val_ctx_e = word_tokenizer.texts_to_sequences(val_ctx)\n",
    "test_ctx_e = word_tokenizer.texts_to_sequences(test_ctx)\n",
    "\n",
    "dev_tags_e = tag_tokenizer.texts_to_sequences(dev_tags)\n",
    "val_tags_e = tag_tokenizer.texts_to_sequences(val_tags)\n",
    "test_tags_e = tag_tokenizer.texts_to_sequences(test_tags)\n",
    "\n",
    "\n",
    "# get all unique letter in words\n",
    "characters = set()\n",
    "\n",
    "for lemma in df_dev[\"lemm\"].unique():\n",
    "    for letter in lemma:\n",
    "        characters.add(letter)\n",
    "\n",
    "for lemma in df_test[\"lemm\"].unique():\n",
    "    for letter in lemma:\n",
    "        characters.add(letter)\n",
    "\n",
    "for word in df_dev[\"word\"].unique():\n",
    "    for letter in word:\n",
    "        characters.add(letter)\n",
    "\n",
    "for word in df_test[\"word\"].unique():\n",
    "    for letter in word:\n",
    "        characters.add(letter)\n",
    "    \n",
    "\n",
    "# add padding and unknown to characters\n",
    "characters.add(\" \")\n",
    "\n",
    "# the length of the vocab for one-hot encoded char\n",
    "VOCAB_SIZE = len(characters)\n",
    "\n",
    "print (\"Vocab size: \", VOCAB_SIZE)\n",
    "# order characters\n",
    "characters = sorted(list(characters))\n",
    "\n",
    "\n",
    "char2idx = {char: idx for idx, char in enumerate(characters)}\n",
    "idx2char = {idx: char for idx, char in enumerate(characters)}\n",
    "\n",
    "MAX_WORD_LENGTH = 0\n",
    "for w in dev_words + test_words + dev_lemmas + test_lemmas + val_words + val_lemmas:\n",
    "    MAX_WORD_LENGTH = max(MAX_WORD_LENGTH, len(w))\n",
    "print(\"Max word length: \", MAX_WORD_LENGTH)\n",
    "\n",
    "def encode_words(words):\n",
    "    encoded_words = []\n",
    "    for word in words:\n",
    "        word_e = []\n",
    "        for letter in word:\n",
    "            word_e.append(characters.index(letter))\n",
    "        encoded_words.append(word_e)\n",
    "    return encoded_words\n",
    "\n",
    "dev_words_e = encode_words(dev_words)\n",
    "test_words_e = encode_words(test_words)\n",
    "val_words_e = encode_words(val_words)\n",
    "\n",
    "dev_lemmas_e = encode_words(dev_lemmas)\n",
    "test_lemmas_e = encode_words(test_lemmas)\n",
    "val_lemmas_e = encode_words(val_lemmas)\n",
    "\n",
    "dev_words_e = tf.keras.preprocessing.sequence.pad_sequences(dev_words_e, maxlen=MAX_WORD_LENGTH, padding=\"post\")\n",
    "test_words_e = tf.keras.preprocessing.sequence.pad_sequences(test_words_e, maxlen=MAX_WORD_LENGTH, padding=\"post\")\n",
    "val_words_e = tf.keras.preprocessing.sequence.pad_sequences(val_words_e, maxlen=MAX_WORD_LENGTH, padding=\"post\")\n",
    "\n",
    "dev_lemmas_e = tf.keras.preprocessing.sequence.pad_sequences(dev_lemmas_e, maxlen=MAX_WORD_LENGTH, padding=\"post\")\n",
    "test_lemmas_e = tf.keras.preprocessing.sequence.pad_sequences(test_lemmas_e, maxlen=MAX_WORD_LENGTH, padding=\"post\")\n",
    "val_lemmas_e = tf.keras.preprocessing.sequence.pad_sequences(val_lemmas_e, maxlen=MAX_WORD_LENGTH, padding=\"post\")\n",
    "\n",
    "index = np.random.randint(0, len(dev_ctx))\n",
    "print(\"\\nContext: \\n\", dev_ctx[index], \"\\n\", dev_ctx_e[index])\n",
    "print(\"\\nTags: \\n\", dev_tags[index], \"\\n\", dev_tags_e[index])\n",
    "print(\"\\nWords: \\n\", dev_words[index], \"\\n\", dev_words_e[index])\n",
    "print(\"\\nLemma: \\n\", dev_lemmas[index], \"\\n\", dev_lemmas_e[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n"
     ]
    }
   ],
   "source": [
    "# one hot encode the characters for the lemmas\n",
    "dev_lemmas_e = tf.one_hot(dev_lemmas_e, VOCAB_SIZE)\n",
    "test_lemmas_e = tf.one_hot(test_lemmas_e, VOCAB_SIZE)\n",
    "val_lemmas_e = tf.one_hot(val_lemmas_e, VOCAB_SIZE)\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context shape:  (27782, 25)\n",
      "Words shape:  (27782, 25)\n",
      "Tags shape:  (27782, 25)\n",
      "Lemmas shape:  (27782, 25, 77)\n"
     ]
    }
   ],
   "source": [
    "# trnasform to numpy array\n",
    "dev_ctx_e = np.array(dev_ctx_e)\n",
    "dev_words_e = np.array(dev_words_e)\n",
    "dev_tags_e = np.array(dev_tags_e)\n",
    "dev_lemmas_e = np.array(dev_lemmas_e)\n",
    "\n",
    "test_ctx_e = np.array(test_ctx_e)\n",
    "test_words_e = np.array(test_words_e)\n",
    "test_tags_e = np.array(test_tags_e)\n",
    "test_lemmas_e = np.array(test_lemmas_e)\n",
    "\n",
    "val_ctx_e = np.array(val_ctx_e)\n",
    "val_words_e = np.array(val_words_e)\n",
    "val_tags_e = np.array(val_tags_e)\n",
    "val_lemmas_e = np.array(val_lemmas_e)\n",
    "\n",
    "print(\"Context shape: \", dev_ctx_e.shape)\n",
    "print(\"Words shape: \", dev_words_e.shape)\n",
    "print(\"Tags shape: \", dev_tags_e.shape)\n",
    "print(\"Lemmas shape: \", dev_lemmas_e.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.argmax(y_true, axis=-1)\n",
    "    y_pred = tf.argmax(y_pred, axis=-1)\n",
    "    correct_predictions = tf.reduce_all(tf.equal(y_true, y_pred), axis=-1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
    "    return accuracy\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 384\n",
    "VOCABULARY_SIZE = len(word_tokenizer.word_index) + 1\n",
    "\n",
    "def get_word2vec_weights(DIM):\n",
    "    # train word2vec model\n",
    "    word2vec = gensim.models.Word2Vec(dev_ctx + val_ctx + test_ctx, vector_size=DIM, window=10, min_count=1, workers=8)\n",
    "\n",
    "    # create an empty embedding matix\n",
    "    embedding_weights = np.zeros((VOCABULARY_SIZE, DIM))\n",
    "\n",
    "    # create a word to index dictionary mapping\n",
    "    word2id = word_tokenizer.word_index\n",
    "\n",
    "    # copy vectors from word2vec model to the words present in corpus\n",
    "    for word, index in word2id.items():\n",
    "        try:\n",
    "            embedding_weights[index, :] = word2vec.wv[word]\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    return embedding_weights\n",
    "\n",
    "embedding_weights = get_word2vec_weights(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 25)]         0           []                               \n",
      "                                                                                                  \n",
      " context_embedding (Embedding)  (None, 25, 384)      9040512     ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " tags_input (InputLayer)        [(None, 25)]         0           []                               \n",
      "                                                                                                  \n",
      " lstm_18 (LSTM)                 (None, 25, 384)      1181184     ['context_embedding[1][0]']      \n",
      "                                                                                                  \n",
      " tags_embedding (Embedding)     (None, 25, 384)      6912        ['tags_input[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 25, 768)      0           ['lstm_18[1][0]',                \n",
      "                                                                  'tags_embedding[1][0]']         \n",
      "                                                                                                  \n",
      " input_10 (InputLayer)          [(None, 25)]         0           []                               \n",
      "                                                                                                  \n",
      " lstm_combine (Bidirectional)   (None, 25, 768)      3542016     ['concatenate_6[1][0]']          \n",
      "                                                                                                  \n",
      " words_embedding (Embedding)    (None, 25, 384)      29568       ['input_10[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 25, 1152)     0           ['lstm_combine[1][0]',           \n",
      "                                                                  'words_embedding[1][0]']        \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 25, 1152)     0           ['concatenate_7[1][0]']          \n",
      "                                                                                                  \n",
      " lstm (Bidirectional)           (None, 25, 768)      4721664     ['dropout_15[1][0]']             \n",
      "                                                                                                  \n",
      " lstm1 (Bidirectional)          (None, 25, 768)      3542016     ['lstm[1][0]']                   \n",
      "                                                                                                  \n",
      " dense1 (Dense)                 (None, 25, 384)      295296      ['lstm1[1][0]']                  \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 25, 384)      0           ['dense1[1][0]']                 \n",
      "                                                                                                  \n",
      " dense2 (Dense)                 (None, 25, 384)      147840      ['dropout_16[1][0]']             \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 25, 384)      0           ['dense2[1][0]']                 \n",
      "                                                                                                  \n",
      " dense3 (Dense)                 (None, 25, 384)      147840      ['dropout_17[1][0]']             \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)           (None, 25, 384)      0           ['dense3[1][0]']                 \n",
      "                                                                                                  \n",
      " dense4 (Dense)                 (None, 25, 384)      147840      ['dropout_18[1][0]']             \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 25, 77)       29645       ['dense4[1][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 22,832,333\n",
      "Trainable params: 13,791,821\n",
      "Non-trainable params: 9,040,512\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Neural network model\n",
    "# inputs:\n",
    "#   - context: (batch_size, CTX_DIM * 2) \n",
    "#   - tags: encoded tags: (batch_size, MAX_WORD_LENGTH)\n",
    "#   - words: encoded words: (batch_size, MAX_WORD_LENGTH)\n",
    "# outputs:\n",
    "#  - lemma: encoded lemma: (batch_size, MAX_WORD_LENGTH)\n",
    "\n",
    "def get_model():\n",
    "    # context\n",
    "    context_input = Input(shape=(CTX_DIM * 2 + 1,), name=\"context_input\")\n",
    "    context_input = Masking(mask_value=0)(context_input)\n",
    "    context_input = Masking(mask_value=0)(context_input)\n",
    "    context_embedding = Embedding(len(word_tokenizer.word_index) + 1, EMBEDDING_DIM, input_length=CTX_DIM * 2 + 1,name=\"context_embedding\", trainable=False, weights=[embedding_weights])(context_input)\n",
    "    context_embedding = LSTM(EMBEDDING_DIM, return_sequences=True)(context_embedding)\n",
    "\n",
    "    # tags\n",
    "    tags_input = Input(shape=(CTX_DIM * 2 + 1,), name=\"tags_input\")\n",
    "    tags_embedding = Embedding(len(tag_tokenizer.word_index) + 1, EMBEDDING_DIM, input_length=CTX_DIM * 2 + 1, name=\"tags_embedding\", trainable=True)(tags_input)\n",
    "\n",
    "    # words\n",
    "    words_input = Input(shape=(MAX_WORD_LENGTH,), name=\"words_input\")\n",
    "    words_input = Masking(mask_value=0)(words_input)\n",
    "    words_embedding = Embedding(VOCAB_SIZE, int(EMBEDDING_DIM), input_length=MAX_WORD_LENGTH, name=\"words_embedding\", trainable=True)(words_input)\n",
    "\n",
    "    combine = Concatenate()([context_embedding, tags_embedding])\n",
    "    combine = Bidirectional(LSTM(EMBEDDING_DIM, return_sequences=True), name=\"lstm_combine\")(combine)\n",
    "\n",
    "    # combine\n",
    "    combine = Concatenate()([combine, words_embedding])\n",
    "\n",
    "    combine = Dropout(0.5)(combine)\n",
    "    lstm = Bidirectional(LSTM(EMBEDDING_DIM, return_sequences=True), name=\"lstm\")(combine)\n",
    "    lstm = Bidirectional(LSTM(EMBEDDING_DIM, return_sequences=True), name=\"lstm1\")(lstm)\n",
    "\n",
    "    dense = Dense(EMBEDDING_DIM, activation=\"swish\", name=\"dense1\")(lstm)\n",
    "    dense = Dropout(0.5)(dense)\n",
    "    dense = Dense(EMBEDDING_DIM, activation=\"swish\", name=\"dense2\")(dense)\n",
    "    dense = Dropout(0.5)(dense)\n",
    "    dense = Dense(EMBEDDING_DIM, activation=\"swish\", name=\"dense3\")(dense)\n",
    "    dense = Dropout(0.5)(dense)\n",
    "    dense = Dense(EMBEDDING_DIM, activation=\"swish\", name=\"dense4\")(dense)\n",
    "\n",
    "    # output\n",
    "    output = Dense(VOCAB_SIZE, activation=\"softmax\", name=\"output\")(dense)\n",
    "\n",
    "    model = Model(inputs=[context_input, tags_input,words_input], outputs=output)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = get_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "109/109 [==============================] - 51s 391ms/step - loss: 0.9540 - accuracy: 7.1032e-04 - val_loss: 0.4970 - val_accuracy: 0.0171\n",
      "Epoch 2/100\n",
      "109/109 [==============================] - 35s 321ms/step - loss: 0.3836 - accuracy: 0.0836 - val_loss: 0.2595 - val_accuracy: 0.3265\n",
      "Epoch 3/100\n",
      "109/109 [==============================] - 35s 317ms/step - loss: 0.2361 - accuracy: 0.3028 - val_loss: 0.2016 - val_accuracy: 0.4726\n",
      "Epoch 4/100\n",
      "109/109 [==============================] - 35s 317ms/step - loss: 0.1833 - accuracy: 0.4595 - val_loss: 0.1704 - val_accuracy: 0.6257\n",
      "Epoch 5/100\n",
      "109/109 [==============================] - 34s 316ms/step - loss: 0.1457 - accuracy: 0.5518 - val_loss: 0.1359 - val_accuracy: 0.6563\n",
      "Epoch 6/100\n",
      "109/109 [==============================] - 34s 314ms/step - loss: 0.1267 - accuracy: 0.5866 - val_loss: 0.1160 - val_accuracy: 0.6678\n",
      "Epoch 7/100\n",
      "109/109 [==============================] - 34s 315ms/step - loss: 0.1097 - accuracy: 0.6152 - val_loss: 0.1009 - val_accuracy: 0.6806\n",
      "Epoch 8/100\n",
      "109/109 [==============================] - 34s 315ms/step - loss: 0.0952 - accuracy: 0.6413 - val_loss: 0.0842 - val_accuracy: 0.7156\n",
      "Epoch 9/100\n",
      "109/109 [==============================] - 34s 316ms/step - loss: 0.0817 - accuracy: 0.6721 - val_loss: 0.0669 - val_accuracy: 0.7473\n",
      "Epoch 10/100\n",
      "109/109 [==============================] - 34s 308ms/step - loss: 0.0727 - accuracy: 0.6963 - val_loss: 0.0649 - val_accuracy: 0.7312\n",
      "Epoch 11/100\n",
      "109/109 [==============================] - 34s 313ms/step - loss: 0.0589 - accuracy: 0.7383 - val_loss: 0.0482 - val_accuracy: 0.8006\n",
      "Epoch 12/100\n",
      "109/109 [==============================] - 34s 313ms/step - loss: 0.0494 - accuracy: 0.7705 - val_loss: 0.0369 - val_accuracy: 0.8325\n",
      "Epoch 13/100\n",
      "109/109 [==============================] - 34s 314ms/step - loss: 0.0404 - accuracy: 0.8023 - val_loss: 0.0327 - val_accuracy: 0.8528\n",
      "Epoch 14/100\n",
      "109/109 [==============================] - 34s 312ms/step - loss: 0.0350 - accuracy: 0.8268 - val_loss: 0.0335 - val_accuracy: 0.8541\n",
      "Epoch 15/100\n",
      "109/109 [==============================] - 34s 316ms/step - loss: 0.0296 - accuracy: 0.8443 - val_loss: 0.0264 - val_accuracy: 0.8799\n",
      "Epoch 16/100\n",
      "109/109 [==============================] - 34s 314ms/step - loss: 0.0246 - accuracy: 0.8693 - val_loss: 0.0247 - val_accuracy: 0.8905\n",
      "Epoch 17/100\n",
      "109/109 [==============================] - 34s 313ms/step - loss: 0.0226 - accuracy: 0.8783 - val_loss: 0.0220 - val_accuracy: 0.9025\n",
      "Epoch 18/100\n",
      "109/109 [==============================] - 34s 311ms/step - loss: 0.0190 - accuracy: 0.8965 - val_loss: 0.0200 - val_accuracy: 0.9106\n",
      "Epoch 19/100\n",
      "109/109 [==============================] - 34s 310ms/step - loss: 0.0171 - accuracy: 0.9080 - val_loss: 0.0210 - val_accuracy: 0.9146\n",
      "Epoch 20/100\n",
      "109/109 [==============================] - 34s 309ms/step - loss: 0.0153 - accuracy: 0.9161 - val_loss: 0.0189 - val_accuracy: 0.9186\n",
      "Epoch 21/100\n",
      "109/109 [==============================] - 34s 310ms/step - loss: 0.0161 - accuracy: 0.9126 - val_loss: 0.0183 - val_accuracy: 0.9212\n",
      "Epoch 22/100\n",
      "109/109 [==============================] - 34s 311ms/step - loss: 0.0137 - accuracy: 0.9212 - val_loss: 0.0177 - val_accuracy: 0.9339\n",
      "Epoch 23/100\n",
      "109/109 [==============================] - 34s 310ms/step - loss: 0.0110 - accuracy: 0.9404 - val_loss: 0.0183 - val_accuracy: 0.9448\n",
      "Epoch 24/100\n",
      "109/109 [==============================] - 34s 309ms/step - loss: 0.0105 - accuracy: 0.9426 - val_loss: 0.0161 - val_accuracy: 0.9490\n",
      "Epoch 25/100\n",
      "109/109 [==============================] - 33s 305ms/step - loss: 0.0085 - accuracy: 0.9549 - val_loss: 0.0168 - val_accuracy: 0.9472\n",
      "Epoch 26/100\n",
      "109/109 [==============================] - 34s 310ms/step - loss: 0.0076 - accuracy: 0.9605 - val_loss: 0.0159 - val_accuracy: 0.9580\n",
      "Epoch 27/100\n",
      "109/109 [==============================] - 33s 304ms/step - loss: 0.0067 - accuracy: 0.9637 - val_loss: 0.0165 - val_accuracy: 0.9466\n",
      "Epoch 28/100\n",
      "109/109 [==============================] - 33s 304ms/step - loss: 0.0081 - accuracy: 0.9551 - val_loss: 0.0162 - val_accuracy: 0.9492\n",
      "Epoch 29/100\n",
      "109/109 [==============================] - 33s 304ms/step - loss: 0.0073 - accuracy: 0.9599 - val_loss: 0.0154 - val_accuracy: 0.9575\n",
      "Epoch 30/100\n",
      "109/109 [==============================] - 33s 304ms/step - loss: 0.0227 - accuracy: 0.8990 - val_loss: 0.0185 - val_accuracy: 0.9402\n",
      "Epoch 31/100\n",
      "109/109 [==============================] - 34s 309ms/step - loss: 0.0075 - accuracy: 0.9615 - val_loss: 0.0146 - val_accuracy: 0.9615\n",
      "Epoch 32/100\n",
      "109/109 [==============================] - 33s 305ms/step - loss: 0.0046 - accuracy: 0.9766 - val_loss: 0.0169 - val_accuracy: 0.9586\n",
      "Epoch 33/100\n",
      "109/109 [==============================] - 33s 305ms/step - loss: 0.0043 - accuracy: 0.9771 - val_loss: 0.0172 - val_accuracy: 0.9587\n",
      "Epoch 34/100\n",
      "109/109 [==============================] - 34s 309ms/step - loss: 0.0040 - accuracy: 0.9785 - val_loss: 0.0167 - val_accuracy: 0.9641\n",
      "Epoch 35/100\n",
      "109/109 [==============================] - 34s 310ms/step - loss: 0.0080 - accuracy: 0.9608 - val_loss: 0.0276 - val_accuracy: 0.9117\n",
      "Epoch 36/100\n",
      "109/109 [==============================] - 34s 308ms/step - loss: 0.0089 - accuracy: 0.9517 - val_loss: 0.0163 - val_accuracy: 0.9598\n",
      "Epoch 37/100\n",
      "109/109 [==============================] - 34s 313ms/step - loss: 0.0038 - accuracy: 0.9805 - val_loss: 0.0173 - val_accuracy: 0.9638\n",
      "Epoch 38/100\n",
      "109/109 [==============================] - 34s 311ms/step - loss: 0.0031 - accuracy: 0.9837 - val_loss: 0.0192 - val_accuracy: 0.9643\n",
      "Epoch 39/100\n",
      "109/109 [==============================] - 34s 309ms/step - loss: 0.0028 - accuracy: 0.9843 - val_loss: 0.0164 - val_accuracy: 0.9648\n",
      "Epoch 40/100\n",
      "109/109 [==============================] - 33s 304ms/step - loss: 0.0026 - accuracy: 0.9861 - val_loss: 0.0183 - val_accuracy: 0.9625\n",
      "Epoch 41/100\n",
      "109/109 [==============================] - 33s 304ms/step - loss: 0.0132 - accuracy: 0.9430 - val_loss: 0.0165 - val_accuracy: 0.9611\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=False)\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"./model_checkpoint/\",\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[accuracy])\n",
    "\n",
    "# train model\n",
    "history = model.fit([dev_ctx_e, dev_tags_e, dev_words_e], dev_lemmas_e, epochs=100, batch_size=256, validation_data=([val_ctx_e, val_tags_e, val_words_e], val_lemmas_e), callbacks=[early_stopping, checkpoint_callback])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2038/2038 [==============================] - 139s 68ms/step - loss: 0.0227 - accuracy: 0.9502\n",
      "Test loss:  0.0226734708994627\n",
      "Test accuracy:  0.9502269625663757\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "result = model.evaluate([test_ctx_e, test_tags_e, test_words_e], test_lemmas_e)\n",
    "print(\"Test loss: \", result[0])\n",
    "print(\"Test accuracy: \", result[1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08eac26dc1f80337b7d87e94e7159a5bad95c2e85f47efef91c61359b3afbfe9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
